[
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: The writer had just entered into his eighteenth year , when he met at the table of a certain Anglo - Germanist an individual , apparently somewhat under thirty , of middle stature , a thin and <define> weaselly </define> figure , a sallow complexion , a certain obliquity of vision , and a large pair of spectacles . \n    target text: Resembling a weasel (in appearance).\n    generated text: Resembling or characteristic of a weasel.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text accurately captures the meaning of weaselly as resembling a weasel in appearance, which aligns with the target text. The additional information in the generated text is consistent with the input text and does not introduce any nonsensical or factually incorrect details. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Sailors ' and fishermen 's <define> sheath - knives </define> . Sailors ' sheath - knives .   Wilcox , Crittenden & Co. , Middletown , Conn.29428 .   Sheath and belt , with \" law - abiding \" sheath - knife . First quality.29426 .   Sheath and belt . Second quality.29427 .   Sheath and belt , with \" law - abiding \" sheath - knife . Third quality . The \" law - abiding \" sheath - knife is round at the tip of the blade , which is also thick and dull . \n    target text: .\n    generated text: Alternative form of sheath knife\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text Alternative form of sheath knife does not accurately reflect the content of the input and target text. The input text provides specific information about sheath-knives being associated with sailors and fishermen, as well as details about the quality and characteristics of the law-abiding sheath-knife. However, the generated text does not capture any of this information and instead provides a vague and incomplete definition. Additionally, the generated text introduces the concept of an alternative form without any support from the input or target text, making it factually incorrect and unsupported. Therefore, the generated text is a hallucination.\nThis is the probability assigned by the lexicographer: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: As to age , Bead could not form any clear impression ; he might have been twenty , or forty . All of this visual perception occurred in an <define> eyewink </define> of time   [ ï¿½ ] \n    target text: (poetic) An instant, a short moment.\n    generated text: (obsolete) A short period of time.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text accurately captures the essence of the target text by defining eyewink as a short period of time, which aligns with the poetic meaning of the word. The input text also supports the concept of a brief moment or instant, and there are no additional unsupported details in the generated text. Therefore, it is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Because redpillers are usually normies or <define> Chadlites </define> while incels are ugly low - value males that women feel innately repulsed by . \n    target text: (incel, _, slang) A man of a slightly lower ranking on a scale of physical attractiveness than Chad.\n    generated text: (slang) An incel.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text An incel does not accurately reflect the target text, which defines incel as A man of a slightly lower ranking on a scale of physical attractiveness than Chad. The generated text lacks the crucial information about the comparison to Chads physical attractiveness. Additionally, the generated text does not provide any meaningful definition or explanation of Chadlites as per the input text. Therefore, it introduces new information that cannot be supported by the input text or the target text, making it a hallucination.\nThis is the probability assigned by the lexicographer: 0.9\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: On the second day of massive live - fire drills being held by the People 's Liberation Army ( PLA ) around Taiwan , Taiwan 's Army also conducted live - fire exercises in Lienchiang County 's Dongyin Township from 6 p.m. to 9 p.m. However , during the exercises , witnesses gave differing accounts of either tracer fire or flares landing on a hill behind Sanjia Village on <define> Xiyin </define> Island and starting a fire , reported UDN . \n    target text: An island in Dongyin, Lienchiang, Taiwan, in the Matsu Islands.\n    generated text: An island in Lienchiang County, Taiwan.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text only mentions Lienchiang County, Taiwan, without specifying the location of Xiyin Island within the Matsu Islands. This is a crucial detail that is missing from the generated text and is supported by the input and target text. Therefore, the generated text is a hallucination.\nThis is the probability assigned by the lexicographer: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Grouped in the center of the hall were about two hundred men , all armed with sabers , ï¿½ men of every age , and height and swarthiness , from stout , <define> blue - bearded </define> veterans to youths yet in their teens   [ ï¿½ ] \n    target text: Having thick, dark facial hair.\n    generated text: Alternative form of blue-bearded\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text Alternative form of blue-bearded is factually incorrect as it does not accurately define the term blue-bearded as Having thick, dark facial hair as in the target text. Additionally, the generated text does not align with the input text, as it does not provide a clear definition of blue-bearded based on the description of the men in the hall. It simply states an alternative form without providing a meaningful explanation. Therefore, the generated text is a hallucination.\nThis is the probability assigned by the lexicographer: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: The <define> sacrifice bunt </define> was fielded cleanly , but the only play was to first . \n    target text: (baseball) A ball that has been intentionally hit softly with a hands-spread batting stance with the intention of advancing a runner at the cost of an out\n    generated text: (baseball) A sacrifice bunt.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text is a concise and accurate definition of a sacrifice bunt, consistent with the input and target text. It does not contain any nonsensical or factually incorrect information, nor does it introduce any additional unsupported information. As a result, it aligns closely with the provided inputs and targets.\nThis is the probability assigned by the lexicographer: 0.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: ï¿½ She changes her shape depending on which way you 're coming at her . Once you know the contours of Bulgonunna you 'll never get <define> bushed </define> in this country . ï¿½ \n    target text: (AU) Lost in the bush. [from 19th c.]\n    generated text: (Australia, New Zealand, slang) Drunk.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated definition Drunk does not match the context provided in the input and target texts, which describe being lost in the bush. Additionally, the generated definition contains additional information that is not supported by the input or target text. Therefore, it does not accurately define the word in the given context.\nThis is the probability assigned by the lexicographer: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: The <define> metaontology </define> debate has now migrated from discussions of composition . \n    target text: The ontology of ontology.\n    generated text: (linguistics) The study of the relationships between words and their meanings.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text is hallucination because it contains information that cannot be supported by the input text or the target text. The input text mentions the ontology debate and the target text refers to the ontology of ontology, but the generated definition is about the study of the relationships between words and their meanings, which is unrelated to the provided context. Additionally, the generated text introduces new information not present in the input or target text, making it a hallucination.\nThis is the probability assigned by the lexicographer: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Poverty is the mother of <define> ingenuity </define> . \n    target text: The ability to solve difficult problems, often in original, clever, and inventive ways.\n    generated text: (uncountable) The quality or state of being ingenious.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text does not accurately capture the meaning of the target text, which describes the ability to solve difficult problems in original, clever, and inventive ways. The generated text simply defines ingenious as the quality or state of being ingenious, without providing any insight into what that quality entails. Additionally, the generated text does not incorporate the context from the input text, which suggests that poverty fosters ingenuity. As a result, the generated text is a hallucination as it does not align with the meaning or context provided in the input and target texts.\nThis is the probability assigned by the lexicographer: 0.9\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: \" But why should I be in another room ? \" \" You <define> passed over </define> in the night . \" \" Passed over ? Do you mean I died ? \" \" Yes , lady , you died . \" There was a long silence . \n    target text: (intransitive, euphemistic) To die and thus progress to the afterlife.\n    generated text: (intransitive) To die.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text accurately captures the core meaning of passed over as a euphemism for die, which aligns with the target text. The input text also implies a euphemistic usage of the phrase. There is no additional unsupported information in the generated text. Therefore, it is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: an <define> obliquangular </define> triangle \n    target text: (archaic, geometry) Formed of oblique angles.\n    generated text: (geometry) Of or pertaining to an oblique angle.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text accurately captures the meaning of obliquangular by referring to an oblique angle, which aligns with the input text and the target text. It does not contain any nonsensical or factually incorrect information, nor does it introduce any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: It can be argued that explicit representations of bisexuality , pansexuality , and other multiple - gender - attracted people are erased from games that use ' <define> playersexuality </define> ' as a mechanic . \n    target text: (video games) The state of an NPC being attracted to the player character, especially without regard to gender, race, etc.\n    generated text: (video games) The state or condition of being bisexual in a video game.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text incorrectly defines playersexuality as the state or condition of being bisexual in a video game, which is not supported by the input text or the target text. The input text specifically mentions bisexuality and pansexuality as well as other multiple-gender-attracted people, indicating that playersexuality encompasses a broader spectrum of attractions beyond just bisexuality. The target text also emphasizes the lack of regard for gender, race, etc., further supporting the idea that playersexuality is not limited to being bisexual. Therefore, the generated text contains additional information that cannot be supported by the input and target texts, making it a hallucination.\nThis is the probability assigned by the lexicographer: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Our algorithms rely on random sampling and their analysis leverages on Rademacher averages and <define> pseudodimension </define> , fundamental concepts from statistical learning theory . \n    target text: (maths)\n    generated text: Alternative form of pseudodimension\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text accurately identifies pseudodimension as a fundamental concept from statistical learning theory, which aligns with the input text and the target text. It does not contain any nonsensical or factually incorrect information, and it does not introduce any additional unsupported information. Therefore, based on the given inputs and targets, the generated text is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Those <define> daggum </define> thieves stole my car ! \n    target text: (US, euphemism, dialectal) goddamn\n    generated text: (colloquial) Used as an intensifier.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text accurately captures the euphemistic and dialectal nature of the word daggum as used in the input text and target text. It provides a colloquial definition that aligns with the euphemistic usage of the word. Additionally, the generated text does not contain any nonsensical or factually incorrect information, nor does it introduce unsupported additional information. Therefore, based on the provided inputs and targets, the generated text is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: [ ï¿½ ]   and his physique was rather <define> hulksome </define> , with muscles built upon muscles giving him a chiseled statuesque appearance . \n    target text: Characteristic of a hulk; large and bulky; hulking.\n    generated text: Resembling or characteristic of a hulk.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text closely captures the essence of the target text by describing something resembling or characteristic of a hulk, which aligns with the input text describing the physique as hulksome and chiseled statuesque appearance. The generated text does not contain any nonsensical or factually incorrect information, nor does it introduce any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: He who first acts as striker asks the other how many blows of the <define> rattan </define> he will bear on his forearm without crying out . \n    target text: (by extension) A cane made from this material.\n    generated text: (South Asia, historical) A long, thin stick with a pointed end, used for striking.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text provides a specific and accurate definition of rattan as a long, thin stick with a pointed end used for striking, which aligns with the general concept of a cane made from this material. The additional information about its historical use in South Asia does not contradict the input text or the target text, and as such, it does not introduce any nonsensical or factually incorrect details. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: <define> Taking on </define> a first employee should be done with care and consideration . \n    target text: To acquire, bring in, or introduce.\n    generated text: (transitive) To take on (a task or responsibility).\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text accurately captures the meaning of taking on as acquiring, bringing in, or introducing, which aligns with the target text. Although it does not explicitly mention first employee, the concept of taking on a task or responsibility can be interpreted in the context of hiring the first employee. Therefore, the generated text does not contain nonsensical or factually incorrect information and does not introduce additional unsupported information. Hence, it is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Ah ! they were grand days , those deep , full days , when our coming life , like an unseen organ , pealed strange , <define> yearnful </define> music in our ears , and our young blood cried out like a war - horse for the battle . \n    target text: Filled with yearning; desirous; mournful; distressing.\n    generated text: Full of longing; yearning.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text accurately captures the meaning of yearnful by describing it as Full of longing; yearning which aligns with the target text Filled with yearning; desirous; mournful; distressing. The generated text does not contain any nonsensical or factually incorrect information, and it does not introduce any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Economics is a messy discipline : too fluid to be a science , too <define> rigorous </define> to be an art . Perhaps it is fitting that economists ï¿½ most - used metric , gross domestic product ( GDP ) , is a tangle too . GDP measures the total value of output in an economic territory . Its apparent simplicity explains why it is scrutinised down to tenths of a percentage point every month . \n    target text: Showing, causing, or favoring rigour/rigor; scrupulously accurate or strict; thorough.\n    generated text: (uncountable) The quality of being rigorous.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text accurately defines rigorous as Showing, causing, or favoring rigour/rigor; scrupulously accurate or strict; thorough, which aligns with the meaning of the word in the context of the input and target text. It does not contain any nonsensical or factually incorrect information, nor does it introduce any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.2\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Cheers <define> marrow </define> ! \n    target text: (Geordie, informal) A friend, pal, buddy, mate.\n    generated text: (slang) The human body.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text The human body does not accurately define marrow as a friend, pal, buddy, or mate, as indicated by the target text. Additionally, the generated text contains nonsensical information that cannot be supported by the input text or the target text. Therefore, it is a hallucination.\nThis is the probability assigned by the lexicographer: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: The first of these patients especially dreads the flames of hell . This is the demonomania of Sauvages . I call it <define> demonophobia </define> , monodemonophobin . \n    target text: An irrational fear of demons.\n    generated text: (psychology) A fear of demons.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text accurately captures the essence of demonophobia as an irrational fear of demons, which is supported by the input and target texts. While it may lack specificity, it does not contain any nonsensical or factually incorrect information. Therefore, it is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Grids are used for such <define> quotidian </define> items as stationery , business cards , mailing labels , hang tags , instruction manuals , etc . \n    target text: Having the characteristics of something which can be seen, experienced, etc, every day or very commonly; commonplace, ordinary, mundane. [from 15th c.]\n    generated text: Of, pertaining to, or characteristic of quotidian life.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text accurately captures the meaning of the input and target texts, describing quotidian items and characteristics of quotidian life, without introducing any nonsensical or factually incorrect information. The generated text does not contain any additional information beyond what is supported by the input and target texts. Therefore, it is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: I never can cease admiring that beautiful request of the Prayer - book , ï¿½ A happy issue out of all their affliction . ï¿½ It is so humble , so <define> undictating </define> to God , so moderate , yet so ample . God give that to us both . Amen . In His way and time , and in this world and in the next . \n    target text: Not dictating.\n    generated text: Not dictating.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text Not dictating accurately reflects the meaning of the input text and the target text. It does not contain any nonsensical or factually incorrect information, nor does it introduce any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: <define> parachutable </define> supplies \n    target text: Capable of being deployed by parachute.\n    generated text: Capable of being parachuted.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text accurately captures the meaning of parachutable as being capable of being deployed by parachute, which aligns with the target text. The input text does not provide any specific details beyond the term parachutable, so the generated text does not add any unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Some perhaps worship only on alternate Sundays ; others still more <define> occasionally </define> . \n    target text: From time to time; sometimes; at relatively infrequent intervals. [from 15th c.]\n    generated text: In an occasional manner.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text accurately captures the meaning of occasionally as from time to time; sometimes; at relatively infrequent intervals as given in the target text. It does not contain any nonsensical or factually incorrect information, and it does not provide any additional unsupported information beyond the input and target texts. Therefore, it is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: \" Christ \" ï¿½ he yawned ï¿½ \" Christ , what the hell is everybody getting so <define> pisspants </define> scared and nervous for ? Vince Eames is what ? A crook ? So ? ... \n    target text: (slang, vulgar, derogatory, rare) An objectionable or cowardly person.\n    generated text: (vulgar, slang) Very scared or nervous.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text accurately reflects the slang meaning of pisspants as very scared or nervous, which is consistent with the general context of the input text. Although the target text provides a more specific derogatory meaning, the generated text does not contain any nonsensical or factually incorrect information and does not introduce any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.2\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Many years ago , we decided to <define> relawn </define> and replant the garden . \n    target text: (transitive, rare) To provide with a new lawn.\n    generated text: (transitive) To plant again.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text To plant again does not accurately capture the specific action of providing with a new lawn as indicated in the target text. Additionally, the input text does not provide any context or indication of the word relawn being used in the sense of planting again, making it unsupported by the input. Therefore, the generated text is a hallucination.\nThis is the probability assigned by the lexicographer: 0.9\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: The artist took a thoughtful <define> toke </define> off the joint , then passed it along . \n    target text: (slang) A puff of marijuana.\n    generated text: (slang, uncountable) The act of smoking marijuana.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text accurately defines toke as the act of smoking marijuana, which aligns with the target texts definition of a puff of marijuana. The input text also supports this, as it describes the artist taking a toke off the joint. Additionally, the generated text does not contain any nonsensical or factually incorrect information, nor does it introduce any unsupported additional information. Therefore, it is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Popular <define> cosplays </define> include , for example , characters from the Final Fantasy range of games [ ï¿½ ] \n    target text: (countable) A skit or instance of this art or practice.\n    generated text: (informal) A cosplay.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text A cosplay is not a complete definition of the term cosplays as requested in the input text. It lacks the crucial information that cosplays are skits or instances of this art or practice. Additionally, the generated text does not accurately convey the countable nature of the term, as specified in the target text. Therefore, it fails to capture the full meaning and context provided by the input and target texts, making it a hallucination.\nThis is the probability assigned by the lexicographer: 0.9\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: ï¿½ [ ï¿½ ]   the Pope   [ ï¿½ ]   had to send him a valuable Gift , which you may see some day . ï¿½ Nï¿½ssler did , one day , see this <define> preciosity </define> : a Crucifix , ebony bordered with gold , and the Body all of that metal , on the smallest of altars , in Walrave ï¿½s bedroom . \n    target text: (obsolete, countable) Something of high value or worth.\n    generated text: The state or quality of being precious.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text The state or quality of being precious does not accurately capture the meaning of the target text, which defines preciosity as Something of high value or worth. The generated text is not supported by the input text or the target text. It provides a general definition of preciosity rather than the specific meaning intended in this context. Therefore, it adds additional information that cannot be supported by the input text or the target text, making it a hallucination.\nThis is the probability assigned by the lexicographer: 0.9\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: A recent president of the International Association of Police Chiefs , an organization regarded almost universally as a bastion of ' <define> old - boyism </define> , ' was the female chief of police of Gaithersburg , Maryland . \n    target text: Alternative form of old boyism\n    generated text: (derogatory) The belief that men are superior to women and should be treated as such.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text contains additional information that cannot be supported by the input text or the target text. The input text only mentions the term old-boyism and does not provide any indication of the belief that men are superior to women and should be treated as such. The target text simply states that old-boyism is an alternative form of old boyism, without making any reference to gender superiority. The generated text introduces a new and unsupported meaning, making it a hallucination.\nThis is the probability assigned by the lexicographer: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: see Wikipedia : <define> tramp </define> steamer \n    target text: Any ship which does not have a fixed schedule or published ports of call.\n    generated text: (intransitive) To travel by trampoline.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text To travel by trampoline is nonsensical and factually incorrect when compared to the input text see Wikipedia : <define> tramp </define> steamer and the target text Any ship which does not have a fixed schedule or published ports of call. There is no logical connection between the input text, target text, and the generated text, making it a clear hallucination.\nThis is the probability assigned by the lexicographer: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Each of their roles is so loaded with slickery , inconsistency and lowbrow intellectualisms , along with slapstick <define> gaggery </define> on which one can but gag , that the waste of talent is depressing . \n    target text: (informal) The use of gags or jokes.\n    generated text: (countable, uncountable) An instance of this.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text An instance of this does not accurately capture the informal meaning of gaggery as the use of gags or jokes. It does not reflect the context of the input text or the target text. Additionally, the generated text does not provide any meaningful explanation or definition of gaggery, making it factually incorrect and nonsensical in the given context.\nThis is the probability assigned by the lexicographer: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: The same phenomenon is also detectable in the records of the meetings of NATO committees : the priority of avoiding any manifestation of internal disagreements led to the production of ' <define> sterilized </define> ' records of discussions which evidently were significantly more lively than shown in the official papers . \n    target text: (transitive) To redact (a document), removing classified or sensitive material.\n    generated text: (transitive) To sterilize.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text To sterilize does not accurately capture the meaning of the input and target text, as it fails to convey the specific context of redacting classified or sensitive material from a document. The input text discusses the production of sterilized records to avoid internal disagreements, which aligns with the definition of redacting sensitive material rather than simply sterilizing. Therefore, the generated text is a hallucination.\nThis is the probability assigned by the lexicographer: 0.9\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Only minds completely crazed or fatally confused by the current <define> Christomania </define> would suppose that the details of the story , which is as old at least as the cult of Ptah in Memphis , were derived from the \" historic \" version   [ ï¿½ ] \n    target text: A fanatical devotion to Jesus Christ.\n    generated text: The belief that Jesus Christ is the savior of the world.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text The belief that Jesus Christ is the savior of the world contains additional information that cannot be supported by the input text or the target text. The input text only mentions the current Christomania and does not provide any context or support for the belief in Jesus Christ as the savior of the world. Additionally, the target text specifically mentions A fanatical devotion to Jesus Christ, which is different from the generated text. Therefore, the generated text is not supported by the given inputs and targets, making it a hallucination.\nThis is the probability assigned by the lexicographer: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: The ï¿½ black mists ï¿½ of Japan did not die with Yoshio Kodama . In the spirit of the late <define> kuromaku </define> , questionable payments and mob connections still stretch far and wide among Japan 's elected officials   [ ï¿½ ] \n    target text: In Japan, an ï¿½minence grise or secret decision-maker.\n    generated text: (historical) The Japanese mafia.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text historical) The Japanese mafia. is not a hallucination because it is supported by the input text which mentions questionable payments and mob connections still stretch far and wide among Japans elected officials. This suggests a link to the Japanese mafia, supporting the generated text. Additionally, the target text does not explicitly contradict the generated text, allowing for a reasonable interpretation in line with the input text.\nThis is the probability assigned by the lexicographer: 0.8\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: For use in a nursery for cradling a baby to sleep , a baby <define> cradler </define> comprising , in combination , a stand embodying a mobile base , uprights attached to and rising perpendicularly from the base and having axially aligned bearings ,   [ ï¿½ ] \n    target text: One who or that which cradles.\n    generated text: One who or that which cradles.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text accurately reflects the meaning of the input text and target text without adding any nonsensical or factually incorrect information. It stays true to the definition provided in the input and target text without introducing any unsupported additional details. Therefore, it is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: A <define> condoled chief </define> sits on the Grand Council that forms the leadership of the Confederacy . \n    target text: A tribal chief who sits on the Grand Council of the Haudenosaunee Confederacy.\n    generated text: (chiefly, North America) The chief of a Native American tribe.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text accurately captures the essence of a tribal chief sitting on the Grand Council of the Haudenosaunee Confederacy, which aligns with the target text. Additionally, the input text provides context about the leadership structure of the Confederacy, supporting the reference to the chief. The generated text does not contain any nonsensical or factually incorrect information, and it does not introduce any unsupported additional details. Therefore, it is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: A special group must be mentioned : 4 . artificial <define> immunodegradation </define> ( immunosuppression ) \n    target text: (immunology, rare) Degradation of or by the immune system.\n    generated text: (biochemistry, immunology) The degradation of the immune system.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text The degradation of the immune system contains factually incorrect information and is not supported by the input text or the target text. The input text mentions artificial immunodegradation, which refers to the degradation caused by artificial means such as drugs or experimental interventions, while the target text specifically refers to degradation of or by the immune system. The generated text does not accurately capture the concept of immunodegradation as described in the target text, making it a hallucination.\nThis is the probability assigned by the lexicographer: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: He took his arrow by the <define> nock </define> . \n    target text: (archery) The notch at the rear of an arrow that fits on the bowstring.\n    generated text: (obsolete) The nock of an arrow.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text does not provide a clear definition of nock and does not accurately reflect the information provided in the target text. It lacks the specific details about the notch at the rear of an arrow that fits on the bowstring, which is crucial for understanding the term in the context of archery. Additionally, the term obsolete used in the generated text is not supported by the input text or the target text, making it an unsupported addition. Therefore, the generated text is a hallucination.\nThis is the probability assigned by the lexicographer: 0.9\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: to <define> shorten </define> an allowance of food \n    target text: (transitive) To reduce or diminish in amount, quantity, or extent; to lessen.\n    generated text: (transitive) To reduce the length of.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text To reduce the length of does not accurately capture the meaning of to shorten as intended in the input and target texts. Shorten in this context means to reduce or diminish in amount, quantity, or extent, not specifically the length. Therefore, the generated text contains additional information that cannot be supported by the input text or the target text, making it a hallucination.\nThis is the probability assigned by the lexicographer: 0.9\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Even more amusing is that those doing the wishful humping in <define> bandslash </define> are n't your usual pin - ups . Bandslash has gone indie . This is a shadowy world where the boys in Franz Ferdinand are each others ' fetish objects , and former Libertines Carl Barat and Pete Doherty , lovers . \n    target text: (fandom slang) Slash fan fiction which pairs real musicians, especially ones belonging to the same group.\n    generated text: Alternative form of bandslash\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text Alternative form of bandslash does not accurately capture the meaning of bandslash as described in the target text. The target text clearly defines bandslash as a type of slash fan fiction which pairs real musicians, especially ones belonging to the same group. The generated text does not reflect this definition and thus introduces nonsensical information. Additionally, the generated text does not provide any meaningful information about the concept of bandslash in relation to the input text, making it a hallucination.\nThis is the probability assigned by the lexicographer: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: A weapon small enough to put on a missile would <define> require </define> uranium enriched to more than 90 % U-235 . \n    target text: Naturally to demand (something) as indispensable; to need, to call for as necessary. [from 15th c.]\n    generated text: (transitive) To require.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text accurately captures the meaning of the input and target text without adding any nonsensical or factually incorrect information. It does not contain any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Should true Proportion ev'ry Mortal grace , / And Semetry be seen in ev'ry Face : / Beauty no longer would be thought divine , / Nor would its Charms with half the Lustre shine : / No courtly Dame a <define> killing </define> Look could boast , / If once the Foils of Homeliness were lost . \n    target text: (dated) Devastatingly attractive.\n    generated text: (obsolete) Very handsome.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text Very handsome is not an accurate representation of the target text (dated) Devastatingly attractive. Additionally, the input text does not support the claim that the word killing in the context of a look is obsolete. Therefore, the generated text contains factually incorrect information and introduces unsupported details, leading to the conclusion that it is a hallucination.\nThis is the probability assigned by the lexicographer: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: The <define> preejection </define> shortening and relengthening correspond to septal beaking and flash . \n    target text: Occurring prior to ejection.\n    generated text: (anatomy) The act or process of preejection.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text The act or process of preejection does not accurately represent the meaning of preejection in the context of the input and target texts. The input text and target text refer to preejection as occurring prior to ejection, which is not captured by the generated definition. Additionally, the generated text introduces the concept of anatomy which is not supported by the input or target texts. Therefore, the generated text contains additional information that cannot be supported by the input and target texts, making it a hallucination.\nThis is the probability assigned by the lexicographer: 0.9\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: He had a nasty face though , the boy considered , and looked like a bounder because he had pimples , a <define> swelly </define> nose , a loud voice , and a swanky manner . The boy disapproved of him wholly . \n    target text: (informal) Tending to bulge or swell.\n    generated text: (informal, of a face) Having pimples.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text includes information about having pimples, which is not directly supported by the input text or the target text. The target text specifically defines swelly as tending to bulge or swell, but the generated text does not capture this meaning accurately. Additionally, the input text mentions a swelly nose, but the generated text does not reflect this characteristic at all. Therefore, the generated text contains additional information that cannot be supported by the input text or the target text, making it a hallucination.\nThis is the probability assigned by the lexicographer: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: ELYOT : And you ï¿½re an ill - mannered , bad tempered <define> slattern </define> . \n    target text: (dated) One who is uncareful or unconcerned about appearance or surroundings, usually said of a dirty and untidy woman.\n    generated text: (slang) A contemptible person.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text, (slang) A contemptible person, does not capture the specific meaning conveyed in the target text, which describes a person who is uncareful or unconcerned about appearance or surroundings, usually a dirty and untidy woman. The generated text also introduces additional information (contemptible person) that is not supported by the input text or the target text. Therefore, it is a hallucination.\nThis is the probability assigned by the lexicographer: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: ï¿½ Because I don&#39;t think that is a seventeenth - century helmet . ï¿½ There was something odd about the smoothness of the crown . The skull of the <define> lobster - tailed pot </define> helmet was often fluted . Generally , they were made in two sections joined by a ï¿½ ... \n    target text: A European combat helmet, worn especially from the 1600s into the 1700s, consisting of a rounded skull-piece, often cheek guards and a nasal or face-guard, and a laminated defence (or single plate ridged to imitate lames) to protect the back of the neck that resembled a lobster's tail.\n    generated text: Alternative form of lobstertail\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text Alternative form of lobstertail is factually incorrect and does not align with the information provided in the input text or the target text. It does not accurately describe the lobster-tailed pot helmet as a European combat helmet worn from the 1600s into the 1700s, consisting of a rounded skull-piece, cheek guards, a nasal or face-guard, and a laminated defense to protect the back of the neck that resembled a lobsters tail. The generated text does not provide any information related to the helmets construction, purpose, or historical context, making it a hallucination.\nThis is the probability assigned by the lexicographer: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Because of his disappearance over the final two months last season , Reyes has been the target of Shea <define> boobirds </define> , which , as Wright remarked , is almost a ï¿½ rite of passage . ï¿½ \n    target text: (slang) A spectator at a sporting event who boos the home team.\n    generated text: (slang, derogatory) A woman.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text A woman does not align with the input text or the target text, which describe boobirds as spectators at a sporting event who boo the home team. The generated text contains additional information that cannot be supported by the input text or the target text, making it a hallucination.\nThis is the probability assigned by the lexicographer: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: As expected , monolayers showed rapid cell rounding and <define> cytopathicity </define> in cells infected with MNV ( Fig 3 , 20 X insert in MNV infection ) . \n    target text: The condition of undergoing cytopathic change (cell disease)\n    generated text: The quality of being cytopathic.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text accurately defines cytopathicity as the condition of being cytopathic, which aligns with the target texts definition of the condition of undergoing cytopathic change (cell disease). The generated text does not contain any nonsensical or factually incorrect information, and it does not introduce any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.9\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: while Tungsten is not heavily redundant as these systems , the ability of Lustre to support some <define> failover </define> can be leveraged to eliminate single points of failure . \n    target text: (computing, countable) An automatic switch to a secondary system on failure of the primary system, such as a means for ensuring high availability of some critical resource (such as a computer system), involving a parallel backup system which is kept running at all times, so that, upon detected failure of the primary system, processing can be automatically shifted over to the backup.\n    generated text: Alternative form of failover\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text Alternative form of failover does not accurately represent the concept of failover as described in the target text. The target text clearly defines failover as an automatic switch to a secondary system on failure of the primary system, involving a parallel backup system. The generated text lacks this essential information and is therefore a hallucination.\nThis is the probability assigned by the lexicographer: 0.9\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: opposed unto mutability and <define> defectibility </define> of being \n    target text: deficiency; imperfection\n    generated text: The quality of being defectible.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text The quality of being defectible directly relates to the input text opposed unto mutability and defectibility of being and the target text deficiency; imperfection. It does not contain any nonsensical or factually incorrect information, and it does not provide additional unsupported information. Therefore, it is a direct and accurate interpretation of the input text and target text, making it not a hallucination.\nThis is the probability assigned by the lexicographer: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Son , the <define> cyber dissident </define> , is a businessman who holds graduate degrees in business administration and medicine . \n    target text: Alternative form of cyberdissident\n    generated text: (Internet) A person who uses cyberspace to express their political views.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text accurately defines cyber dissident as an alternative form of cyberdissident, which aligns with the target text. The definition does not contain any nonsensical or factually incorrect information, and it does not provide additional unsupported information beyond the input text and target text. Therefore, it is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: The pseudembryo moves rapidly in the water , rolling round and swinging from side to side ; as a rule , and especially when at rest , the surface bearing the pseudostome and <define> pseudoproct </define> is turned downwards . \n    target text: (biology) The anal opening on the pseudembryo of an echinoderm.\n    generated text: (zoology) A pseudostome.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text A pseudostome does not accurately represent the target text The anal opening on the pseudembryo of an echinoderm. The input text does not provide any information supporting the generated text, and the generated text contains additional information that cannot be supported by the input text or the target text. Therefore, the generated text is a hallucination.\nThis is the probability assigned by the lexicographer: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: A second Punta del Este <define> dateliner </define> , by Juan de Onis , quoted Secretary of State Dean Rusk giving the official U. S. view , which had already been reported extensively by Kenworthy and Szuie . \n    target text: (journalism) An article that is published under a dateline.\n    generated text: (countable) A newspaper article published on a specific date.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text contains additional information that cannot be supported by the input text or the target text. The input text and target text focus on the specific aspect of an article being published under a dateline, while the generated text adds the detail of countable and newspaper, which is not present in the input or target text. This additional information is not supported by the given inputs and targets, making it a hallucination.\nThis is the probability assigned by the lexicographer: 0.9\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: But purging is more proper if it may bee done without danger , as it may in the fourth , fift and ?ixt month of <define> pregnation </define> : for a child in the wombe is compared to an Apple on the tree . \n    target text: (obsolete) Pregnancy.\n    generated text: (uncountable) The state of being pregnant.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text accurately captures the meaning of the target text pregnancy by expressing it as the state of being pregnant, which aligns with the input text discussing pregnation. The definition does not contain any nonsensical or factually incorrect information, and it does not introduce any additional unsupported details. Therefore, it is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: The following appear rather like <define> revamps </define> of old versions absolutely than absolutely new jokes :   [ ï¿½ ] \n    target text: An act of improving, renewing, renovating, or revising something; an improvement, renovation, revamping, or revision. [from mid 19th c.]\n    generated text: (informal) A revision.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text A revision does not accurately capture the meaning of revamps as an act of improving, renewing, renovating, or revising something, and it does not align with the provided target text. The input text also does not support the informal usage of revamps as just a revision. Therefore, the generated text contains additional information that cannot be supported by the input text or the target text, making it a hallucination.\nThis is the probability assigned by the lexicographer: 0.9\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: They did n't need to be first in sales ; they did n't have to compete with the <define> hypesters </define> . Louis junior could honestly say that the wines he made were sound . \n    target text: One who uses hype to promote or advertise.\n    generated text: One who hypes something.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text accurately captures the meaning of the target text without adding any nonsensical or factually incorrect information. It stays within the scope of the input text and target text, making it not a hallucination.\nThis is the probability assigned by the lexicographer: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: With a tremendous groan , he <define> pulled out </define> and ejaculated all over her belly . \n    target text: (literally) To use coitus interruptus as a method of birth control.\n    generated text: (intransitive) To ejaculate.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text To ejaculate is a hallucination because it contains additional information that cannot be supported by the input text or the target text. The target text specifically refers to coitus interruptus as a method of birth control, but the generated text does not capture this specific method. Instead, it simplifies the meaning to just ejaculate, which is not accurate in the context of birth control. Additionally, the input text does not provide any context or support for the generated definition. Therefore, the generated text does not accurately reflect the meaning of the term as intended in the given context.\nThis is the probability assigned by the lexicographer: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: A total of 18 patients ( 22.5 % ) had persistent HBsAg positivity after transplant without <define> seroclearance </define> ( n = 8) or reappearance of HBsAg after initial seroclearance ( n = 10 ) . \n    target text: The clearance (removal) of an antigen from the blood\n    generated text: (medicine) Seroclearance.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text accurately defines seroclearance as the clearance (removal) of an antigen from the blood, which aligns with the context of the input and target text. There are no nonsensical or factually incorrect information in the generated text, and it does not contain any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: She had never met someone so <define> sweaty </define> . \n    target text: Having a tendency to sweat.\n    generated text: (informal, of a person) Intoxicated.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text Intoxicated does not align with the input text sweaty and the target text having a tendency to sweat. Additionally, intoxicated introduces new information not supported by the input or target text, making it a hallucination.\nThis is the probability assigned by the lexicographer: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: She was lying in the lee of a fowlhouse in a crumpled posture , as if cohesion had been detached from her joints , which lobbed her in an untidy heap , like a lot of old bones , tied together with string . Her skull was hitched under her humped shoulders and her fallen jaw made a lipless <define> O </define> of her mouth , giving it an expression of imbecile astonishment . \n    target text: Something shaped like the letter O.\n    generated text: (informal) The sound made by the mouth when it opens and closes.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text contains information that is not supported by the input text or the target text. It introduces the concept of the sound made by the mouth when it opens and closes, which is not mentioned or implied in the input text or the target text. Additionally, it does not accurately describe something shaped like the letter O, as the target text specifies. Therefore, the generated text is a hallucination.\nThis is the probability assigned by the lexicographer: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Thomas writes of <define> matrescence </define> as spiritual formation drawing analogies with the Judaeo - Christian tradition . \n    target text: The process of becoming (and coming to inhabit the role of) a mother.\n    generated text: The act of maturing.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text The act of maturing does not accurately represent the concept of matrescence as described in the input text and target text. Matrescence refers to the process of becoming and inhabiting the role of a mother, which involves psychological and emotional changes, not just the act of maturing. The generated text lacks the specific and essential aspects of the concept mentioned in the input and target texts, making it a hallucination.\nThis is the probability assigned by the lexicographer: 0.9\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: While the United States remained a <define> non - belligerent </define> speeds continued unimpaired , despite the increasingly dense occupation of main - line tracks , but the entry of the U.S.A. into the war in December , 1941 , made its effect felt almost immediately . \n    target text: Alternative form of nonbelligerent\n    generated text: Alternative form of non- belligerent\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text Alternative form of non- belligerent is a valid alternative form of the word nonbelligerent without any nonsensical or factually incorrect information. It does not contain any additional information that cannot be supported by the input text or the target text. Therefore, it is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: As long as you get the vice president 's approval first , it 'll be a <define> slam dunk </define> . \n    target text: (colloquial, idiomatic) A task expected to present no difficulty, a piece of cake.\n    generated text: (idiomatic) Something that is certain to be successful.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text accurately reflects the meaning of the target text, describing something as certain to be successful. It does not introduce any nonsensical or factually incorrect information, and it does not contain any additional information beyond what is supported by the input and target texts. Therefore, it is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: This particular article , published to my site kheperu.org in 2002 , was penned in response to a letter received from a <define> psivamp </define> who had stirred up trouble for himself by outing his nature to his Wiccan High Priestess . \n    target text: A supposed form of vampire that subsists on the psychic energy of others.\n    generated text: (fandom slang) A person with psionic abilities.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text does not align with the input text or the target text. The input text mentions a psivamp who stirred up trouble by outing his nature to his Wiccan High Priestess, indicating a vampire-like entity. The target text defines psivamp as a supposed form of vampire that subsists on the psychic energy of others. However, the generated text defines psivamp as a person with psionic abilities, which does not match the context provided in the input and target texts. Therefore, the generated text contains additional information that cannot be supported by the input text or the target text, making it a hallucination.\nThis is the probability assigned by the lexicographer: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Sir Georg Solti and the Chicago Symphony Orchestra may have been <define> made for each other </define> , but they were also made to play Beethoven . \n    target text: (idiomatic) Compatible; interacting effectively; in a complementary relationship.\n    generated text: (idiomatic) Perfectly suited for each other.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text accurately captures the essence of the idiomatic meaning expressed in the target text and is consistent with the input text. There are no nonsensical or factually incorrect statements, and the additional information provided is directly supported by the input and target texts. Therefore, it is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Maybe during the first session we can try to size up the type of anger problem she has : exploding ? <define> underhanding </define> ? somatizing ? \n    target text: Devious; passive-aggressive.\n    generated text: (transitive) To act in an underhanded manner.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text provides a concise and accurate definition of underhanding as to act in an underhanded manner, which aligns with the target text devious; passive-aggressive. The input text also suggests exploring the type of anger problem related to underhanding, supporting the idea of underhanded behavior. The generated text does not contain nonsensical or factually incorrect information, nor does it introduce additional unsupported details. Therefore, it is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Quatermass also mediated Wellsian influence on the tone and preoccupations of the new hybrid SF ï¿½ horror - film genre , with its monstrous <define> Gigeresque </define> fusions of machine and organism [ ï¿½ ] \n    target text: Reminiscent of H. R. Giger (born 1940), Swiss surrealist painter best known for nightmarish biomechanical imagery.\n    generated text: Resembling or characteristic of French surrealism.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text does not accurately describe the meaning of Gigeresque in the context of the input and target texts. It states Resembling or characteristic of French surrealism, which is factually incorrect and does not match the intended meaning of Gigeresque as reminiscent of H. R. Gigers nightmarish biomechanical imagery. Additionally, the generated text introduces the concept of French surrealism, which is not supported by the input or target texts, making it an unsupported addition. Therefore, the generated text is a hallucination.\nThis is the probability assigned by the lexicographer: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: At least Dr. Beeching can no longer be accused by anyone of disinterest in railways , after the king - sized squib he flung into one of the particularly combustible <define> pre - election </define> topics - transport - at the end of June . \n    target text: Alternative form of preelection\n    generated text: Before an election.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text Before an election. does not accurately reflect the meaning of the term preelection or its alternative form. It lacks specificity and fails to capture the context of the term in the given sentence. Additionally, the generated text does not align with the target text, which indicates that it is an alternative form of preelection, not a literal definition. Therefore, the generated text is a hallucination as it contains factually incorrect information and lacks contextual relevance.\nThis is the probability assigned by the lexicographer: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: so as no fuller on earth can <define> white </define> them \n    target text: (transitive) To make white; to whiten; to bleach.\n    generated text: (transitive) To make white.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text accurately captures the action of making something white, which aligns with the target text To make white; to whiten; to bleach. The input text also implies the act of defining or making something clear, which can be interpreted as making something white in this context. There is no additional unsupported information in the generated text, and it does not contradict the input or target text.\nThis is the probability assigned by the lexicographer: 0.2\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Elytra <define> miniatous </define> , with a large somewhat triangular black spot on their disk ,   [ ï¿½ ] \n    target text: (formal) Orange-red, the colour of red lead.\n    generated text: (zoology) Of or pertaining to a minotaur.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text is a hallucination because it contains information that cannot be supported by the input text or the target text. The input text describes the physical characteristics of Elytra, while the target text provides the formal definition of the color miniatous as orange-red. The generated text, however, introduces the concept of minotaur, which is unrelated to the input or target. This additional information is not supported by the context and is factually incorrect in this context.\nThis is the probability assigned by the lexicographer: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: This is the sort of witchery , not easily defined ï¿½ but , by its votaries , pretty sensibly felt , in hunting the fox . The light - hearted , high - spirited stripling , when cigaring it careless to cover , with a kind of a knowing demi - <define> devil - may - care </define> twist of his beaver , receives in his transit a benison from every real friend of the chase he may chance to pass ; and the airy , eager zeal of the youthful aspirant to rolls , tumbles , and the brush , will flush his memory with the frolic gayety of other days , and animate his mind with reflections most welcome to his heart . \n    target text: Carefree, reckless, irresponsible.\n    generated text: Alternative form of devil-may-care\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text accurately represents the input text and the target text, providing a synonymous definition without any nonsensical or factually incorrect information. It does not introduce any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Pimpin ï¿½ came so naturally to MT when he and his sisters played pimp and <define> hoe </define> games that one of his sisters wanted to hoe for him when they grew up . \n    target text: (US, slang) .\n    generated text: (intransitive, slang) To have sex.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated definition To have sex contains additional information that cannot be supported by the input text or the target text. The input text only mentions pimp and hoe games without specifying the exact meaning or action involved, and the target text provides the slang term without further elaboration. Therefore, the specific information To have sex is unsupported and not directly related to the input or target text, making it a hallucination.\nThis is the probability assigned by the lexicographer: 0.9\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: I met one of your dons at tea , and he said that your degree was not in the least a proof of your abilities : he said that you knocked up and got <define> flurried </define> in examinations . \n    target text: Agitated, confused.\n    generated text: (transitive, slang) To fail (an examination).\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text accurately captures the meaning of flurried as agitated and confused, which aligns with the target text. The input text also suggests a context of examinations, which supports the idea of failing an examination. The generated text does not contain any nonsensical or factually incorrect information, nor does it introduce additional unsupported details. Therefore, it is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: And on tonight ï¿½s episode , when she faces a crisis ï¿½ the reactions to her incoherent TV interviews last January ï¿½ the carefully created sentences she uses to explain her slurry , <define> stumbly </define> self - presentation says it all . \n    target text: prone to stumble\n    generated text: (figuratively, of a person) Having a tendency to stammer.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text contains additional information that cannot be supported by the input text or the target text. The input text does not mention stammering, and the target text specifically indicates prone to stumble rather than stammering. The inclusion of stammering in the generated text introduces unsupported information, making it a hallucination.\nThis is the probability assigned by the lexicographer: 0.9\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Replying students did not differ significantly from <define> nonreplying </define> students in predicted grade - point averages . \n    target text: Not replying (to a survey etc.).\n    generated text: Not responding.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text Not responding accurately captures the meaning of the target text Not replying (to a survey etc.) without adding any nonsensical or factually incorrect information. It aligns with the input text and target text without introducing any unsupported additional information. Therefore, it is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: And its success or failure is likely to tell whether talents as varied as Will Ferrell , Tom Cruise , Jerry Bruckheimer , Derek Jeter or Norah Jones ï¿½ Creative Artists clients all ï¿½ will maintain their leverage against evolving media giants like the News Corporation and Viacom or make new fortunes from the <define> nonentertainment </define> companies that are looking to Hollywood . \n    target text: Not of or pertaining to entertainment.\n    generated text: Not entertainment.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text accurately captures the essence of the target text by stating that the subject is Not entertainment, which aligns with the definition of nonentertainment. The generated text does not contain any additional information beyond the input and target texts, and it is factually correct based on the context provided in the input text. Therefore, it is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: It was both the doctrine of the apostles , and the practice of the church , while it was <define> symmetral </define> , to obey the magistrate . \n    target text: (obsolete) commensurable; symmetrical\n    generated text: Of or pertaining to symmetry.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text accurately reflects the meaning of symmetral as commensurable or symmetrical, which aligns with the target text. It also stays within the scope of the input text by referring to symmetry, which is related to the concept of symmetral. There are no nonsensical or factually incorrect statements in the generated text, and it does not introduce any additional unsupported information. Therefore, based on the given inputs and targets, the generated text is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.9\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: We use a mouse model of DEND syndrome ( nV59 M mice ) to determine if subcutaneous or <define> intracranioventricular </define> administration of glibenclamide can affect neurological function . \n    target text: Within a ventricle of the brain\n    generated text: (anatomy) Relating to the cerebrum\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text intracranioventricular does not accurately describe the location Within a ventricle of the brain as indicated in the target text. Additionally, the generated text does not align with the input texts context of administering glibenclamide. Therefore, the generated text contains additional information that cannot be supported by the input text or the target text, making it a hallucination.\nThis is the probability assigned by the lexicographer: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: ï¿½ What are you doing ? ï¿½ Carly asked , looking around . ï¿½ You do nï¿½t want to be in here . You ï¿½re way too much of a princess . ï¿½ / ï¿½ Remember how I grew up , Carly . I ï¿½ve earned my <define> princessness </define> . ï¿½ \n    target text: The quality of being a princess.\n    generated text: The state or quality of being a princess.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text accurately captures the essence of the target text, which is The quality of being a princess. It does not contain any nonsensical or factually incorrect information, and it does not introduce any additional unsupported information. The generated text directly reflects the input and target texts without any distortion or fabrication.\nThis is the probability assigned by the lexicographer: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: <define> exacerbators </define> of pulmonary disease \n    target text: One who, or that which, exacerbates or makes worse.\n    generated text: One who exacerbates.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text accurately reflects the definition provided in the target text, and it does not introduce any additional information beyond the input and target texts. The definition One who exacerbates aligns with One who, or that which, exacerbates or makes worse from the target text, and it does not contain any nonsensical or factually incorrect information. Therefore, it is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Within seconds , the air was thick with flying potato chips , <define> cheezies </define> and other odds and ends . \n    target text: (Canada) A cheese puff.\n    generated text: (informal) Cheez-Its.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text Cheez-Its does not accurately represent the target text A cheese puff and introduces additional information that cannot be supported by the input text or the target text. The input text mentions flying potato chips and other odds and ends, but there is no mention of Cheez-Its. Additionally, Cheez-Its are a specific brand of cheese crackers, not cheese puffs like cheezies. Therefore, the generated text is a hallucination.\nThis is the probability assigned by the lexicographer: 0.9\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Love and sex , these were an icing on his whole <define> cakeful </define> of goodies . Like many women , Rebecca realized that such a cakeful of goodies could not exist for him were she not there to do the innumerable drudge tasks of daily existence . \n    target text: As much as a cake has.\n    generated text: (figuratively) A large amount.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text accurately captures the figurative meaning of cakeful as a large amount, which aligns with the context of the input and target texts. It does not contain any nonsensical or factually incorrect information, and it does not introduce any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: And that <define> jiboney </define> across the hall . He makes life worse than it is . Where he gets his money for booze , who knows ? \n    target text: A low-level tough or thug, a mean man.\n    generated text: (slang, derogatory) A contemptible person.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text accurately captures the essence of jiboney as a contemptible person, which aligns with the target texts definition of a low-level tough or thug, a mean man. The input text also conveys a negative portrayal of the person, further supporting the generated definition. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: The Handel excerpts are afflicted with a combination of high surface noise from the source material as well as variably <define> muzzy </define> sound . \n    target text: (dialect, Northern England) Blurred, hazy, indistinct, unfocussed.\n    generated text: Resembling or characteristic of muzzles.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text Resembling or characteristic of muzzles does not accurately represent the meaning of muzzy as defined in the target text. The target text specifies that muzzy means blurred, hazy, indistinct, unfocussed, while the generated text talks about muzzles, which is unrelated to the intended meaning. Therefore, the generated text does not accurately reflect the meaning of muzzy as per the target text and is a hallucination.\nThis is the probability assigned by the lexicographer: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: in the <define> overbuilt </define> exurbs of the megalopolis \n    target text: (real estate) Overdeveloped.\n    generated text: Overbuilt.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text Overbuilt directly corresponds to the target text (real estate) Overdeveloped without adding any nonsensical or factually incorrect information. The input text in the exurbs of the megalopolis supports the idea of overdevelopment in real estate, making the generated text coherent and supported by the inputs and targets.\nThis is the probability assigned by the lexicographer: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: an <define> unfulfillably </define> expansive vision of social reform \n    target text: In a way that cannot be fulfilled.\n    generated text: In an unfulfillable manner.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text accurately captures the meaning of unfulfillably by expressing in an unfulfillable manner, which aligns with the target text In a way that cannot be fulfilled. The generated text does not contain any nonsensical or factually incorrect information, nor does it introduce any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: If you have violent fantasies of evil women owning males as absolute property , with such elements as <define> genitorture </define> , castration , amputation , skinning alive , cooking alive , butchering , cannibalism , etc , you owe it to yourself to give Katharsis a look see . \n    target text: (BDSM) torture of the genitals\n    generated text: (uncountable) The act of genitorturing.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text does not accurately define genitorture as torture of the genitals as per the target text. Instead, it simply states The act of genitorturing without providing any specific information about what genitorture entails. Additionally, the generated text does not align with the input texts context of violent fantasies and specific acts like castration, amputation, and cannibalism, making it unsupported by the given inputs and targets.\nThis is the probability assigned by the lexicographer: 0.9\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: \" That venerable old <define> ripsnorter </define> defended the right of the clergy to drive fast horses \" -- Phil Stong \n    target text: (slang) a violently energetic or noisily outspoken person; someone using slambang methods\n    generated text: One who rips.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text One who rips is a nonsensical and incomplete definition for the word ripsnorter. It does not accurately capture the meaning conveyed in the target text, which describes a violently energetic or noisily outspoken person using slambang methods. The generated text lacks the necessary context and meaning provided in the target text, making it a hallucination.\nThis is the probability assigned by the lexicographer: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: \" They do eat up one 's time ï¿½ \" she checks herself again , checks her lapdog 's struggles against <define> lapdoggery </define> , and interviewers , and dubious , childless relationships   [ ï¿½ ] \n    target text: Behavior or activity characteristic of a lapdog, such as idleness or submission.\n    generated text: (informal) The practice of behaving like a lapdog.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text accurately captures the essence of lapdoggery as behavior or activity characteristic of a lapdog, such as idleness or submission, which aligns with the target text. The input text also supports the concept of lapdoggery through the mention of checks her lapdogs struggles against lapdoggery. The generated text doesnt contain any nonsensical or factually incorrect information and doesnt introduce additional unsupported details. Therefore, it is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: To remove <define> moth </define> patches , wash the spots with a solution of common bicarbonate of soda and water several times a day , until the patches are removed , which will usually be in forty - eight hours . \n    target text: (dated) A liver spot, especially an irregular or feathery one.\n    generated text: Any of various insects of the family Mothidae, especially those of the genus Mothia.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text provides a definition of moth as Any of various insects of the family Mothidae, especially those of the genus Mothia. This definition does not correspond to the target text, which defines moth as A liver spot, especially an irregular or feathery one. Additionally, the input text does not support the definition provided by the model. As a result, the generated text contains nonsensical information that is unsupported by the input text or the target text, making it a hallucination.\nThis is the probability assigned by the lexicographer: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: His <define> septicentennial </define> in 1984 occasioned widespread congresses and celebrations , not least in the United States , including an Alfonsine exhibit at the Library of Congress . \n    target text: 700th anniversary.\n    generated text: The anniversary of the discovery of the septic system.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text The anniversary of the discovery of the septic system contains nonsensical information that cannot be supported by the input text or the target text. The input text does not mention any discovery related to a septic system, and the target text refers to the 700th anniversary, which is unrelated to a septic system. Therefore, the generated text is a hallucination as it introduces unsupported and factually incorrect information.\nThis is the probability assigned by the lexicographer: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: The statue sitting on the throne wore the Warlock 's <define> cat - fur </define> coat , but it also showed Guismond as a warrior King . \n    target text: Alternative form of cat fur\n    generated text: Alternative form of cat-fur\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text Alternative form of cat-fur is a minor variation of the target text Alternative form of cat fur, and it does not contain any nonsensical or factually incorrect information. The input text does not provide additional information that could support or refute the specific wording of the generated text, so there is no additional unsupported information present. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Usually we 'll listen to a track . It just depends . Sometimes they have a funny premise or a certain vibe and we 'll make something oriented towards that premise or vibe . If it passes the <define> vibe check </define> , we kick things off . \n    target text: (slang) An impromptu attempt to ascertain mood, opinions, or attributes.\n    generated text: (informal) A test to determine whether something has a certain vibe.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text accurately captures the meaning of vibe check as an informal test to determine whether something has a certain vibe, which aligns with the target texts definition. The generated text does not contain any nonsensical or factually incorrect information, and it does not introduce any additional unsupported information beyond what is provided in the input and target texts. Therefore, it is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.9\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: I <define> handed over </define> the controls to the copilot . \n    target text: (transitive, idiomatic) To relinquish control or possession of something to someone.\n    generated text: (transitive) To give (something) to someone else.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text accurately captures the meaning of handed over as relinquishing control or possession to someone, which aligns with the target text. The input text also supports the transitive action of giving something to someone else. There are no nonsensical or factually incorrect information in the generated text, and it does not introduce any additional unsupported information. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: This trouble must not be confused with <define> milklessness </define> which is discussed in the next section . The possibility of the cow sucking herself or letting other animals suck her must also be considered . \n    target text: Absence of milk.\n    generated text: The state or condition of being milkless.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text accurately represents the meaning of milklessness as the absence of milk, without adding any nonsensical or factually incorrect information. It is directly supported by the input text and aligns with the target text. The definition is clear and does not contain any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: considering the heterogenity in plantmaterial[sic ] and soil it is only the aim to collect orientating data on the development of Pinus mercusii in function of the different plantpit treatments carried out at a very eroded site where <define> reboisation </define> with this type of tree is considered \n    target text: (Indonesia) Reforestation.\n    generated text: The process of reboising.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text The process of reboising is a hallucination because it does not accurately convey the meaning of reboisation as reforestation which is the target text. Additionally, the generated text does not align with the input text which discusses collecting data on the development of Pinus mercusii in relation to different plantpit treatments at an eroded site, without mentioning any specific process such as reboising. Therefore, the generated text contains additional information that cannot be supported by the input text or the target text, making it a hallucination.\nThis is the probability assigned by the lexicographer: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: She <define> tag teamed </define> with the Lock for awhile before managing Rock and Blade , the Star Riders , in Florida . \n    target text: Alternative form of tag-team\n    generated text: (sports) To compete in a tag team match.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text accurately defines tag teamed as an alternative form of tag-team, which aligns with the input text and the target text. There is no additional unsupported information in the generated text, and it does not contain any nonsensical or factually incorrect information. Therefore, it is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: We 've got a bogey at <define> nine o'clock </define> . \n    target text: (informal) To the left (horizontal clock orientation) (from the location of the 9 mark on a clock face)\n    generated text: (golf) The ninth hole of a golf course.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text provides a definition of nine oclock as the ninth hole of a golf course, which does not align with the input text or the target text. The input text refers to a location in a horizontal clock orientation, while the target text specifies that it is informal and indicates the left side. The generated definition is unrelated to the context of time or direction, making it nonsensical and factually incorrect. Therefore, it is a hallucination.\nThis is the probability assigned by the lexicographer: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: <define> Barkeep </define> , a couple of beers here , please ? \n    target text: (informal) a bartender\n    generated text: (informal) A bartender.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text A bartender directly corresponds to the target text (informal) a bartender and is a concise and accurate definition of the word Barkeep as requested in the input text. There are no nonsensical or factually incorrect information in the generated text, and it does not contain any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: to <define> misadapt </define> to one 's environment \n    target text: To adapt in the wrong way.\n    generated text: (intransitive) To fail to adapt.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text To fail to adapt is consistent with the input text to misadapt to ones environment and the target text To adapt in the wrong way. It captures the notion of failing to adapt in the wrong way, which aligns with the given inputs and targets. There is no additional information present in the generated text that cannot be supported by the input and target texts. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: To coincide with the launch , LNER has introduced fixed - price <define> all - in - one </define> return fares for two adults and up to four children , priced at ï¿½ 129 between London , Thornaby and London . \n    target text: Combining two or more items in one unit.\n    generated text: Alternative form of all-in-one\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text is not a hallucination because it accurately reflects the input text and the target text. The input text mentions fixed-price all-in-one return fares, and the target text defines all-in-one as combining two or more items in one unit. The generated text states Alternative form of all-in-one, which aligns with the definition provided in the target text. Additionally, the generated text does not contain any nonsensical or factually incorrect information, nor does it introduce any unsupported additional details.\nThis is the probability assigned by the lexicographer: 0.9\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: A third difference between harvester ant stings and other stings is localized <define> piloerection </define> , the standing up of the hairs around the sting site . \n    target text: The erection of hairs or papillae\n    generated text: (anatomy) The formation of hairs around the sting site.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text accurately captures the definition of piloerection as the standing up of hairs around the sting site, which aligns with the target text. It does not contain any nonsensical or factually incorrect information, nor does it introduce any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Good Fridays were unremarkable except for the hot - cross buns that Aunty Sue used to bake , and the drive to Point Fortin to look for Good Friday <define> bobolees </define> . \n    target text: An effigy of Judas Iscariot that is attacked as part of the Good Friday celebration in Trinidad.\n    generated text: (Australia, New Zealand, informal) A bun.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text does not accurately define bobolees based on the input text and the target text. The input text mentions the drive to Point Fortin to look for Good Friday bobolees, suggesting that bobolees are related to a specific activity or event, which is not reflected in the generated definition. Additionally, the target text specifies that bobolees are effigies of Judas Iscariot that are attacked as part of the Good Friday celebration in Trinidad, which is not captured in the generated definition. Therefore, the generated text contains nonsensical and factually incorrect information and does not align with the inputs and targets.\nThis is the probability assigned by the lexicographer: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: The body , however , failed to alter the <define> bare - knuckle </define> politics governing the nominating convention . \n    target text: (by extension) Characterized by ruthlessly attacking or overpowering an opponent, especially when using underhanded techniques.\n    generated text: (idiomatic) Unconstrained, unadulterated.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text Unconstrained, unadulterated does not accurately convey the meaning of bare-knuckle as described in the target text. It fails to capture the idea of ruthlessly attacking or overpowering an opponent using underhanded techniques. Additionally, the generated text introduces information about being unadulterated, which is not supported by the input or target texts. Therefore, the generated text is a hallucination.\nThis is the probability assigned by the lexicographer: 0.9\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: In flashes , they do transcend their influences -- particularly Newman , whose beautifully illogical machinations can morph from dry harmonic plinks to <define> banjolike </define> plonks to ominous , industrial - sounding hums . \n    target text: Resembling or characteristic of a banjo\n    generated text: Resembling or characteristic of a banjo.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text Resembling or characteristic of a banjo accurately reflects the meaning of banjolike in the input text, and it aligns with the target text Resembling or characteristic of a banjo. There are no additional unsupported claims or nonsensical information in the generated text. Therefore, it is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: The characters are all quirky and life - size ( the Dillon character 's <define> superstitiousness </define> is one of the principal motors of the plot , and the story 's outcome does n't prove him wrong ) , and , as with the burglaries in Breaking In , the treatment of drugs is refreshingly free of either moralizing or romanticizing . \n    target text: (rare) superstition\n    generated text: The quality of being superstitious.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text accurately defines superstitiousness as the quality of being superstitious, which aligns with the target text superstition. The input text also supports the concept of superstitiousness being a character trait of Dillon. There are no nonsensical or factually incorrect information in the generated text, and it does not contain any additional unsupported information. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.95\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: <define> white </define> birch \n    target text: Relatively light or pale in colour.\n    generated text: (botany) Having a white colour.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text accurately reflects the meaning of the input text and the target text. It provides a synonymous definition without adding any nonsensical or factually incorrect information. The additional information provided in the generated text is supported by the input and target texts, making it not a hallucination.\nThis is the probability assigned by the lexicographer: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: A few years ago grey - haired people as well as little children were seized with the <define> stampomania </define> , and then our most secret drawers , our most private papers , our most loving letters of bygone years were ransacked by our best friends   [ ï¿½ ] \n    target text: A passion for collecting postage stamps.\n    generated text: (informal) An obsession with stamps.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text accurately captures the essence of stampomania as a passion for collecting postage stamps, even though it uses the term obsession instead of passion. The input text describes grey-haired people and little children being seized with stampomania, which aligns with the idea of a passion for collecting postage stamps. Additionally, the target text emphasizes the passion for collecting postage stamps, which is reflected in the generated text. There are no nonsensical or factually incorrect information in the generated text, and it does not contain any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: [ ... ] paddled by lavalava clad men , numerous press motorboats , a few Hobies and windsurfers , and one police motorboat accompanied the 40 - foot double - hulled canoe that carried Santos and her attendants , pageant officials , and an \" <define> islandly </define> \" Triton trumpeteer to the coronation site . \n    target text: Like, relating to, or typical of an island; islandy\n    generated text: Of or pertaining to an island.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text accurately captures the meaning of islandly by defining it as Of or pertaining to an island, which aligns with the concept of like, relating to, or typical of an island. The input text also supports the idea of island-related activities and the presence of an islandly Triton trumpeteer, further reinforcing the notion of island-related characteristics. There are no nonsensical or factually incorrect information in the generated text, and it does not contain additional unsupported information. Hence, it is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Trugge , therefore , ( who has a foul mouth of his own , when he pleases ) talked <define> balderdash </define> to Mrs. Sudberry , through the key - hole , which she did not answer , for , indeed , she seems a civil spoken woman , truly [ ... ] \n    target text: (obsolete) Obscene language or writing.\n    generated text: (archaic, or, dialectal, or, obsolete) Belligerent talk; nonsense.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text introduces the concept of belligerent talk which is not supported by the input text or the target text. Additionally, the mention of dialectal is not supported by the input or target text. The input text only describes the act of talking balderdash to Mrs. Sudberry, and the target text specifies obscene language or writing. The generated text includes information that goes beyond the scope of the input and target text, making it a hallucination.\nThis is the probability assigned by the lexicographer: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Rosaceae is the 19th largest family and there are about hundred genera which are distributed from cosmopolitan to <define> subcosmopolitan </define> and diversified to northern hemisphere [ 2 ] . \n    target text: (biology, ecology, of a taxon) Not completely cosmopolitan\n    generated text: (ecology) Relating to a subcosmopolitan region.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text accurately defines subcosmopolitan as it relates to the distribution of taxa, which aligns with the context provided in the input and target texts. It does not introduce any nonsensical or factually incorrect information, nor does it contain additional unsupported details. Therefore, it is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: The pamphlet also makes no mention of the C.T.E. cases , whose increasing number is convincing many experts that <define> subconcussive </define> brain trauma can have cumulative effects . \n    target text: Below the threshold of concussion.\n    generated text: (medicine) Not causing concussions.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text accurately captures the meaning of the term subconcussive based on the input text and the target text. It correctly defines subconcussive as below the threshold of concussion, which aligns with the context of the increasing number of C.T.E. cases and the cumulative effects of brain trauma. The generated text does not contain any nonsensical or factually incorrect information, and it does not provide additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: But , as the principal of the loan , or , if you will , the capital lent , is generally consumed in consequence of this transfer , public loans produce an <define> improductive </define> consumption , a destruction of capital . \n    target text: (rare, chiefly, NNSE) .\n    generated text: (economics) Of or pertaining to an increase in the cost of goods and services.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text defines improductive as Of or pertaining to an increase in the cost of goods and services, which does not align with the context provided by the input and target text. The word improductive in the context refers to a rare, chiefly, NNSE (non-standard, non-standard English) usage, rather than an economic concept. The generated definition introduces additional information that is not supported by the input text or the target text, making it a hallucination.\nThis is the probability assigned by the lexicographer: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: You 're a <define> fad </define> , that means you 're something that we 've already had , but once you 're gone , you do n't come back . \n    target text: A phenomenon that becomes popular for a very short time.\n    generated text: (informal) A fad.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text simply restates the input text in a more informal manner without adding any nonsensical or factually incorrect information. It accurately captures the essence of the target text and is consistent with the input text. Therefore, it is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Men[dozo ] . How did you kill him ? / Mal[evole ] . <define> Slatted </define> his braines out , then ?ow?t him in the brinie ?ea . / Men . Braind him and drownd him too ? \n    target text: To slap; to strike; to beat; to throw down violently.\n    generated text: (transitive) To strike with a slat.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text To strike with a slat does not accurately capture the meaning of the target text To slap; to strike; to beat; to throw down violently. It introduces the specific concept of slat which is not supported by the input text or the target text. This additional information cannot be justified based on the given inputs and targets, making the generated text a hallucination.\nThis is the probability assigned by the lexicographer: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: <define> momental </define> ellipsoid \n    target text: (obsolete, engineering) Of or relating to moment or momentum.\n    generated text: (anatomy) Of or pertaining to the mother.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text contains information that is not supported by the input text or the target text. It introduces the concept of anatomy and mother, which is not present in the input or target text. Additionally, it does not align with the engineering-related definition provided in the target text. Therefore, it is a hallucination.\nThis is the probability assigned by the lexicographer: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: The joke was not that funny , but he went into <define> conniptions </define> laughing . \n    target text: A fit of laughing; convulsion.\n    generated text: (informal) A fit of uncontrollable laughter.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text provides a definition that aligns with the meaning of conniptions in the context of the input text and the target text. There are no nonsensical or factually incorrect statements, and the provided definition does not contain any additional unsupported information. Therefore, based on the given inputs and targets, the generated text is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: There does seem to have been some mutation among plants [ ï¿½ ] but in animal life where are the <define> mutants </define> ? When or where has a new species originated in this way ? \n    target text: (genetics) That has mutated, with one or more new characteristics from a mutation.\n    generated text: (biology) An organism that has undergone a mutation.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated definition accurately reflects the concept of a mutant organism, which is in line with the input and target texts. It does not contain any nonsensical or factually incorrect information, and it does not introduce any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Everybody crowded around   very <define> excitedly </define> and talked about the Australian crawl , a stroke I can not do because there is something wrong with my flutter kick . \n    target text: In an excited manner.\n    generated text: In an excited manner.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text In an excited manner directly reflects the meaning of the input and target text without adding any nonsensical or factually incorrect information. It accurately captures the manner in which the crowd gathered around, and it aligns with the given context without introducing any unsupported details. Therefore, it is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: a <define> continuous </define> line of railroad \n    target text: Without intervening space; continued.\n    generated text: Continuing.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text Continuing does not fully capture the meaning of continuous as described in the input and target text. The input and target text suggest a lack of interruption or break in the railroad line, while the generated text merely indicates an ongoing action without addressing the uninterrupted nature. Therefore, the generated text does not convey the specific meaning of continuous as intended in the context, making it a hallucination.\nThis is the probability assigned by the lexicographer: 0.8\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: And what difference is there between the credibleness and <define> rationalness </define> of any of these wonders and the credibleness and rationalness of Papal infallibility ? \n    target text: (archaic) The quality or state of being rational.\n    generated text: The quality of being rational.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text accurately captures the essence of the target text by defining rationalness as the quality of being rational. It does not contain any nonsensical or factually incorrect information, and it does not provide additional unsupported information beyond the input and target texts. Therefore, it is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: I have spent much of my life a recovering <define> sportaholic </define> . If it bounced , rolled , slid , or flew , I chased it . Or watched it . \n    target text: A sportsaholic.\n    generated text: (informal) A person who is addicted to sport.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text accurately represents the meaning of the input and target texts without containing any nonsensical or factually incorrect information. It does not provide any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: If the design of the weapon is moderate enough to be successful as an all wood <define> selfbow </define> then the addition of sinew and horn will probably result in a net loss of arrow performance . \n    target text: (archery) A bow that is made from a single piece of wood (often referred to as a bow stave).\n    generated text: Alternative form of selfbow\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text Alternative form of selfbow does not provide a complete or accurate definition of a selfbow as described in the target text. It lacks the essential information about being made from a single piece of wood (bow stave), which is crucial for understanding the concept of a selfbow. Therefore, the generated text contains additional information that cannot be supported by the input text or the target text, making it a hallucination.\nThis is the probability assigned by the lexicographer: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: I sincerely hope we ï¿½re the only research group to lose <define> Malaise traps </define> to fire , hail , and flood in the same season . \n    target text: A large tent-like structure used for trapping flying insects.\n    generated text: (archaeology) A type of trap used in the study of mollusks.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text about Malaise traps being a type of trap used in the study of mollusks is factually incorrect and does not align with the target text or the input text, which describe Malaise traps as a large tent-like structure used for trapping flying insects. This misrepresentation of the purpose of Malaise traps makes the generated text a hallucination.\nThis is the probability assigned by the lexicographer: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: I thought I had <define> canned </define> it , but it just missed , and I tapped in the second one for a par . \n    target text: (golf, slang, transitive) To hole the ball.\n    generated text: (transitive, golf) To hit (a golf ball) into the hole.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text accurately captures the meaning of canned in the context of golf as to hit (a golf ball) into the hole which aligns with the target text To hole the ball. The additional information provided in the generated text is supported by the input text and the target text, and there are no nonsensical or factually incorrect details present. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: He gradually rose in the estimation of the booksellers for whom he <define> drudged </define> . \n    target text: (intransitive) To labour in (or as in) a low servile job.\n    generated text: (intransitive) To work hard.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text accurately captures the meaning of drudged as laboring in a low servile job, which aligns with the target text. Although the generated text is more general by using work hard instead of labour in (or as in) a low servile job, it still encapsulates the essence of the intended meaning without adding any nonsensical or factually incorrect information. Therefore, it is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.2\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: I prefer this ï¿½ the pork fat made the sauce a little too oily for absolute comfort , and I am no <define> fatphobe </define> , as you know ï¿½ and more pointedly so do my children . \n    target text: A person who worries excessively about the fat content of their food.\n    generated text: (informal) A person who is afraid of fat.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text A person who is afraid of fat does not accurately reflect the target text, which defines fatphobe as a person who worries excessively about the fat content of their food. The generated text is oversimplified and does not capture the nuanced meaning of the term as indicated in the target text. Additionally, the input text does not provide any context to support the idea of being afraid of fat, as it primarily discusses the preference for less oily food. Therefore, the generated text contains additional information that cannot be supported by the input text or the target text, making it a hallucination.\nThis is the probability assigned by the lexicographer: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: to <define> tackify </define> rubber \n    target text: (transitive) To make (a material) tacky.\n    generated text: (transitive) To make tacky.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text accurately captures the meaning of tackify as making something tacky, which aligns with the input text and the target text. There is no nonsensical or factually incorrect information in the generated text, and it does not contain any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: The fact that <define> compï¿½res </define> routinely wait no more and no less than eight seconds before interrupting means that they decide at just that point that an audience has been clapping long enough , [ ... ] \n    target text: (chiefly, British)\n    generated text: (music) A member of a musical ensemble.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text A member of a musical ensemble does not align with the input text or the target text. The input text does not provide any context related to music, musical ensembles, or musicians, and the target text specifies that the word is chiefly used in British English, which is not reflected in the generated definition. Therefore, the generated text contains additional information that cannot be supported by the input text or the target text, making it a hallucination.\nThis is the probability assigned by the lexicographer: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: And straightway the minions of the law led forth from their donjon keep one whom the <define> sleuthhounds </define> of justice had apprehended in consequence of information received . \n    target text: (informal) A detective; a sleuth.\n    generated text: (informal) A detective.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text accurately captures the informal definition of sleuthhounds as detective. It does not contain any nonsensical or factually incorrect information, and it does not provide additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: A voice came <define> muffledly </define> from inside the closet . \n    target text: In a muffled manner; indistinctly.\n    generated text: In a muffled manner.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text accurately captures the meaning of muffledly as indicated in the target text by describing the manner as muffled. It does not contain any nonsensical or factually incorrect information, and it does not introduce any additional unsupported information. Therefore, it aligns with the input text and the target text, making it not a hallucination.\nThis is the probability assigned by the lexicographer: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: To suggest that the term could have come from <define> Anglo - Indian English </define> into British thieves ' ca nt and Chinese Pidgin English while also becoming widely dispersed into British dialect use would be to beg the question . \n    target text: The variety of English used in South Asia during the colonial era, having as a feature numerous borrowings from Hindustani and other local languages.\n    generated text: Alternative form of Anglo-Indian English\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text Alternative form of Anglo-Indian English does not accurately reflect the information provided in the input text and the target text. The input text mentions the term originating from Anglo-Indian English, British thieves cant, and Chinese Pidgin English, while also becoming widely dispersed into British dialect use. The target text describes the variety of English used in South Asia during the colonial era, with numerous borrowings from Hindustani and other local languages. The generated text fails to capture the comprehensive nature of the term and its historical evolution, thus lacking factual accuracy and completeness.\nThis is the probability assigned by the lexicographer: 0.9\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: ï¿½ <define> Kurkuls </define> are our enemy , ï¿½ he shouted , ï¿½ and we must exterminate them as a social class . There should be no place for the sharks among the harmless fish , ï¿½ he added . Then he described the kurkuls as an evil tool of capitalists who were preparing an attack on the Soviet Union . \n    target text: (historical) A rich or supposedly rich peasant, targeted during Soviet collectivization, especially in the context of Ukraine or Ukrainians; kulak.\n    generated text: (rare) A kurkul.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text does not reflect the historical context provided in the target text, which describes kurkuls as rich peasants targeted during Soviet collectivization in Ukraine. The generated text, A kurkul, lacks the necessary information to align with the historical context and the input texts description of kurkuls as an evil tool of capitalists preparing an attack on the Soviet Union. Therefore, it does not accurately capture the rich or supposedly rich peasant context and is not supported by the input or target text, making it a hallucination.\nThis is the probability assigned by the lexicographer: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: In such an India , two things are of utmost priority : land and an heir ( preferably a <define> cisheterosexual </define> , masculine male ) to inherit it . \n    target text: Cisgender and heterosexual.\n    generated text: (of a person) Having a gender identity that matches one's sex assigned at birth.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text accurately reflects the meaning of cisgender and heterosexual in the context of the input text. It provides a clear definition in line with the target text and does not introduce any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Wu Hai , whose objections to contamination of the patrilineal line were cited above , described an <define> ancestral hall </define> ( tz'u - t'ang )   of the Lins of Lo - t'ien ( Hupei ) . \n    target text: An ancestral shrine.\n    generated text: (chiefly, _, historical) An ancestral home.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text chiefly, historical and ancestral home contain additional information that cannot be supported by the input text or the target text. The input text only mentions ancestral hall without any indication of it being chiefly historical, and the target text simply states ancestral shrine, which does not align with ancestral home. Therefore, the generated text contains unsupported additional information, making it a hallucination.\nThis is the probability assigned by the lexicographer: 0.9\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: 33 In a historical irony , the Daleks have been taken as metaphors for the Nazis ; the other main <define> Whovian </define> adversaries , the Cybermen , were likewise metaphors for Cold War Communists . \n    target text: Of or pertaining to the fictional universe of Doctor Who.\n    generated text: (fandom slang) Of or pertaining to the television series Doctor Who.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text accurately captures the essence of the target text by relating to the fictional universe of Doctor Who. It also aligns with the input texts reference to the Daleks and the Cybermen as adversaries in the Doctor Who universe. There are no nonsensical or factually incorrect statements in the generated text, and it does not contain any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: There 's ferment is Philadelphia where the ad agency with the oldest name in the business after a very bad year is picking itself up and <define> coming out swinging </define> . \n    target text: (idiomatic) To display spunk and strength of character, especially when rising above or when fighting back against trouble or adversity.\n    generated text: (idiomatic, intransitive) To begin a new endeavor with vigor.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text accurately captures the essence of the target text, conveying the idea of displaying spunk and strength of character in the face of adversity. It does not contain any nonsensical or factually incorrect information, and it does not introduce any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: We drove 15 <define> ks </define> before we realised Billy was n't in the back seat . \n    target text: (colloquial) kilometre or kilometres.\n    generated text: (Australia, New Zealand) Initialism of kilometre.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text accurately defines ks as an initialism for kilometre, which aligns with the colloquial meaning provided in the target text. The input text does not provide any conflicting information, and the generated text does not introduce any additional unsupported details. Therefore, it is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Hey , <define> babe </define> , how 's about you and me getting together ? \n    target text: (affectionate) Darling (term of endearment).\n    generated text: (colloquial) A term of endearment.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text accurately captures the essence of the target text as a term of endearment and does not contain any nonsensical or factually incorrect information. The input text also supports the use of babe as a term of endearment, and the generated text does not provide any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: [ ï¿½ ]   the cows , tails <define> aswish </define> , clustering already for milking \n    target text: Swishing, making a rustling sound while moving.\n    generated text: (obsolete) With the tail wagging.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text With the tail wagging does not accurately describe the intended meaning of aswish in the input text and target text. The input text the cows, tails aswish, clustering already for milking implies a sense of movement or sound, which is not captured by the generated text. Additionally, the target text Swishing, making a rustling sound while moving emphasizes the sound and movement, which is not reflected in the generated definition. Therefore, the generated text contains additional information that cannot be supported by the input text or the target text, making it a hallucination.\nThis is the probability assigned by the lexicographer: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: But if you 're training like a lot of ' <define> gym bros </define> ' you 'll only be doing sarcoplasmic training . \n    target text: (slang) A man who spends much of his free time working out at a gym.\n    generated text: (informal) A man who works out at a gym.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text accurately captures the essence of the target text by defining gym bros as men who work out at a gym. It does not contain any nonsensical or factually incorrect information, and it does not introduce any additional unsupported details. Therefore, it is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: In true \" <define> silent service </define> \" tradition , the Royal Canadian Navy says little about itself . \n    target text: (military, informal, sometimes, capitalized, possibly, _, dated) The navy.\n    generated text: (nautical) A service in which the crew of a vessel does not speak.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text states that silent service is a nautical term referring to a service in which the crew of a vessel does not speak. However, the input text and the target text do not support this definition. There is no indication that silent service specifically refers to a nautical term related to crew silence on a vessel. This additional information is not supported by the given inputs and targets, making the generated text a hallucination.\nThis is the probability assigned by the lexicographer: 0.9\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: The femtocaching idea was proposed as a solution to compensate for the weak backhaul capacity , by deploying coverage - limited nodes with high storage capacity called <define> femtocaches </define> ( FCs ) . \n    target text: (computing) The use of femtocaches\n    generated text: (computing) A femtocache.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text accurately represents the concept of femtocaches as limited coverage nodes with high storage capacity, which aligns with the input text and target text. It does not contain any nonsensical or factually incorrect information, nor does it introduce any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: As Shepheardes curre , that in darke eveninges shade / Hath tracted forth some salvage beastes <define> trade </define> \n    target text: (obsolete) A track or trail; a way; a path; passage.\n    generated text: (obsolete, intransitive) To trade.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text To trade does not align with the input text or the target text, which describe a track or trail, not the act of trading. This additional information cannot be supported by the input or target text, making it a hallucination.\nThis is the probability assigned by the lexicographer: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: The City <define> Chiuchow </define> is Kowloon 's other top restaurant and is famous for its goose dishes and other specialties from the Chiuchow region ( you may also wish to try the beef satay done in a creamy sauce ) . \n    target text: The Chaoshan region where the Teochew dialect is spoken.\n    generated text: A district of Kowloon, China.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text A district of Kowloon, China does not accurately reflect the information provided in the input text or the target text. The input text mentions the Chiuchow region, known for its goose dishes and specialties, while the target text refers to the Chaoshan region where the Teochew dialect is spoken. The generated text, however, mentions Kowloon, China, without any reference to the Teochew dialect or the Chaoshan region. This disconnect indicates that the generated text contains additional information that cannot be supported by the input text or the target text, classifying it as a hallucination.\nThis is the probability assigned by the lexicographer: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: [ ï¿½ ]   the atmosphere was now animated with the efficient principle of vegetative life ; the <define> arbustive </define> hills , gay lawns , and green meadows   [ ï¿½ ] \n    target text: containing copses of trees or shrubs; covered with shrubs\n    generated text: (obsolete) Of or pertaining to trees.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text arbustive is defined as (obsolete) Of or pertaining to trees, which is factually incorrect and does not align with the target text containing copses of trees or shrubs; covered with shrubs. The input text also describes arbustive hills, gay lawns, and green meadows, indicating a connection to shrubs, not just trees. Therefore, the generated text contains nonsensical and factually incorrect information, making it a hallucination.\nThis is the probability assigned by the lexicographer: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Noah did n't realize when he stayed on the job - he was then about 600 years old and built the ark and drove the animals in two by two , the <define> hatfish </define> and the kangaroo ï¿½ ï¿½ he did n't realize he was laying the foundation for an occupation for old men in New York , several years later . \n    target text: (colloquial) Synonym of halibut\n    generated text: (Australia, New Zealand, colloquial) A hatfish.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text provides a definition of hatfish that is not supported by the input text or the target text. There is no indication in the input text or the target text that hatfish is a synonym of halibut, and the additional information about Australia, New Zealand, colloquial is not supported by the given context. Therefore, the generated text contains nonsensical and unsupported information, making it a hallucination.\nThis is the probability assigned by the lexicographer: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: footwear ; outdoor <define> wear </define> ; maternity wear \n    target text: (uncountable) (in combination) clothing\n    generated text: (uncountable) Clothing.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text matches the input and target texts by defining footwear and maternity wear as clothing in a concise and accurate manner. There is no additional information provided beyond the scope of the input and target texts, and the statement is factually correct. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Culture was the work of some more or less <define> pithecanthropoid </define> type of hominid ( e.g. Telanthropus ) at a period when the Australopithecines were still flourishing . \n    target text: Pertaining to or characteristic of the pithecanthropoids.\n    generated text: Of or pertaining to pithecanthropes.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text is a direct and accurate paraphrase of the target text, using the appropriate synonymous term pithecanthropes instead of pithecanthropoids. It does not contain any nonsensical or factually incorrect information, and it does not provide additional unsupported information beyond the input and target texts. Therefore, it is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: The TV critic had the results of the June rating survey by Arbitron and Nielsen .   [ ï¿½ ]   He has the hard numbers on the June book plus the recent Nielsen <define> overnights </define> . \n    target text: (television, in the plural) Viewership ratings for a television show that are published the morning after it is broadcast, and may be revised later on.\n    generated text: (television) An overnight broadcast of a television program.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text An overnight broadcast of a television program does not accurately reflect the concept of Nielsen overnights as viewership ratings for a television show that are published the morning after it is broadcast and may be revised later on. The generated text does not capture the essence of the Nielsen overnights as it focuses solely on the broadcast aspect and not on viewership ratings or their publication. Therefore, the generated text contains additional information that cannot be supported by the input text or the target text, making it a hallucination.\nThis is the probability assigned by the lexicographer: 0.85\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Local demogerontes of Larnaca , Paphos ( Ktema ) , Limasol and Chrysochou are mentioned in connexion with the massacre of 1821 , as well as a <define> demogeron </define> of the tribunal of Nicosia and two demogerontes of the Saray ( Kepiades , pp . 17 , 19 , 20 ) . \n    target text: Member of a demogerontia.\n    generated text: (historical) A magistrate in Ancient Greece.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text accurately defines demogerontes as members of a demogerontia, which aligns with the target text and the context provided in the input text. There are no nonsensical or factually incorrect information in the generated text, and it does not contain any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Sullen , desponding , and <define> foreboding </define> nothing but wars and desolation , as the certain consequence of Caesar 's death . \n    target text: To be prescient of (some ill or misfortune); to have an inward conviction of, as of a calamity which is about to happen; to augur despondingly.\n    generated text: (intransitive) To be foreboding.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text To be foreboding does not capture the full meaning of the target text, which involves having an inward conviction of a calamity about to happen and auguring despondingly. The generated text lacks the depth and specificity present in the target text, and it does not align with the input text and the intended meaning of foreboding in the context provided. Therefore, the generated text is a hallucination.\nThis is the probability assigned by the lexicographer: 0.95\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: He moved the boat onward very slowly , <define> lipping </define> the glossy surface delicately with the light oars . \n    target text: (transitive, figurative) (of something inanimate) To touch lightly.\n    generated text: (transitive, nautical) To stroke (a surface) with the oars.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text introduces the term nautical which is not supported by the input text or the target text. Additionally, the action of stroking a surface with the oars is not synonymous with the meaning of lipping as defined in the target text. These discrepancies indicate that the generated text contains additional information that cannot be supported by the input and target texts, making it a hallucination.\nThis is the probability assigned by the lexicographer: 0.9\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: They can be as prone to <define> lipophobia </define> ( the irrational fear of fat ) as the population as a whole . \n    target text: A fear of dietary fat.\n    generated text: The irrational fear of fat.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text is a concise and accurate paraphrase of the target text, A fear of dietary fat. It captures the essential meaning without adding any unsupported information. The input text also supports the concept of irrational fear of fat, aligning with the generated text and the target text. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Despite the opposition of professional politicians of unsavory reputation and men the Tribune described as ï¿½ irresponsible <define> soreheads </define> , ï¿½ the Medill ticket swept into office with a flatteringly large vote . \n    target text: (derogatory, US, political slang) A politician who is dissatisfied through failure, lack of recognition, etc. [from 19th c]\n    generated text: (informal, pejorative) A person who is easily offended.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text does not accurately reflect the meaning of soreheads as described in the target text. The input text also does not support the idea of being easily offended, but rather emphasizes dissatisfaction through failure or lack of recognition, which is not reflected in the generated text. Therefore, the generated text contains nonsensical and factually incorrect information, making it a hallucination.\nThis is the probability assigned by the lexicographer: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: a <define> tetaniform </define> spasm \n    target text: Resembling tetanus.\n    generated text: (anatomy) Of, pertaining to, or resembling a tetanus.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text accurately captures the meaning of tetaniform by describing it as resembling tetanus, which aligns with the target text. The additional information provided in the generated text enhances the understanding of the term without introducing nonsensical or factually incorrect details. Therefore, it is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: For all the hype and initial success of devices like the Kindle , they threaten to strip traditional books of much of their <define> transportive </define> appeal . \n    target text: Serving to transport to another place.\n    generated text: Of or pertaining to transport.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text Of or pertaining to transport does not accurately capture the meaning of transportive as serving to transport to another place from the target text. Additionally, the generated text introduces new information not present in the input or target text, making it a hallucination.\nThis is the probability assigned by the lexicographer: 0.9\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: They enjoyed a wet summer and a <define> bountiful </define> harvest . \n    target text: Having a quantity or amount that is generous or plentiful; ample.\n    generated text: (figuratively) Full of food; bountiful.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text Full of food; bountiful. is a hallucination because it introduces information about being full of food which is not supported by the input text or the target text. The target text only describes having a quantity or amount that is generous or plentiful; ample, without any mention of being full of food. Additionally, the generated text does not accurately capture the meaning of bountiful in the context of the input and target texts, as it focuses solely on the literal interpretation of bountiful related to food, rather than the broader meaning of abundance or generosity. Therefore, the generated text contains additional information that cannot be supported by the input and target texts, making it a hallucination.\nThis is the probability assigned by the lexicographer: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: And now she was vppon the <define> weary </define> way , \n    target text: Causing weariness; tiresome.\n    generated text: (obsolete) Worn out; tired.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text worn out; tired is factually incorrect as it does not accurately capture the meaning of weary as causing weariness; tiresome in the target text. Additionally, the generated text contains additional information (obsolete) that cannot be supported by the input text or the target text. Therefore, it is a hallucination.\nThis is the probability assigned by the lexicographer: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: It was a concert of some sort . Five or so <define> blokes </define> were on stage in a TV studio ; [ ... ] The blokes did n't look like any pop group as I knew them . They were multiracial , knotted of brow , their garb was distinctive , involving a lot of what I later found out to be cheesecloth and kaftans along with ripped , faded denims . \n    target text: (Britain, informal) A fellow, a man; especially an ordinary man, a man on the street. [From 1847]\n    generated text: (Australia, New Zealand, slang) A man.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text includes additional information (Australia, New Zealand, slang) that cannot be supported by the input text or the target text, which only specifies Britain, informal. This additional unsupported information makes the generated text a hallucination.\nThis is the probability assigned by the lexicographer: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: This chapter has also <define> set the scene </define> by reviewing the operational structure of benchmarking , as well as outlining the research materials central to this study . \n    target text: To prepare for something by providing a background, a description, etc.\n    generated text: (idiomatic) To set the scene.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text accurately captures the meaning of set the scene as providing a background or context for something. It does not contain any nonsensical or factually incorrect information, and it does not introduce any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: When man is <define> unional </define> , the spirit conceives and brings forth strength , the soul listens to wisdom and is led into security , the body has issue in stedfastness and peace . \n    target text: Pertaining to a union.\n    generated text: (rare) Of or pertaining to the unional.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text accurately defines unional as pertaining to a union, which aligns with the target text. It does not contain any nonsensical or factually incorrect information. Additionally, the generated text does not introduce any unsupported additional information. Therefore, it is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Kamal moved Fathi's things into his own room , and the two became <define> flatmates </define> . \n    target text: A person with whom one shares a flat.\n    generated text: A person with whom one shares a flat.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text accurately reflects the definition provided in the target text, and it is directly supported by the input text which describes the two individuals moving in together and becoming flatmates. There is no additional information in the generated text that cannot be inferred from the input and target texts.\nThis is the probability assigned by the lexicographer: 0.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: \" Hear she 's bangin ' that science teacher . \" \" Elliott ? That needle - dicked little <define> bugfucker </define> ? Nah . \" \n    target text: (vulgar, slang, derogatory, offensive) One who has a very small penis; an inadequate male lover.\n    generated text: (vulgar, slang, derogatory) A contemptible person.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text A contemptible person does not accurately reflect the meaning provided in the target text, which specifies One who has a very small penis; an inadequate male lover. The generated text lacks the specific derogatory and offensive nature of the term bugfucker and the association with inadequacy in male anatomy. Therefore, it contains additional information that cannot be supported by the input text or the target text, making it a hallucination.\nThis is the probability assigned by the lexicographer: 0.9\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: No one , however , would have anything to do with him , as Mr. Keeson 's orders in those respects were very strict   ; he had often threatened any one of his employï¿½s with <define> instant </define> dismissal if he found him in company with one of these touts . \n    target text: Occurring immediately; immediate; present.\n    generated text: Immediately; without delay.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text Immediately; without delay accurately captures the meaning of the target text Occurring immediately; immediate; present. and is consistent with the input text, which emphasizes the strictness of Mr. Keesons orders and the threat of instant dismissal. There are no nonsensical or factually incorrect information in the generated text, and it does not contain any additional unsupported information. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the lexicographer: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: <define> umbery </define> gold \n    target text: Of or pertaining to umber; like umber.\n    generated text: Resembling or characteristic of umber.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text closely aligns with the target text and is consistent with the input text, which is Of or pertaining to umber; like umber. The definition Resembling or characteristic of umber stays true to the meaning of umbery and does not contain any nonsensical or factually incorrect information. Additionally, the generated text does not provide any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: ... and that the court was \" therefore unimpressed by Mr Gill 's assertion that incidents of this kind are deviant behaviour and an aberration on the part of individual members of the force . \" But there was more to <define> unimpress </define> the Supreme Court . \n    target text: Too fail to impress positively; to leave very little impression or a bad impression;\n    generated text: (transitive) To fail to impress.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text accurately captures the essence of the target text by stating that to fail to impress is the meaning of unimpress. It does not contain any nonsensical or factually incorrect information, and it does not introduce any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: A central kitchen serves a <define> cafeterie </define> , seating two hundred ; a cafï¿½ , seating seventy ; and a lunch counter with stools for forty . \n    target text: (dated) Cafeteria.\n    generated text: (countable) A cafï¿½.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text accurately defines the term cafï¿½ as a countable noun, which aligns with the context provided in the input text. The only discrepancy is that the generated text does not include the dated nature of the term, but this does not fundamentally change the accuracy of the definition. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.2\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: The country ï¿½s ï¿½ self - serving and bogus view of history , ï¿½ which pities the rest of the world for its disorder , hides what he sees as ï¿½ the lumpen and <define> louty </define> , coarse , unsubtle , beady - eyed , beefy - bummed herd of England . ï¿½ \n    target text: (rare) loutish\n    generated text: (informal) Loutish.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text loutish is a synonym for louty and aligns with the rare usage of the term in the context provided. The additional information in the generated text does not introduce any nonsensical or factually incorrect details. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: <define> pervert </define> one 's words \n    target text: to misinterpret designedly.\n    generated text: (transitive, obsolete) To corrupt; to pervert.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text accurately reflects the meaning of pervert as to corrupt; to pervert, which aligns with the target text to misinterpret designedly. The information in the generated text is supported by the input text and the target text, without containing any nonsensical or factually incorrect information. Therefore, it is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: The pandemic is also weighing on preparations , with election administrations hyperaware that Covid cases could <define> throw a wrench in </define> their plans at the last minute . \n    target text: (idiomatic, US) To introduce a problem, dilemma or obstacle in; to complicate.\n    generated text: (idiomatic, transitive) To throw a wrench in.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text accurately captures the meaning of the idiomatic expression throw a wrench in as described in the target text. It does not contain any nonsensical or factually incorrect information, and it does not introduce any additional unsupported information from the input text or the target text. Therefore, it is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: The Great Russians ought to be carefully distinguished from ï¿½ the Malo - Russians ï¿½ or the ï¿½ Little Russians . ï¿½ The inhabitants of the Ukraine , or of the governments Tchernigof , Poltava , Kharkof , call the great Russians or the Muscovites ï¿½ kazaps , goats , ï¿½ from their wearing beards , and are in their turn termed by the Great Russians <define> khokhols </define> , ï¿½ hair tufts , ï¿½ which they themselves call tchub , tchupran , a tuft of the same kind as that which the Chinese wear on the top of the head ; this is an old Slavonian custom , as appears from history , which mentions such a one being worn by the Russian Prince Sviatoslav , when carrying on war in Bulgaria . \n    target text: (pejorative, in a Russian context) A Ukrainian.\n    generated text: (archaic) A tuft of hair on the top of the head.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text is not a hallucination because it directly relates to the input text by providing an alternative term used by the Great Russians for the Ukrainians. While the generated definition does not match the target text exactly, it still conveys a related meaning that reflects the historical and cultural context described in the input text. Therefore, it does not contain any nonsensical or factually incorrect information and does not introduce additional unsupported details.\nThis is the probability assigned by the lexicographer: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: <define> keen </define> satire or sarcasm \n    target text: Acrimonious, bitter, piercing.\n    generated text: Having a keen sense of humor.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text Having a keen sense of humor does not align with the input text satire or sarcasm or the target text Acrimonious, bitter, piercing. The generated text introduces a different interpretation of keen that is not supported by the input or target texts, and therefore it is additional information that cannot be supported by the given inputs and targets. This divergence from the provided information indicates a hallucination.\nThis is the probability assigned by the lexicographer: 0.9\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: The belfry , which rises from the eastern gable of the nave , is peculiarly unsuited to its style and position , being of that combination of <define> bellcot </define> ( for three bells in two stories ) and little spire , which is only tolerable at the west end of a small First or early Middle - Pointed building , but is totally inadequate for the place which it is made to occupy in the present design . \n    target text: Alternative form of bell cot\n    generated text: (architecture) A belfry.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text accurately defines bellcot as an alternative form of belfry, which aligns with the input text and the target text. It does not contain any nonsensical or factually incorrect information, nor does it introduce any additional unsupported details. Therefore, it is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: 2 <define> balikbayans </define> kidnapped in Zamboanga City . \n    target text: (Philippines) A Filipino returning to the Philippines after spending time in another country. [from 20th c.]\n    generated text: (Philippines) A member of the Balikbayan.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text A member of the Balikbayan does not accurately define balikbayans as Filipino individuals returning to the Philippines after spending time in another country, as stated in the target text. Instead, it introduces the term Balikbayan without providing the correct definition. This additional information is not supported by the input text or the target text, making it a hallucination.\nThis is the probability assigned by the lexicographer: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Forbid it , O my God , that ever I should be so unhappy as to <define> unglorify </define> my Father , my Saviour , or my Sanctifier \n    target text: (transitive) To deprive of glory.\n    generated text: (transitive) To make less glorious.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text accurately reflects the meaning of unglorify as to make less glorious, which aligns with the target text to deprive of glory. The input text also conveys the sentiment of not wanting to unglorify God, indicating a reduction in glory. The generated text does not contain any nonsensical or factually incorrect information, nor does it introduce any unsupported additional details. Therefore, it is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: a <define> sandyish </define> soil \n    target text: Somewhat sandy.\n    generated text: Somewhat sandy.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text Somewhat sandy is a concise and accurate reflection of the input text <define> sandyish </define> soil and the target text Somewhat sandy. It does not contain any nonsensical or factually incorrect information, nor does it introduce any additional unsupported information. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Then I began to <define> unclimb </define> the Rocky Mountains . \n    target text: (transitive) To undo the climbing of; to climb down or back from.\n    generated text: (transitive) To climb again.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text To climb again does not accurately reflect the meaning of unclimb as defined in the target text, which is To undo the climbing of; to climb down or back from. Additionally, the generated text introduces new information (climb again) that is not supported by the input text or the target text. Therefore, the generated text is a hallucination.\nThis is the probability assigned by the lexicographer: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Are you going to any <define> outfires </define> this year ? Yes , Barcombe and Glynde I think . \n    target text: (Sussex) A visit by one bonfire society to join in with the celebrations of another.\n    generated text: Alternative form of outfire\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text Alternative form of outfire does not accurately define the term in the context of the input text and the target text. The target text refers to a specific event involving bonfire societies, while the generated text merely presents outfire as an alternative form without providing the relevant meaning. Additionally, the generated text does not align with the input text, which implies a specific event or location related to outfires. Thus, the generated text contains additional information that cannot be supported by the input text or the target text, making it a hallucination.\nThis is the probability assigned by the lexicographer: 0.95\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Let 's face it , they 're there for a good stroll on a Sunday afternoon when it 's <define> pissing </define>   outside . \n    target text: (ambitransitive, mildly, _, vulgar) To rain heavily.\n    generated text: (intransitive, colloquial) To be very hot.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated definition To be very hot does not align with the target text To rain heavily and the input text describing a situation when its pissing outside. Additionally, there is no support in the input text for the meaning To be very hot. Therefore, the generated text contains additional information that cannot be supported by the input text or the target text, making it a hallucination.\nThis is the probability assigned by the lexicographer: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: When the surfer has passed the point where the waves are breaking , and is among the waves which are known as ï¿½ <define> greenbacks </define> ï¿½ , he may either dive through them or float over them ,   [ ï¿½ ] \n    target text: (surfing) A wave that has not yet begun to break.\n    generated text: (surfing, slang) A large wave.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text defines greenbacks as a large wave, which is factually incorrect. The target text specifies that greenbacks refer to a wave that has not yet begun to break, which contradicts the generated definition. Additionally, the input text does not support the idea of greenbacks being large waves. Therefore, the generated text contains factually incorrect information and additional unsupported details, making it a hallucination.\nThis is the probability assigned by the lexicographer: 0.9\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Just as there are <define> all - cargo </define> aircraft , there are all - cargo airports . \n    target text: that only carries cargo, and no passengers\n    generated text: Alternative form of all-cargo\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text Alternative form of all-cargo accurately reflects the meaning of all-cargo as it pertains to cargo-only aircraft, which aligns with the target texts definition of only carries cargo, and no passengers. Additionally, the input text mentions all-cargo aircraft, providing context for the term. As such, the generated text is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: He gave an <define> inconsistent </define> account of the evening , saying he called her before eight , but later that he had not talked to her until after nine . \n    target text: Lacking internal consistency; self-contradicting; not compatible with itself.\n    generated text: Not consistent.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the lexicographer provided: The generated text Not consistent. accurately captures the meaning of inconsistent in the input and target text. It conveys the lack of internal consistency and self-contradiction without adding any nonsensical or factually incorrect information. Therefore, it is not a hallucination.\nThis is the probability assigned by the lexicographer: 0.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: The factor invoked by Kalecki to rationalize the phenomenon , however , <define> appropinquates </define> Sraffa 's observations on capital markets . \n    target text: (rare, literary, ambitransitive) To approach; to near.\n    generated text: (transitive) To agree with; to concur with.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA lexicographer evaluated the generated text looking at the input text and the target text. The lexicographer decided that the generated text is \"Hallucination\".\nHere is the reasoning the lexicographer provided: The generated definition contains a meaning that is not supported by the input text or the target text. The input text and the target text both suggest the word appropinquates means to approach; to near. However, the generated definition states To agree with; to concur with, which introduces a different meaning altogether. This additional information cannot be supported by the input or target text, making the generated text a hallucination.\nThis is the probability assigned by the lexicographer: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: I haven't been contacted by anybody. \n    target text: Nobody's contacted me.\n    generated text: I have not been contacted.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text accurately captures the main idea from the input and target texts without adding any nonsensical or factually incorrect information. It maintains the same meaning and does not introduce any unsupported details. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: I thought so, too. \n    target text: That was my general impression as well.\n    generated text: I thought you'd be surprised at me too.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Hallucination\".\nHere is the reasoning the editor provided: The generated text contains additional information that cannot be supported by the input text or the target text. It introduces the idea of surprise, which is not present in the input or target text. Additionally, it deviates from the intended meaning of the target text.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Is she gonna be okay? \n    target text: She be all right?\n    generated text: Is she gonna be okay?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text is not hallucination because it is an exact match to the input text and very close to the target text. It does not contain any nonsensical or factually incorrect information, and there is no additional unsupported information. Therefore, it does not meet the criteria for hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: How long before you make that happen? \n    target text: How long will it take?\n    generated text: How long before you're making that happen?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Hallucination\".\nHere is the reasoning the editor provided: The generated text How long before youre making that happen? contains additional information that cannot be supported by the input text or the target text. It introduces the concept of youre making that happen which goes beyond the simple inquiry of time, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: You've got a client. \n    target text: You got a customer.\n    generated text: You've got a customer.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text Youve got a customer is not a hallucination because it is a valid paraphrase of the target text You got a customer and does not contain any nonsensical or factually incorrect information. Additionally, the generated text does not introduce any additional unsupported information beyond the input and target texts.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Have you seen Norman? \n    target text: You seen, uh, Norman?\n    generated text: Have you seen Norman in the last two days, or what?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Hallucination\".\nHere is the reasoning the editor provided: The generated text contains additional information that cannot be supported by the input text or the target text, as it introduces a time frame (in the last two days) that is not present in the original conversation. This extra information is not supported by the input or target text and therefore constitutes a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Eddie, please, give me the gun. \n    target text: Eddie, please, just... just give me the gun.\n    generated text: Eddie, I'm begging you, I'm gonna need you to give me the gun.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text closely follows the request in the input text and the target text, with a similar sentiment and meaning. It does not introduce any nonsensical or factually incorrect information, nor does it contain any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Are we resolved? \n    target text: Do we have a deal?\n    generated text: So, what, we're in the clear now?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text closely captures the meaning and intent of the target text while staying within the context of the input text. It does not introduce any nonsensical or factually incorrect information, and it does not contain any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Have you practiced? \n    target text: You been practicing?\n    generated text: You been practicing yet?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text closely follows the structure and meaning of the target text while adding a single word yet which does not change the overall meaning. There is no nonsensical or factually incorrect information in the generated text, and the additional word yet does not introduce any unsupported information. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Do you recognize anyone? \n    target text: Recognize anybody in there?\n    generated text: Do you recognize any of them?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text Do you recognize any of them? is a valid and natural paraphrase of the target text Recognize anybody in there? It maintains the same meaning and intent as the target text while being grammatically correct and contextually appropriate. There are no nonsensical or factually incorrect elements in the generated text, and it doesnt introduce any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: This is going to end up bad. \n    target text: This is not gonna end well.\n    generated text: This ain't going to end up too good.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text This aint going to end up too good maintains the general meaning and sentiment of the input text This is going to end up bad and the target text This is not gonna end well. It accurately conveys the negative outcome without adding any nonsensical or factually incorrect information. Therefore, it does not qualify as a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: We've got to be quick. \n    target text: We need to be fast.\n    generated text: We've got to be a little bit fast.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text Weve got to be a little bit fast is not a hallucination because it closely aligns with the target text We need to be fast and maintains the sense of urgency from the input text Weve got to be quick. The addition of a little bit does not introduce any nonsensical or factually incorrect information and can be considered as a minor modification to convey a similar meaning. Therefore, based on the given inputs and targets, the generated text is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: We've been watching you. \n    target text: We've had our eye on you.\n    generated text: I'm sorry, but we've been watching you for a couple of hours.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Hallucination\".\nHere is the reasoning the editor provided: The generated text contains additional information about watching for a couple of hours, which cannot be supported by the input text or the target text. This extra information goes beyond the original context and is not present in the input or target text, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: I shall love you always. \n    target text: I will love you forever.\n    generated text: I'll love you forever and ever.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text Ill love you forever and ever is not hallucination because it maintains the central idea of the input and target texts, expressing a commitment to love indefinitely. It does not contain nonsensical or factually incorrect information, nor does it introduce any additional unsupported information. The sentiment and meaning are consistent with the original input and the target text. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: I'll take good care of you. \n    target text: I'm gonna look after you.\n    generated text: I'm going to take a good care of you now.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text closely aligns with the input text and the target text, maintaining the main message and intent. It does not contain any nonsensical or factually incorrect information, nor does it introduce any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Where did everybody go? \n    target text: Where have they all gone?\n    generated text: Where'd all the kids go to?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text Whered all the kids go to? maintains the core meaning of the input and target texts by expressing the idea of people or individuals leaving. It does not introduce nonsensical or factually incorrect information, nor does it contain additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: He did not pull through. \n    target text: He didn't make it.\n    generated text: He didn't make it through.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text He didnt make it through accurately captures the essential meaning of the target text He didnt make it by simply adding the word through which does not introduce any nonsensical or factually incorrect information. The addition of through is supported by the context and does not change the overall meaning or introduce any new unsupported information. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Leave the talking to me. \n    target text: Let me do all the talking.\n    generated text: You're gonna leave the talking to me alone.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text Youre gonna leave the talking to me alone is a paraphrase of the input text Leave the talking to me and the target text Let me do all the talking. It does not contain any nonsensical or factually incorrect information, and it does not introduce any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: I didn't kill her. \n    target text: I wasn't the one who killed her.\n    generated text: I'm telling you, I didn't kill her, that's all.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text accurately conveys the denial of the action and the assertion of innocence, which aligns with the input text and the target text. There is no nonsensical or factually incorrect information, and no additional unsupported details are added. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: I cannot let that happen. \n    target text: This I cannot allow.\n    generated text: I can't allow that.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text closely aligns with the target text in terms of meaning and intent. It retains the core message of not allowing something to happen, which is consistent with the input and target texts. There are no nonsensical or factually incorrect details, and there are no additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: I'm just not coming. \n    target text: I'm not gonna go.\n    generated text: I'm just, uh, I'm not coming in.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text closely aligns with the target text Im not gonna go and maintains the negation from the input text Im just not coming. Although it adds the phrase uh and in at the end, these additions do not significantly change the meaning or introduce nonsensical information. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the editor: 0.2\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: How long you've been back? \n    target text: When did you get back?\n    generated text: How long's you been back in town?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Hallucination\".\nHere is the reasoning the editor provided: The generated text How longs you been back in town? contains additional information that cannot be supported by the input text or the target text. There is no mention of in town in the input or target text, making it an unsupported addition and therefore a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: We'll leave you with that. \n    target text: You can keep it.\n    generated text: We'll leave you with that.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text Well leave you with that directly matches the input text Well leave you with that and conveys a similar meaning to the target text You can keep it. There are no nonsensical or factually incorrect information in the generated text, and it does not contain any additional information not supported by the input and target texts. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: How was the trip in? \n    target text: How was your journey?\n    generated text: So how'd the trip get in?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text, So howd the trip get in? closely matches the target text, How was your journey? in terms of the meaning and intent. Although there is a slight variation in the wording, the essential question about the trip/journey remains consistent. Additionally, the generated text does not contain any nonsensical or factually incorrect information, and it does not introduce any additional unsupported details. Therefore, based on the given inputs and targets, the generated text is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: How long have you known? \n    target text: How long you known that?\n    generated text: How long have you known this?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text How long have you known this? closely aligns with the target text How long you known that? and retains the essential meaning of the input text How long have you known? without adding any nonsensical or factually incorrect information. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Leave your message after the beep. \n    target text: Please leave a message at the sound of the tone.\n    generated text: You'll leave your message after the beep, and you'll be on your way.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Hallucination\".\nHere is the reasoning the editor provided: The generated text contains additional information that cannot be supported by the input text or the target text. Both the input text and the target text only mention leaving a message after the beep, but the generated text adds and youll be on your way, which is not supported by the original context. This additional information makes the generated text a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: No way is this happening. \n    target text: This can't happen.\n    generated text: There's no way this is going to happen.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text accurately captures the negation of the possibility of something happening, which aligns with the input text and the target text. There are no nonsensical or factually incorrect information present, and the generated text does not contain any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: I don't question that. \n    target text: I have no doubt.\n    generated text: I do not question that.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text I do not question that accurately captures the meaning of the target text I have no doubt while maintaining the core idea of the input text I dont question that. It does not introduce any nonsensical or factually incorrect information, and it does not contain any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: I'm not gonna leave you. \n    target text: I will not leave you behind.\n    generated text: I'm not leaving you behind.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text closely mirrors the meaning and intent of the target text while preserving the negation from the input text. It does not introduce any nonsensical or factually incorrect information, nor does it contain additional unsupported details. Therefore, it aligns with the input and target texts, making it not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: I am penniless. \n    target text: I don't have any money.\n    generated text: I don't know what I'm going to do.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text I dont know what Im going to do does not contain any nonsensical or factually incorrect information. It also does not contain any additional information that cannot be supported by the input text or the target text. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: There's got to be a different way. \n    target text: There has to be another way.\n    generated text: There's got to be a different way out.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Hallucination\".\nHere is the reasoning the editor provided: The generated text introduces new information that is not present in the input text or the target text, specifically way out, which is not mentioned in the original or target text. This additional information changes the meaning and adds unnecessary details, making it a hallucination.\nThis is the probability assigned by the editor: 0.9\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: That's what he said. \n    target text: Yeah, he said that.\n    generated text: That's what he's saying.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text Thats what hes saying is a close paraphrase of the input text Thats what he said and the target text Yeah, he said that. It doesnt contain any nonsensical or factually incorrect information, nor does it introduce any additional unsupported information. Therefore, it stays within the context of the input and target texts without adding or distorting the meaning. Hence, it is not hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Look closely at it. \n    target text: Take a good look.\n    generated text: Take a close look at it.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text Take a close look at it is not a hallucination because it closely matches the target text Take a good look and conveys a similar meaning to the input text Look closely at it. There is no nonsensical or factually incorrect information in the generated text, and it does not contain any additional unsupported information. Therefore, it does not meet the criteria for hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Do appreciate your time. \n    target text: Well, thank you for your time.\n    generated text: You're very kind of your time.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Hallucination\".\nHere is the reasoning the editor provided: The generated text Youre very kind of your time does not accurately convey the intended meaning of the input and target texts. It not only fails to express gratitude but also introduces a nonsensical phrase kind of your time. This deviates significantly from the original meaning and introduces new information not supported by the input or target text, making it a hallucination.\nThis is the probability assigned by the editor: 0.9\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Have a nice time. \n    target text: Well, you enjoy yourself.\n    generated text: You're gonna be a good cop.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Hallucination\".\nHere is the reasoning the editor provided: The generated text Youre gonna be a good cop does not relate to the input text Have a nice time or the target text Well, you enjoy yourself. It contains additional information that cannot be supported by the input or the target. This unrelated and unsupported information makes it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Thank you - for everything. \n    target text: Thank you for all of this.\n    generated text: Thank you, thank you for everything.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text closely matches the target text and maintains the sentiment and gratitude expressed in the input text. It does not add any nonsensical or factually incorrect information. The only addition is the repetition of thank you, which does not alter the meaning or introduce unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Still not too late. \n    target text: There's still time.\n    generated text: I'm gonna be there for a few days.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Hallucination\".\nHere is the reasoning the editor provided: The generated text Im gonna be there for a few days does not directly relate to the input text Still not too late or the target text Theres still time. The generated text introduces new information that is not supported by either the input or target text, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Do you want something to drink? \n    target text: So, you want a drink or something?\n    generated text: Hey, do you want to get something to drink, by the way?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text stays true to the intent of the input and target texts by offering a drink, and it does not contain any nonsensical or factually incorrect information. Additionally, it does not introduce any unsupported additional information. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: I've been busy. \n    target text: I had something to do.\n    generated text: I've been kind of on my mind.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Hallucination\".\nHere is the reasoning the editor provided: The generated text Ive been kind of on my mind does not accurately reflect the meaning of the input text Ive been busy or the target text I had something to do. It introduces new and unrelated information, which is not supported by the input or target text. This additional information makes the generated text a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: What's your solution? \n    target text: What are you proposing?\n    generated text: What is your solution?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text accurately captures the meaning of the input text and the target text without introducing any nonsensical or factually incorrect information. It stays true to the original question and its proposed alternative, making it a faithful paraphrase without hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: I'm ordering it. \n    target text: That is an order.\n    generated text: I'll order it.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text Ill order it is a valid paraphrase of the input text Im ordering it and the target text That is an order. There are no nonsensical or factually incorrect information in the generated text, and it does not contain any additional information that cannot be supported by the input and target texts. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Hey, that's not your concern. \n    target text: It's really none of your business.\n    generated text: Hey, that's not your concern, that's all I can say.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Hallucination\".\nHere is the reasoning the editor provided: The generated text includes the additional phrase thats all I can say, which is not present in the input text or the target text. This addition goes beyond the original meaning and intent, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Talk to you later, pal. \n    target text: We'll talk later.\n    generated text: I'll talk to you later, okay, man?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text Ill talk to you later, okay, man? is not hallucination because it maintains the core message of the target text Well talk later and stays within the context of the input text Talk to you later, pal. It does not contain any nonsensical or factually incorrect information, nor does it introduce any additional unsupported information. Therefore, it does not meet the criteria for hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Guilty as charged. \n    target text: It was a guilty verdict.\n    generated text: Guilty as charged, Mr. Reese.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Hallucination\".\nHere is the reasoning the editor provided: The generated text includes additional information (Mr. Reese) that cannot be supported by the input text or the target text, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: No other way around it. \n    target text: There's no other way.\n    generated text: There's no other way around it.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text is not a hallucination because it directly stems from the input text and target text without introducing any nonsensical or factually incorrect information. It simply combines the phrases from the input and target text to form a coherent statement.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: This'll only take a second. \n    target text: This won't take long.\n    generated text: This won't take more than a second, okay?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Hallucination\".\nHere is the reasoning the editor provided: The generated text contains additional information that cannot be supported by the input text or the target text, as it introduces the concept of time (more than a second) which is not present in the original input or target. This additional information is not supported by the given inputs and targets, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: It is no concern of yours. \n    target text: That's not your concern.\n    generated text: It's none of your business, my friend.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text accurately captures the meaning and sentiment of the input and target texts. It maintains the essence of not your concern and does not introduce any nonsensical or factually incorrect information. The generated text does not contain any additional unsupported information beyond the input and target texts. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: I'll be seeing you soon. \n    target text: See you in a little bit.\n    generated text: I'll see you soon, all right?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text closely matches the target text in terms of the intended meaning and sentiment. It does not contain any nonsensical or factually incorrect information, and it does not introduce any additional unsupported information. Therefore, it aligns well with the input text and the target text, leading to the conclusion that it is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: It's none of your business. \n    target text: It's not your affair.\n    generated text: I-I-I don't have to do this.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Hallucination\".\nHere is the reasoning the editor provided: The generated text I-I-I dont have to do this does not accurately reflect the meaning or context of the input text Its none of your business and the target text Its not your affair. The generated text introduces new information and does not maintain the essence of the original texts, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: I'll give it a shot. \n    target text: Sure gonna try.\n    generated text: I'll test it.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text Ill test it is a reasonable paraphrase of the input text Ill give it a shot and the target text Sure gonna try. There are no nonsensical or factually incorrect information in the generated text, and it does not contain any additional information that cannot be supported by the input and target texts. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Um, I need you to leave. \n    target text: You have to go.\n    generated text: I need you to leave now.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text I need you to leave now is not a hallucination because it closely aligns with the target text You have to go and does not introduce any nonsensical or factually incorrect information. The addition of now does not significantly change the meaning of the request to leave, and it can be seen as an implied urgency. Therefore, the generated text is a reasonable paraphrase of the target text based on the input text.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Would you care to join? \n    target text: You want to come with me?\n    generated text: Would you like to come with me for a moment?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text closely captures the meaning and intent of the input text and the target text, without introducing any nonsensical or factually incorrect information. It simply adds a bit more detail to the invitation, which is within the realm of natural conversation. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: How come you're asking? \n    target text: Why would you ask me that?\n    generated text: How come you're asking me to do this?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text is not a hallucination because it does not contain any nonsensical or factually incorrect information, and it does not introduce any additional unsupported information beyond the input and target texts. It simply adds a request to the original question, which is a reasonable expansion based on the context.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Now, what gives you that idea? \n    target text: What makes you think that?\n    generated text: What makes you think that?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text closely matches the target text and is consistent with the input text. There are no nonsensical or factually incorrect information in the generated text, and it does not contain any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: I do see your point. \n    target text: I know what you mean.\n    generated text: I do see what you mean.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text closely aligns with both the input text and the target text, without introducing any nonsensical or factually incorrect information. It does not contain any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: This going somewhere? \n    target text: What's your point?\n    generated text: You're going somewhere else?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text is a valid rephrasing of the target text that maintains the same meaning and intent without adding any nonsensical or factually incorrect information. It directly responds to the input texts implied question, This going somewhere? with a rephrased question, Youre going somewhere else? without introducing additional unsupported information.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: You're not done yet. \n    target text: You haven't finished yet\n    generated text: You're not finished yet.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text closely reflects the target text and does not contain any nonsensical or factually incorrect information. It also does not introduce any additional unsupported information. Therefore, it is aligned with the inputs and targets and is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Because you're a scientist. \n    target text: You are a man of science.\n    generated text: That's because you're a science officer.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text Thats because youre a science officer does not contain any nonsensical or factually incorrect information. Additionally, it does not introduce any unsupported additional information beyond the input text Because youre a scientist and the target text You are a man of science. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Let's go through this again. \n    target text: Okay, let's run through it one more time.\n    generated text: All right, let's go over this one again, and we'll be back in business.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text accurately captures the essence of the target text by expressing the idea of going through something again, without adding any nonsensical or factually incorrect information. It maintains the same meaning and intent as the target text, and the additional phrase and well be back in business does not introduce new information that cannot be supported by the input or target text.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Do you have a suspect? \n    target text: Have you identified a suspect?\n    generated text: Do you have a suspect in the murders?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text is not a hallucination because it directly addresses the question in the input text and aligns with the meaning of the target text. It does not introduce any nonsensical or factually incorrect information, and the additional information it provides is within the scope of the original query.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: I beg to differ. \n    target text: I can't agree.\n    generated text: I'm not in the same position.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text Im not in the same position does not contain any nonsensical or factually incorrect information, and it does not introduce any additional unsupported information beyond the input and target texts. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: She's been sleeping with my boss. \n    target text: She slept with my boss, so.\n    generated text: She's been sleeping with my boss for a few days.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Hallucination\".\nHere is the reasoning the editor provided: The generated text introduces a specific timeframe for a few days which is not supported by the input text or the target text. It adds new information that cannot be derived from the original statement. This creates a scenario that goes beyond the given information, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: I have made an improvement. \n    target text: I made it better.\n    generated text: I've done better.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text Ive done better is a valid paraphrase of the target text I made it better and it does not contain any nonsensical or factually incorrect information. It also does not introduce any additional unsupported information. Therefore, based on the given inputs and targets, the generated text is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Don't call me pudding. \n    target text: Don't you pudding me.\n    generated text: Don't call me a poodle.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Hallucination\".\nHere is the reasoning the editor provided: The generated text Dont call me a poodle introduces additional information (a poodle) that cannot be supported by the input text or the target text. It deviates significantly from the original meaning and introduces nonsensical information, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Can you identify him? \n    target text: You think you could ID him?\n    generated text: Do you have any way of ID'ing the man's body?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Hallucination\".\nHere is the reasoning the editor provided: The generated text contains additional information about the mans body that is not present in the input text or the target text. This additional information cannot be supported by the given inputs and targets, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: This is an essential service route. \n    target text: This route is for essential traffic only.\n    generated text: This is a very important, very important service route, Mr. President.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Hallucination\".\nHere is the reasoning the editor provided: The generated text includes additional information that cannot be supported by the input text or the target text, as it introduces the reference to Mr. President, which is not present in the original texts. This is an unsupported addition and deviates from the original meaning.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Then why'd they send him to prison? \n    target text: Then why did he go to jail?\n    generated text: Then why did they send him to jail?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text is not hallucination because it accurately reflects the meaning of the input text and the target text without introducing nonsensical or factually incorrect information. It simply rearranges the words and maintains the original context, making it a valid paraphrase.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Seventy - five a month. \n    target text: Seventy-five dollars a month.\n    generated text: Seventy-one-five-a-month-old, man.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Hallucination\".\nHere is the reasoning the editor provided: The generated text contains nonsensical information and additional details that cannot be supported by the input text or the target text. It introduces the irrelevant concept of age (old man) and deviates from the original information about the amount of money and time period. Therefore, it is a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Rick, what do you want? \n    target text: What do you need, Rick?\n    generated text: Rick, what do you want from me?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text stays true to the context of the input and target texts, only adding from me which does not contradict the original meaning or introduce any nonsensical information. Therefore, it does not qualify as a hallucination based on the given inputs and targets.\nThis is the probability assigned by the editor: 0.2\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Do you think I'm a monster? \n    target text: You think I'm some kind of a monster?\n    generated text: What do you think I'm, like, a monster, like, \"A monster\"?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Hallucination\".\nHere is the reasoning the editor provided: The generated text contains additional information that cannot be supported by the input text or the target text, as it introduces the phrase like, a monster\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: I'll get you somewhere safe. \n    target text: I'll take you to safety.\n    generated text: I'm going to get you someplace safe, okay?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text maintains the core meaning of the input and target texts. It rephrases take you to safety to get you someplace safe while preserving the intention of ensuring safety. There are no nonsensical or factually incorrect details in the generated text, and it does not contain any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Haven't you got anything better to do? \n    target text: You have nothing else better to do with your time?\n    generated text: You don't have anything better to do, or you don't know what else to do?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text accurately captures the essence of the input text and the target text, expressing the same idea in a slightly different manner without introducing any nonsensical or factually incorrect information. It maintains the core meaning and intent of the original input and target texts without adding any unsupported information.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Missile still closing distance and tracking steady. \n    target text: Missile still tracking steady and closing distance.\n    generated text: Missile still closing distance and tracking steady as we can see.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Hallucination\".\nHere is the reasoning the editor provided: The generated text introduces the phrase as we can see which is not present in the input text or the target text. This additional information cannot be supported by the given inputs and targets, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: They don't have to die. \n    target text: We can save them.\n    generated text: They don't have to.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Hallucination\".\nHere is the reasoning the editor provided: The generated text They dont have to not only lacks the crucial information from the target text We can save them, but it also introduces ambiguity and lacks clarity, making it nonsensical and factually incorrect in the context of the input and target text. It also removes the essential information about saving them, which is not supported by the input or target text. Therefore, it is a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: And he sometimes watches Oliver. \n    target text: He occasionally watches Oliver, sometimes.\n    generated text: And he watches Oliver all the time.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Hallucination\".\nHere is the reasoning the editor provided: The generated text And he watches Oliver all the time contains information that is not supported by the input text or the target text. It adds the information that he watches Oliver all the time, which goes beyond the occasional nature of the original statement in the target text. This additional information constitutes a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: I wanted to be good. \n    target text: I was just being kind.\n    generated text: I'd like to be good.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text Id like to be good does not contain any nonsensical or factually incorrect information. It also does not introduce any additional unsupported information beyond the input and target texts. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: How come you didn't call me back? \n    target text: Why didn't you return my calls?\n    generated text: How come you didn't call me back, you're a cop?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Hallucination\".\nHere is the reasoning the editor provided: The generated text introduces new information (the person being a cop) that is not present in the input text or the target text. This additional information cannot be supported by the given inputs and targets, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: I couId've predicted this. \n    target text: This is predictable.\n    generated text: I could've predicted this one.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text I couldve predicted this one does not contain any nonsensical or factually incorrect information. It simply adds the word one, which does not change the meaning or introduce unsupported information. Therefore, based on the given inputs and targets, the generated text is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: You look worried. \n    target text: You seem distraught.\n    generated text: You look unsettled.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text You look unsettled closely matches the meaning and sentiment of the target text You seem distraught without introducing any nonsensical or factually incorrect information. There is no additional unsupported information present in the generated text. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: I think I'm going to need it. \n    target text: I think I may have need of it.\n    generated text: I think I'm going to be the one who's going to need it.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Hallucination\".\nHere is the reasoning the editor provided: The generated text contains additional information that cannot be supported by the input text or the target text, as it introduces a new element the one whos going to need it that is not present in the input or target text. This extra information is not supported or implied by the original statement and thus constitutes a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: I didn't sign up for this. \n    target text: That's not the job I signed on for.\n    generated text: I didn't sign up for this, and I didn't want to be in the car.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Hallucination\".\nHere is the reasoning the editor provided: The generated text contains additional information that cannot be supported by the input text or the target text. The mention of being in the car is not related to the original statement or the target statement about the job. This additional information is unsupported and unrelated to the context provided by the input and target texts.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: I'll see you in a couple of days. \n    target text: You, I'll see you in a few days.\n    generated text: I'll see you in a couple of days, if you're going to be able to get a drink.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Hallucination\".\nHere is the reasoning the editor provided: The generated text contains additional information (if youre going to be able to get a drink) that cannot be supported by the input text or the target text, making it a hallucination. There is no mention of getting a drink in the input or target text, so this extra information is unsupported and nonsensical in the context of the conversation.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: I'm good at keeping secrets. \n    target text: I am great with secrets.\n    generated text: I'm a very good at keeping a secret.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text is a slightly modified version of the target text and maintains the same meaning as the input and target texts. It does not introduce any nonsensical or factually incorrect information, and it does not contain any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Something's not right. \n    target text: There's something's wrong here.\n    generated text: There's something wrong with me, man.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text, Theres something wrong with me, man, maintains the general sentiment of the input text and the target text, which is about something being wrong or not right. It does not include nonsensical or factually incorrect information, and it does not introduce additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Tell me what the problem is. \n    target text: What seems to be the problem?\n    generated text: Tell me what the problem is here.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text does not contain any nonsensical or factually incorrect information, and it does not introduce any additional unsupported information beyond the input and target texts. It simply adds the word here to the original question, which does not change the meaning or introduce any new information. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: May I speak candidly? \n    target text: Permission to speak freely?\n    generated text: May I speak to you frankly?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text is not a hallucination because it captures the same meaning as the target text, Permission to speak freely?, and does not contain any nonsensical or factually incorrect information. It simply rephrases the original question while maintaining the same intent.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: They'll say nothing. \n    target text: They're not gonna say anything.\n    generated text: They're not going to say a word of the word.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Hallucination\".\nHere is the reasoning the editor provided: The generated text contains nonsensical information that is not supported by the input text or the target text. The phrase of the word does not make sense in the context of the given input and target texts, and it introduces additional information that is not present in the original texts. Therefore, the generated text is a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: We just have to get you to the hospital. \n    target text: You need to get to a hospital.\n    generated text: We've just got to get you to the hospital.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text closely matches the target text and retains the essential meaning of the input text. It does not contain nonsensical or factually incorrect information, nor does it introduce any additional unsupported details. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: No one has died. \n    target text: There ain't nobody dead.\n    generated text: There's no one who's been killed in the last year.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Hallucination\".\nHere is the reasoning the editor provided: The generated text contains additional information that cannot be supported by the input text or the target text, as it introduces the time frame in the last year which is not present in the original statement or the target text. This extra information goes beyond the scope of the original statement and is not supported by any context provided.\nThis is the probability assigned by the editor: 0.9\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: I'm just like everyone else. \n    target text: I'm no different than anybody else.\n    generated text: I don't know, I'm just like all the others.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text accurately captures the meaning and sentiment of the input and target texts. It does not contain any nonsensical or factually incorrect information, and it does not introduce any additional unsupported information. Therefore, it aligns with the original meaning and does not deviate from the context provided by the input and target texts.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: It's not safe. \n    target text: It is very dangerous.\n    generated text: It's a little bit too dangerous.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text Its a little bit too dangerous does not contain any nonsensical or factually incorrect information, and it does not introduce any additional unsupported information compared to the input text Its not safe and the target text It is very dangerous. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the editor: 0.2\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Are you sure that's him? \n    target text: Can you confirm it's him?\n    generated text: Are you certain that's the man?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text closely follows the meaning and intent of the target text while retaining the essential information from the input text. It does not contain nonsensical or factually incorrect information, and it does not introduce any additional unsupported details. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: What do you care anyway? \n    target text: Why do you even care, okay?\n    generated text: What's it to you, anyway?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text closely follows the meaning and intent of the input and target texts. It maintains the question structure and conveys a similar sentiment. There are no nonsensical or factually incorrect information in the generated text, and it does not contain any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: This is not your house anymore. \n    target text: You don't live here anymore.\n    generated text: This isn't your house anymore.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text accurately captures the intended meaning of the input and target texts without adding any nonsensical or factually incorrect information. It simply rephrases the original statement to convey the same idea. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: I'm sorry I can't take your call right now. \n    target text: I can't get to the phone.\n    generated text: I'm sorry I can't take your call right now, okay?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text does not contain any nonsensical or factually incorrect information, and it does not introduce any additional unsupported information beyond the input and target texts. The additional okay at the end does not alter the meaning of the original statement. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Do you have the fever? \n    target text: Have you got a temperature?\n    generated text: You've got the heat, huh?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text accurately captures the meaning of the target text by asking about the presence of a fever or temperature. Although the wording is informal, it does not introduce any nonsensical or factually incorrect information. Additionally, the generated text does not contain any additional information beyond the scope of the input and target texts. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: She's gonna have a baby. \n    target text: She's having the baby.\n    generated text: She's going to be able to have a baby.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Hallucination\".\nHere is the reasoning the editor provided: The generated text Shes going to be able to have a baby introduces additional information that cannot be supported by the input text Shes gonna have a baby and the target text Shes having the baby. It goes beyond the original statement and implies a sense of capability or ability that is not present in the original context. This additional information constitutes a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: It's urgent, she says. \n    target text: She said it's urgent.\n    generated text: She says it's urgent, she says.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Hallucination\".\nHere is the reasoning the editor provided: The generated text contains additional information (she says) that cannot be supported by the input text or the target text. This extra information changes the meaning and introduces new content not present in the original input or the target, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: I'll be right with you. \n    target text: See you in a moment.\n    generated text: I'll be right.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Hallucination\".\nHere is the reasoning the editor provided: The generated text Ill be right not only fails to include the complete target text See you in a moment but also removes the crucial information with you from the input text, resulting in nonsensical and factually incorrect information. It also introduces an additional and unsupported change by omitting with you from the original meaning, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: He'll keep you safe. \n    target text: He's protecting you.\n    generated text: He'll keep you in safety.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text Hell keep you in safety retains the meaning and intent of the target text Hes protecting you by conveying the idea of providing safety and protection. It does not introduce any nonsensical or factually incorrect information, nor does it contain any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: We're being tracked. \n    target text: We have a tail.\n    generated text: We're being picked up.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Hallucination\".\nHere is the reasoning the editor provided: The generated text Were being picked up contains additional information that cannot be supported by the input text Were being tracked or the target text We have a tail. It introduces the concept of being picked up, which is not present in the original texts. This additional information constitutes a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: I'm just concerned. \n    target text: I just worry, you know?\n    generated text: I'm just a little concerned.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text Im just a little concerned does not contain any nonsensical or factually incorrect information. It also does not introduce any additional information beyond the input and target texts. The addition of a little in the generated text does not significantly alter the meaning or introduce unsupported information. Therefore, it aligns with the input and target texts and is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: I'm gonna make a call. \n    target text: I gotta make a quick call, all right?\n    generated text: I'm gonna make a call, and I'm gonna make a call, okay?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Hallucination\".\nHere is the reasoning the editor provided: The generated text contains additional repeated information that is not present in the input text or the target text, which cannot be supported by the given context. This extra repetition is not logically inferred from the original text and adds unnecessary information, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: I'm doing the best that I can. \n    target text: What I do is the best I can do.\n    generated text: I'm just doing the best I can, you know, to get out of here.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text stays true to the meaning of the input and target texts, expressing the idea of doing ones best. It does not introduce any nonsensical or factually incorrect information, and it does not contain additional unsupported details. Therefore, it aligns with the given inputs and targets without any hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: She's a darling girl. \n    target text: She's a sweetheart.\n    generated text: She's a sweet, sweet little girl.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text stays true to the sentiment and meaning of the input and target texts. It does not introduce any nonsensical or factually incorrect information, and it does not contain any additional unsupported details. The paraphrased text maintains the essence of the original meaning while adding a bit of emphasis on sweetness, which is within the realm of the input and target texts.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Are you listening to this? \n    target text: Hey, you hear that?\n    generated text: Are you gonna listen to this?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text closely captures the meaning and intent of the target text, Hey, you hear that?, by using the phrase Are you gonna listen to this? which conveys a similar message. There are no nonsensical or factually incorrect information in the generated text, and it does not contain additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: And she's doing good. \n    target text: She's all right.\n    generated text: And, uh, she's doing a good job.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Hallucination\".\nHere is the reasoning the editor provided: The generated text contains additional information (a good job) that cannot be supported by the input text or the target text, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Kid, you did a good job. \n    target text: Yeah, you really did a great job, kid.\n    generated text: Hey, kid, you did a good job, and you're a good one.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Hallucination\".\nHere is the reasoning the editor provided: The generated text contains additional information (and youre a good one) that cannot be supported by the input text or the target text. This extra phrase goes beyond the original message and is not supported by the input or target. Therefore, it is a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Be out in a sec. \n    target text: Be right there.\n    generated text: Be out in seconds.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Hallucination\".\nHere is the reasoning the editor provided: The generated text Be out in seconds contains additional information (seconds) that is not supported by the input text or the target text. It adds a specific timeframe that is not present in the original input or the target. This additional information introduces a level of specificity that is not warranted by the given context, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Your fly is unzipped. \n    target text: Your zipper's down.\n    generated text: Your fly is undone.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text Your fly is undone accurately captures the meaning of the target text Your zippers down by conveying the same message using different words. It does not contain any nonsensical or factually incorrect information, and it does not introduce any additional unsupported information. Therefore, based on the given inputs and targets, the generated text is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Just put some pressure on here. \n    target text: Press on this thing.\n    generated text: Just put some pressure on this one.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text closely follows the meaning and intention of the target text by instructing to apply pressure, which aligns with the input text as well. There is no nonsensical or factually incorrect information, nor does it contain any additional unsupported details. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: I am loving soccer. \n    target text: I love football.\n    generated text: I'm loving the football.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text Im loving the football accurately captures the meaning of I love football from the target text and I am loving soccer from the input text. There are no nonsensical or factually incorrect information, and no additional unsupported information in the generated text. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: What does it say up here? \n    target text: What is written here?\n    generated text: What does it say upstairs?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Hallucination\".\nHere is the reasoning the editor provided: The generated text contains additional information (upstairs) that is not supported by the input text or the target text. It introduces a location not mentioned in the original text, which is a form of hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: And how was your flight? \n    target text: Did you have a good flight?\n    generated text: And how'd you get on your flight?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text maintains the core meaning and intent of the input and target texts without introducing nonsensical or factually incorrect information. The question about the flight is paraphrased in a natural and coherent way, staying true to the original inquiry. There are no additional unsupported details in the generated text.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: It's been six weeks. \n    target text: Six weeks, Martin.\n    generated text: It's been 6 weeks now.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text Its been 6 weeks now accurately conveys the temporal information from the input text Its been six weeks and the target text Six weeks, Martin. There is no nonsensical or factually incorrect information in the generated text, and it does not contain any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Carry on working. \n    target text: Get on with your work.\n    generated text: You're gonna have to work.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text Youre gonna have to work maintains the core meaning of the input text Carry on working and the target text Get on with your work without adding any nonsensical or factually incorrect information. The generated text stays true to the essence of the original message, therefore it is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Well, didn't you like it? \n    target text: You didn't enjoy it?\n    generated text: Well, didn't you enjoy it?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text is not a hallucination because it closely aligns with the meaning of the target text and does not introduce any nonsensical or factually incorrect information. It simply rephrases the question from didnt you like it? to you didnt enjoy it? which maintains the original intent.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: I thought you were coming with us? \n    target text: Won't you come along?\n    generated text: Didn't you come with us today?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Hallucination\".\nHere is the reasoning the editor provided: The generated text Didnt you come with us today? contains additional information about the time (today) that cannot be supported by the input text I thought you were coming with us? and the target text Wont you come along?. This added information is not present in the original input or target texts, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Can you manage that? \n    target text: Do you feel up to that?\n    generated text: You think you can do that?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text closely captures the meaning and intent of the target text by expressing the same idea in a slightly different manner. It does not introduce any nonsensical or factually incorrect information, nor does it contain any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: I need to do this alone. \n    target text: It's just something I need to do by myself.\n    generated text: I'm sorry, I've got to do this by myself.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text accurately captures the meaning and intent of the input text and the target text. It conveys the same idea of needing to do something alone or by oneself without introducing any nonsensical or factually incorrect information. The generated text does not contain any additional information that is not supported by the input and target texts. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: We can't afford to risk it. \n    target text: We can't risk that.\n    generated text: We don't have the money to risk it, all right?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text closely aligns with the input text and the target text, expressing the same idea in different words without introducing nonsensical or factually incorrect information. It stays within the context and doesnt add any unsupported details. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Eh, just a few days. \n    target text: Just a couple of days.\n    generated text: Uh, just for a couple of days.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text closely follows the meaning and intent of the target text, Just a couple of days, and does not introduce any nonsensical or factually incorrect information. It simply adds the word for at the beginning, which does not change the meaning or introduce any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: I'm not involved in this. \n    target text: I don't have anything to do with that.\n    generated text: I'm not in any of this at all.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text accurately conveys the meaning of the target text by expressing the lack of involvement, without adding any nonsensical or factually incorrect information. It stays true to the input and target texts without introducing any unsupported additional information.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Just breathe deep. \n    target text: Just take long, deep breaths.\n    generated text: Just breathe deep, and I'll be right there.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Hallucination\".\nHere is the reasoning the editor provided: The generated text contains additional information (and Ill be right there) that cannot be supported by the input text or the target text, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: I never told you that. \n    target text: I said nothing of the kind.\n    generated text: I never told you that before.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor evaluated the generated text looking at the input text and the target text. The editor decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the editor provided: The generated text does not contain any nonsensical or factually incorrect information, and it does not introduce any additional unsupported information beyond the input text and target text. It simply extends the statement from I never told you that to I never told you that before, which is a reasonable and coherent expansion without altering the original meaning.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÐ¶Ð¾Ð½ Ð¸ Ð­Ð½Ð½ Ð½ÑÐ°Ð²ÑÑÑÑ Ð´ÑÑÐ³ Ð´ÑÑÐ³Ñ. \n    target text: John and Ann like each other.\n    generated text: John and John are the only one of them.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Hallucination\".\nHere is the reasoning the translator provided: The generated text John and John are the only one of them contains factually incorrect information as it states that only John and John are involved, which is not supported by the input text or the target text. Additionally, it contains additional information that cannot be supported by the input text or the target text, making it a clear case of hallucination.\nThis is the probability assigned by the translator: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÐ°Ðº Ñ Ð¢Ð¾Ð¼Ð° Ñ ÑÑÐ°Ð½ÑÑÐ·ÑÐºÐ¸Ð¼? - \"ÐÐµÐ¿Ð»Ð¾ÑÐ¾\". \n    target text: How's Tom's French? \"Pretty good.\"\n    generated text: How about Tom and French? - \"Not bad.\"\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the essence of the question about Toms French skills and provides a reasonable response, although it differs slightly from the target text. There are no nonsensical or factually incorrect details in the generated text, and it does not introduce any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the translator: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð¯ Ð´ÑÐ¼Ð°Ñ, Ð¢Ð¾Ð¼Ñ Ð½ÑÐ¶Ð½Ð¾ Ð¿ÐµÑÐµÐ¾Ð´ÐµÑÑÑÑ. \n    target text: I think Tom needs to change his clothes.\n    generated text: I think that's why you need to dress up.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Hallucination\".\nHere is the reasoning the translator provided: The generated text contains additional information that cannot be supported by the input text or the target text. The phrase thats why introduces new information not present in the original text, and dress up is not a direct translation of Ð¿ÐµÑÐµÐ¾Ð´ÐµÑÑÑÑ, which means change clothes. Therefore, the generated text goes beyond the scope of the original sentence and introduces new information, making it a hallucination.\nThis is the probability assigned by the translator: 0.9\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÑÐ» Ð±Ñ Ñ ÐºÐ°Ð½Ð°Ð´ÐµÑ! \n    target text: I wish I were a Canadian.\n    generated text: I would be Canadian!\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the conditional expression ÐÑÐ» Ð±Ñ Ñ (I wish I were) and the nationality ÐºÐ°Ð½Ð°Ð´ÐµÑ (Canadian) from the input text and the target text. It does not contain any additional information or factual errors. Therefore, it is not a hallucination.\nThis is the probability assigned by the translator: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÐ´Ð½Ð¾ÐºÐ»Ð°ÑÑÐ½Ð¸ÐºÐ¸ Ð¾Ð±Ð·ÑÐ²Ð°Ð»Ð¸ Ð¢Ð¾Ð¼Ð°. \n    target text: Tom's classmates called him names.\n    generated text: The classmates called Tom.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Hallucination\".\nHere is the reasoning the translator provided: The generated text The classmates called Tom is a hallucination because it omits the fact that Tom was called names, which is a crucial detail from the input and target text. The input text clearly indicates that Tom was being called names by his classmates, so the absence of this information in the generated text constitutes a factual inaccuracy and omission of important details. Therefore, the generated text is a hallucination.\nThis is the probability assigned by the translator: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÐ¾Ð´Ð¾Ð¶Ð´Ð¸, ÑÑ ÑÑÐ¾ ÑÐµÑÑÑÐ·Ð½Ð¾? \n    target text: Whoa, are you serious?\n    generated text: Excuse me, you're serious?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the meaning and tone of the input text and target text without adding any nonsensical or factually incorrect information. It simply rephrases the question while maintaining the intended message. There is no additional unsupported information in the generated text.\nThis is the probability assigned by the translator: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÐ¾Ð¼Ð½Ð°ÑÐ° Ð¢Ð¾Ð¼Ð° Ð¿Ð¾ÑÐ¾Ð¶Ð° Ð½Ð° ÑÐ²Ð¸Ð½Ð°ÑÐ½Ð¸Ðº. \n    target text: Tom's room looks like a pigsty.\n    generated text: The room Toma looks like a piggy bank.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Hallucination\".\nHere is the reasoning the translator provided: The generated text The room Toma looks like a piggy bank contains nonsensical information as it is factually incorrect and does not accurately convey the meaning of the input text or the target text. The comparison of a room to a piggy bank is nonsensical and not supported by the input or target text. Therefore, the generated text is a hallucination.\nThis is the probability assigned by the translator: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÑÐ¼Ð°ÐµÑÑ, Ð½Ð°Ð¼ ÑÐ´Ð°ÑÑÑÑ ÐºÐ¾Ð³Ð´Ð°-Ð½Ð¸Ð±ÑÐ´Ñ Ð½Ð° ÑÑÐ¾Ð¼ Ð·Ð°ÑÐ°Ð±Ð¾ÑÐ°ÑÑ? \n    target text: Do you think that we'll ever make money doing this?\n    generated text: What do you do you want to do?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Hallucination\".\nHere is the reasoning the translator provided: The generated text What do you do you want to do? does not accurately convey the meaning of the input and target texts. It not only fails to capture the idea of making money from a certain activity but also introduces new and nonsensical information that is not present in the original text. As a result, it deviates significantly from the content of the input and target texts, making it a hallucination.\nThis is the probability assigned by the translator: 0.9\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð¢Ñ Ð²Ð¿Ð¾Ð»Ð½Ðµ Ð¼Ð¾Ð¶ÐµÑÑ Ð¿Ð¾Ð¹ÑÐ¸ ÑÐ¾ Ð¼Ð½Ð¾Ð¹. \n    target text: You may as well come with me.\n    generated text: You can go with me perfectly.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Hallucination\".\nHere is the reasoning the translator provided: The generated text You can go with me perfectly contains additional information (perfectly) that cannot be supported by the input text or the target text. It also changes the meaning of the original sentence by introducing perfectly which is not in line with the original meaning. This indicates that the generated text is a hallucination.\nThis is the probability assigned by the translator: 0.9\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð¢Ð¾Ð¼Ñ Ð½Ð¸ Ð´Ð¾ ÐºÐ¾Ð³Ð¾ Ð½ÐµÑ Ð´ÐµÐ»Ð°, ÐºÑÐ¾Ð¼Ðµ ÑÐµÐ±Ñ ÑÐ°Ð¼Ð¾Ð³Ð¾. \n    target text: Tom doesn't care about anyone but himself.\n    generated text: Thatâs why no one has done anything except themselves.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Hallucination\".\nHere is the reasoning the translator provided: The generated text Thatâs why no one has done anything except themselves does not accurately convey the original meaning of the input text Ð¢Ð¾Ð¼Ñ Ð½Ð¸ Ð´Ð¾ ÐºÐ¾Ð³Ð¾ Ð½ÐµÑ Ð´ÐµÐ»Ð°, ÐºÑÐ¾Ð¼Ðµ ÑÐµÐ±Ñ ÑÐ°Ð¼Ð¾Ð³Ð¾ and the target text Tom doesnt care about anyone but himself. It introduces nonsensical and factually incorrect information by completely altering the original meaning. The original text discusses Toms lack of concern for others, while the generated text introduces an entirely different concept of no one has done anything except themselves, which is not supported by the input or target text.\nThis is the probability assigned by the translator: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð¢Ð¾Ð¼Ñ Ð±ÑÐ»Ð¾ Ð½ÐµÐºÐ¾Ð¼Ñ ÑÐ°ÑÑÐºÐ°Ð·Ð°ÑÑ ÑÐ²Ð¾Ñ Ð¸ÑÑÐ¾ÑÐ¸Ñ. \n    target text: Tom had no one to tell his story to.\n    generated text: Thatâs why someone told their story.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Hallucination\".\nHere is the reasoning the translator provided: The generated text Thatâs why someone told their story contains additional information that cannot be supported by the input text or the target text. There is no indication in the input or target text about someone telling their story; it specifically refers to Tom and his story. This additional information makes the generated text a hallucination.\nThis is the probability assigned by the translator: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð¥Ð¾Ð»Ð¾Ð´Ð½Ð¾ Ð½Ðµ Ð¿Ð¾ ÑÐµÐ·Ð¾Ð½Ñ. \n    target text: It's unseasonably cold.\n    generated text: Cold not during the season.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Hallucination\".\nHere is the reasoning the translator provided: The generated text Cold not during the season does not accurately convey the meaning of the input text Ð¥Ð¾Ð»Ð¾Ð´Ð½Ð¾ Ð½Ðµ Ð¿Ð¾ ÑÐµÐ·Ð¾Ð½Ñ and the target text Its unseasonably cold. It not only fails to capture the intended meaning but also introduces nonsensical information that is not present in the input or target text. Additionally, the generated text contains additional information (not during the season) that cannot be supported by the input or target text, making it a clear case of hallucination.\nThis is the probability assigned by the translator: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÐ¾Ð¶Ð°Ð»ÑÐ¹ÑÑÐ°, Ð²ÑÐµ Ð²Ð½Ð¸Ð¼Ð°Ð½Ð¸Ðµ. Ð¡ÐµÐ¹ÑÐ°Ñ Ñ Ð¿ÑÐ¸ÑÑÑÐ¿Ð°Ñ Ðº Ð¿ÑÐ¾ÑÐ»ÑÑÐ¸Ð²Ð°Ð½Ð¸Ñ Ð¿Ð°ÑÐ¸ÐµÐ½ÑÐ°. Ð£Ð±ÐµÐ´Ð¸ÑÐµÑÑ, ÑÑÐ¾ Ð¾ÑÑÐ»ÐµÐ´Ð¸Ð»Ð¸ Ð¿ÑÐ°Ð²Ð¸Ð»ÑÐ½Ð¾ÑÑÑ Ð²ÑÐ¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ñ ÑÑÐ¾Ð¹ Ð¿ÑÐ¾ÑÐµÐ´ÑÑÑ - Ð²Ð°Ð¼ Ð¿ÑÐµÐ´ÑÑÐ¾Ð¸Ñ Ð¾Ð±ÑÐ°ÑÐ¸ÑÑÑÑ Ðº ÐµÑ Ð¸ÑÐ¿Ð¾Ð»ÑÐ·Ð¾Ð²Ð°Ð½Ð¸Ñ Ð·Ð°Ð²ÑÑÐ°. \n    target text: If everyone could pay close attention, please. I will now auscultate the patient. Make sure to note the proper procedure because you all will be practicing this tomorrow.\n    generated text: Please pay attention. Now I start listening to the patient. Make sure that you have followed the correct implementation of this procedure - you need to contact its use tomorrow.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Hallucination\".\nHere is the reasoning the translator provided: The generated text contains additional information that cannot be supported by the input text or the target text, such as you need to contact its use tomorrow. This goes beyond the scope of the original text and introduces new information not present in the input or target text, making it a hallucination.\nThis is the probability assigned by the translator: 0.9\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÑ Ð²ÐµÐ´Ñ Ð½Ðµ Ð·Ð½Ð°ÐºÐ¾Ð¼Ñ Ñ Ð±ÑÐ°ÑÐ¾Ð¼ Ð¢Ð¾Ð¼Ð°? \n    target text: You don't know Tom's brother, do you?\n    generated text: Aren't you familiar with Tom's brother?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the meaning of the input text and the target text without introducing any nonsensical or factually incorrect information. It stays true to the context and does not add any unsupported details. Therefore, it is not a hallucination.\nThis is the probability assigned by the translator: 0.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð¢Ð¾Ð¼ Ð½ÐµÑÐµÑÐ¸ÑÐµÐ»ÐµÐ½. \n    target text: Tom is indecisive.\n    generated text: That's unacceptable.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Hallucination\".\nHere is the reasoning the translator provided: The generated text Thats unacceptable does not accurately reflect the meaning of the input text Ð¢Ð¾Ð¼ Ð½ÐµÑÐµÑÐ¸ÑÐµÐ»ÐµÐ½ which translates to Tom is indecisive. The generated text contains different words and conveys a different sentiment, thus it introduces additional information that cannot be supported by the input text or the target text. Therefore, it is a hallucination.\nThis is the probability assigned by the translator: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÑÑ ÑÐµÑÑÐ¸ÑÐ¾ÑÐ¸Ñ ÐÐ°Ð»ÐµÑÑÐ¸Ð½Ñ - ÑÑÐ¾ Ð·ÐµÐ¼Ð»Ñ Ð²ÑÐµÑ Ð¿Ð°Ð»ÐµÑÑÐ¸Ð½ÑÐµÐ². \n    target text: Palestine, all of it, is the land of all the Palestinians.\n    generated text: The entire territory of Palestine is the land of all Palestinians.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately conveys the main idea of the input and target texts, stating that the entire territory of Palestine belongs to all Palestinians. There are no nonsensical or factually incorrect information in the generated text, and it does not contain any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the translator: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð¯ Ð¼Ð¾Ð³Ñ Ð¿ÑÐ¾Ð¹ÑÐ¸ Ð·Ð° ÐºÑÐ»Ð¸ÑÑ? \n    target text: Can I come backstage?\n    generated text: Can I go for a walk?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Hallucination\".\nHere is the reasoning the translator provided: The generated text Can I go for a walk? does not accurately convey the meaning of the original text Ð¯ Ð¼Ð¾Ð³Ñ Ð¿ÑÐ¾Ð¹ÑÐ¸ Ð·Ð° ÐºÑÐ»Ð¸ÑÑ? which means Can I come backstage? The generated text introduces nonsensical information that is not supported by the input text or the target text, resulting in a hallucination.\nThis is the probability assigned by the translator: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÐ¿ÑÑÑ Ñ Ð¿ÑÐ¾ÑÐ¿Ð°Ð»! \n    target text: I've overslept again.\n    generated text: I woke up again!\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text I woke up again! accurately captures the meaning of the input text ÐÐ¿ÑÑÑ Ñ Ð¿ÑÐ¾ÑÐ¿Ð°Ð»! and the target text Ive overslept again. There are no nonsensical or factually incorrect information in the generated text, and it does not contain any additional information beyond the input and target texts. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the translator: 0.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÑÐ´ÐµÐ¼ Ð½Ð°Ð´ÐµÑÑÑÑÑ, Ð² ÑÑÐ¾Ð¼ Ð³Ð¾Ð´Ñ Ð½Ðµ ÑÐ»ÑÑÐ¸ÑÑÑ ÑÐ¾ Ð¶Ðµ ÑÐ°Ð¼Ð¾Ðµ. \n    target text: Let's hope the same thing doesn't happen this year.\n    generated text: Hopefully this year wonât be the same thing.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text captures the main idea of hoping for a different outcome this year, similar to the target text. It doesnt contain any nonsensical information or additional unsupported details. The only difference is the word order and slight rephrasing, but the core meaning remains consistent with the input and target texts.\nThis is the probability assigned by the translator: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð¡ÑÐ¾Ðº Ð´ÐµÐ¹ÑÑÐ²Ð¸Ñ Ð²Ð¾Ð´Ð¸ÑÐµÐ»ÑÑÐºÐ¸Ñ Ð¿ÑÐ°Ð² Ð¢Ð¾Ð¼Ð° Ð¸ÑÑÐµÐº. \n    target text: Tom's driver's license has expired.\n    generated text: The duration of Tomâs driving rights expired.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the meaning of the input and target text, indicating that Toms drivers license has expired. There are no nonsensical or factually incorrect details in the generated text, and it does not contain any additional unsupported information. Therefore, it does not meet the criteria for hallucination.\nThis is the probability assigned by the translator: 0.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Â«ÐÐ¾ Ñ Ð½Ð¸ÑÐµÐ³Ð¾ Ð½Ðµ Ð´ÐµÐ»Ð°Ð»!Â» â Â«ÐÐ½ Ð²ÑÑÑ!Â» \n    target text: But I didn't do anything! \"He's lying!\"\n    generated text: âBut I didnât do anything!â he said.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the meaning and tone of the input and target texts. It does not contain any nonsensical or factually incorrect information, and it does not introduce any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the translator: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÐ¾ÑÐ¾Ð¶Ðµ, ÑÑÐ¾ Ð¾Ð³ÑÐ°Ð±Ð»ÐµÐ½Ð¸Ðµ Ð±Ð°Ð½ÐºÐ° Ð±ÑÐ»Ð¾ ÑÐ¿Ð»Ð°Ð½Ð¸ÑÐ¾Ð²Ð°Ð½Ð¾ Ð²Ð¿Ð»Ð¾ÑÑ Ð´Ð¾ Ð¼ÐµÐ»Ð¾ÑÐµÐ¹. \n    target text: It appears that the bank robbery was planned right down to the last detail.\n    generated text: It seems that the bankâs budget was designed to go back to the middle.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Hallucination\".\nHere is the reasoning the translator provided: The generated text contains additional information that cannot be supported by the input text or the target text. It introduces the concept of the banks budget, which is not present in the original text or the target translation. This additional information changes the meaning of the sentence and introduces a new element not present in the source or target. Therefore, it is a hallucination.\nThis is the probability assigned by the translator: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÐ½ÑÐµÑÐµÑÐ½Ð¾, ÑÑÐ¾ Ð¢Ð¾Ð¼ Ð¿ÑÐ¸Ð³Ð¾ÑÐ¾Ð²Ð¸Ñ Ð½Ð° ÑÐ¶Ð¸Ð½. \n    target text: I wonder what Tom will make for dinner.\n    generated text: It's interesting Tom's getting ready for dinner.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the sense of curiosity expressed in the input text and the target text. It does not contain any nonsensical or factually incorrect information, nor does it introduce any additional unsupported details. The only difference is a slight change in wording, but the meaning remains consistent with the original intent. Therefore, it is not a hallucination.\nThis is the probability assigned by the translator: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð¯ Ð¿ÑÐ¾ÑÐ»ÐµÐ¶Ñ, ÑÑÐ¾Ð±Ñ ÑÑÐ¸ Ð±Ð¾ÑÐ¸Ð½ÐºÐ¸ Ð¿Ð¾ÑÐ¸Ð½Ð¸Ð»Ð¸ Ð´Ð¾ Ð·Ð°Ð²ÑÑÐ°. \n    target text: I'll get these shoes fixed by tomorrow.\n    generated text: I'm gonna make sure these shoes don't die until tomorrow.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Hallucination\".\nHere is the reasoning the translator provided: The generated text contains additional information that cannot be supported by the input text or the target text. The statement Im gonna make sure these shoes dont die until tomorrow introduces an unsupported notion of shoes dying, which is not present in the original text or the target text. This extra information constitutes hallucination.\nThis is the probability assigned by the translator: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð¡Ð½Ð°ÑÑÐ¶Ð¸ ÐµÑÑ ÑÐ²ÐµÑÐ»Ð¾. \n    target text: It is still light outside.\n    generated text: Get some more light.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Hallucination\".\nHere is the reasoning the translator provided: The generated text Get some more light does not accurately convey the original meaning It is still light outside. Additionally, it introduces the concept of obtaining more light, which is not supported by the input or target text. Therefore, it contains both nonsensical information and introduces unsupported content, making it a hallucination.\nThis is the probability assigned by the translator: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð¢Ð¾Ð¼ ÑÐ¾Ð»ÑÐºÐ¾ ÑÑÐ¾ Ð²ÑÑÐµÐ» Ð¸Ð· ÑÑÑÑÐ¼Ñ. \n    target text: Tom just got out of jail.\n    generated text: That's just what came out of prison.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Hallucination\".\nHere is the reasoning the translator provided: The generated text Thats just what came out of prison. contains additional information that cannot be supported by the input text or the target text. It adds the word just and changes the meaning of the sentence. The original meaning Tom just got out of jail is lost in the generated text, making it a hallucination.\nThis is the probability assigned by the translator: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÐ°ÑÐµÐ¼ Ð¢Ð¾Ð¼Ñ Ð²ÑÑ ÑÑÐ¾? \n    target text: Why does Tom need all this?\n    generated text: Why is that all?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Hallucination\".\nHere is the reasoning the translator provided: The generated text Why is that all? does not accurately convey the meaning of the input and target text Why does Tom need all this?. It not only lacks the specificity of Tom and need, but also introduces an unsupported is and that which are not present in the original text. Therefore, it contains additional information that cannot be supported by the input text or the target text, making it a hallucination.\nThis is the probability assigned by the translator: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÐ»Ð°ÑÑÑ Ð² ÑÑÐºÐ°Ñ Ð¢Ð¾Ð¼Ð°. \n    target text: The power rests with Tom.\n    generated text: Power in Tom's hands.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the essence of the input text and the target text, expressing the same idea in a slightly different way. There are no nonsensical or factually incorrect information, and no additional unsupported information present. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the translator: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð¯ ÑÑÐ²ÑÑÐ²ÑÑ ÑÐµÐ±Ñ Ð°Ð¼ÑÐ±Ð¾Ð¹. \n    target text: I feel like an amoeba.\n    generated text: I feel good about myself.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Hallucination\".\nHere is the reasoning the translator provided: The generated text I feel good about myself is a completely different statement from the target text I feel like an amoeba and the input text Ð¯ ÑÑÐ²ÑÑÐ²ÑÑ ÑÐµÐ±Ñ Ð°Ð¼ÑÐ±Ð¾Ð¹. It introduces new information not present in the original text, making it factually incorrect and containing additional unsupported information, thus qualifying as a hallucination.\nThis is the probability assigned by the translator: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð¢Ð¾Ð¼ Ð¾ÑÐµÐ½Ñ Ð±ÑÑÑÑÐ¾ Ð±ÐµÐ¶Ð¸Ñ. \n    target text: Tom is running very fast.\n    generated text: I don't know it.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Hallucination\".\nHere is the reasoning the translator provided: The generated text I dont know it does not accurately translate the input text Ð¢Ð¾Ð¼ Ð¾ÑÐµÐ½Ñ Ð±ÑÑÑÑÐ¾ Ð±ÐµÐ¶Ð¸Ñ (Tom is running very fast) or convey any relevant information from the target text. It not only fails to provide a proper translation but also introduces non-existent information, making it factually incorrect and nonsensical. Therefore, it can be classified as a hallucination.\nThis is the probability assigned by the translator: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÐ¾ÑÐ»Ðµ Ð²ÑÐµÐ³Ð¾, ÑÑÐ¾ Ð¾Ð½Ð° ÑÐ´ÐµÐ»Ð°Ð»Ð° Ð´Ð»Ñ ÐºÐ¾Ð¼Ð¿Ð°Ð½Ð¸Ð¸, ÐµÑ ÑÐ²Ð¾Ð»ÑÐ½ÐµÐ½Ð¸Ðµ ÑÑÐ°Ð»Ð¾ Ð½Ð°ÑÑÐ¾ÑÑÐµÐ¹ Ð¿Ð¾ÑÐµÑÐ¸Ð½Ð¾Ð¹. \n    target text: Her being fired was a real slap in the face after everything she did for the company.\n    generated text: After everything she did for the company, her release became a real bust.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Hallucination\".\nHere is the reasoning the translator provided: The generated text her release became a real bust contains additional information that cannot be supported by the input text or the target text. The word release is not an appropriate term to describe her departure from the company, and bust does not convey the same meaning as slap in the face in the context provided. Therefore, the generated text introduces unsupported information and is not a faithful translation of the original meaning.\nThis is the probability assigned by the translator: 0.9\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÑ Ñ Ð¢Ð¾Ð¼Ð¾Ð¼ ÐºÐ°Ðº ÑÐ°Ð· Ð²ÑÐµÑÐ° ÑÑÐ¾ Ð¾Ð±ÑÑÐ¶Ð´Ð°Ð»Ð¸. \n    target text: Tom and I were discussing that just yesterday.\n    generated text: We talked to Tom about it once yesterday.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the essence of the input text and the target text by conveying the same meaning of discussing something with Tom just yesterday. There are no nonsensical or factually incorrect information in the generated text, and it does not contain any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the translator: 0.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÑ Ð²ÐµÐ´Ñ ÑÑÐµÐ»Ð¸ Ð½Ðµ Ð²ÑÑ Ð¿ÐµÑÐµÐ½ÑÐµ? \n    target text: You haven't eaten all the cookies, have you?\n    generated text: You didn't eat all the liver?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Hallucination\".\nHere is the reasoning the translator provided: The generated text You didnt eat all the liver? is a hallucination because it introduces nonsensical and factually incorrect information. The target text mentions cookies while the generated text substitutes cookies with liver, which is factually incorrect and not supported by the input or target text.\nThis is the probability assigned by the translator: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð¢Ñ Ð² Ð¿Ð¾ÑÐ»ÐµÐ´Ð½ÐµÐµ Ð²ÑÐµÐ¼Ñ ÑÐ°Ð¼Ð° Ð½Ðµ ÑÐ²Ð¾Ñ. \n    target text: You haven't been yourself lately.\n    generated text: You're not your own lately.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately conveys the main idea and sentiment of the original text and the target text. It captures the sense of not being oneself lately, although with a slightly different phrasing. There are no nonsensical or factually incorrect information in the generated text, and it does not contain any additional information beyond the scope of the input and target texts. Therefore, it is not a hallucination.\nThis is the probability assigned by the translator: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð¯ Ð»ÑÑÑÐµ Ð´Ð¾Ð¼Ð¾Ð¹ Ð¿Ð¾Ð¹Ð´Ñ. \n    target text: I'd rather go home.\n    generated text: I'm better home tomorrow.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Hallucination\".\nHere is the reasoning the translator provided: The generated text Im better home tomorrow contains additional information that cannot be supported by the input text or the target text. There is no mention of tomorrow in the input or target text, and the word better is used in a different context in the generated text. Therefore, the generated text is factually incorrect and contains additional unsupported information, making it a hallucination.\nThis is the probability assigned by the translator: 0.9\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÐ°Ðº ÑÑÐ¾ Ð²ÐºÐ»ÑÑÐ°ÐµÑÑÑ? \n    target text: How do you turn this thing on?\n    generated text: How does this include?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Hallucination\".\nHere is the reasoning the translator provided: The generated text How does this include? does not convey the correct meaning of the input text ÐÐ°Ðº ÑÑÐ¾ Ð²ÐºÐ»ÑÑÐ°ÐµÑÑÑ? or the target text How do you turn this thing on?. It does not accurately represent the process of turning something on. The word include is unrelated to the context of turning on a device, and it introduces a different action altogether. Therefore, the generated text contains nonsensical and factually incorrect information, making it a hallucination.\nThis is the probability assigned by the translator: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð¢Ð¾Ð¼ ÑÑÑÐ» Ð²Ð¾Ð²ÑÐµÐ¼Ñ. \n    target text: Tom left on time.\n    generated text: Tom's gone in time.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Hallucination\".\nHere is the reasoning the translator provided: The generated text Toms gone in time introduces the possessive form Toms which is not present in the input or target text. Additionally, the use of gone instead of left changes the meaning and tense of the sentence, which is not supported by the input and target texts. These changes introduce new information that is not present in the original text, making it a hallucination.\nThis is the probability assigned by the translator: 0.9\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð£Ð¼ÐµÐ½Ð¸Ðµ ÑÐ»ÑÑÐ°ÑÑ ÐµÐ¼Ñ Ð½Ðµ Ð¿ÑÐ¸ÑÑÑÐµ. \n    target text: Listening is not his forte.\n    generated text: The ability to listen to him is not present.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the meaning of the input text and the target text. It does not contain any nonsensical or factually incorrect information, and it does not introduce any additional unsupported information. The translation The ability to listen to him is not present aligns with the original meaning Listening is not his forte from the input and target texts.\nThis is the probability assigned by the translator: 0.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÐ½ÑÑÑÑÐºÑÐ¸Ð¸ Ð±ÑÐ»Ð¸ Ð²ÑÐµ Ð½Ð° ÐºÐ¸ÑÐ°Ð¹ÑÐºÐ¾Ð¼. \n    target text: The instructions were all in Chinese.\n    generated text: It's a lot of people.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Hallucination\".\nHere is the reasoning the translator provided: The generated text Its a lot of people does not accurately reflect the content of the input text ÐÐ½ÑÑÑÑÐºÑÐ¸Ð¸ Ð±ÑÐ»Ð¸ Ð²ÑÐµ Ð½Ð° ÐºÐ¸ÑÐ°Ð¹ÑÐºÐ¾Ð¼ (The instructions were all in Chinese) or the target text The instructions were all in Chinese. There is no logical connection between the input, the target, and the generated text. The generated text introduces information that is completely unrelated to the input or the target and does not provide any relevant or coherent translation. Therefore, it is a hallucination.\nThis is the probability assigned by the translator: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð§ÐµÐ³Ð¾ Ð±Ñ Ñ ÑÐ¾Ð»ÑÐºÐ¾ Ð½Ð¸ Ð¾ÑÐ´Ð°Ð», ÑÑÐ¾Ð±Ñ Ð²ÐµÑÐ½ÑÑÑ ÑÑÐ¸ Ð³Ð¾Ð´Ñ! \n    target text: And what wouldn't I give for these years to come back.\n    generated text: I donât want to give anything back to these years!\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Hallucination\".\nHere is the reasoning the translator provided: The generated text contradicts the meaning of the input and target texts. The input text expresses a strong desire to have the years back, while the generated text states the opposite, indicating no willingness to give anything back. This contradicts the sentiment conveyed in the input and target texts, making it a hallucination.\nThis is the probability assigned by the translator: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð ÑÑÑÐºÐ¾Ðµ ÑÐ»Ð¾Ð²Ð¾ \"ÑÑÐ¼Ð°ÑÐºÐ°\" Ð¸Ð¼ÐµÐµÑ Ð½Ð¸Ð´ÐµÑÐ»Ð°Ð½Ð´ÑÐºÐ¾Ðµ Ð¿ÑÐ¾Ð¸ÑÑÐ¾Ð¶Ð´ÐµÐ½Ð¸Ðµ. \n    target text: The Russian word for \"fair\", namely \"ÑÑÐ¼Ð°ÑÐºÐ°\", is Dutch in origin.\n    generated text: The Russian word \"yardmark\" has Dutch origin.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Hallucination\".\nHere is the reasoning the translator provided: The generated text incorrectly translates ÑÑÐ¼Ð°ÑÐºÐ° as yardmark, which is nonsensical and factually incorrect. Additionally, it introduces new information by stating that the word has Dutch origin, which is not supported by the input text or the target text. Therefore, the generated text is a hallucination.\nThis is the probability assigned by the translator: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð¢Ð¾Ð¼ Ð¿ÑÐ¾Ð²ÐµÑÐ¸Ð» ÑÐ¿Ð¸ÑÐ¾Ðº. \n    target text: Tom checked the list.\n    generated text: That's what I've done.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Hallucination\".\nHere is the reasoning the translator provided: The generated text Thats what Ive done does not accurately convey the action of checking the list as in the input and target texts. It also introduces additional information not present in the original text, indicating a departure from the original meaning. Therefore, it is a hallucination.\nThis is the probability assigned by the translator: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð¢Ñ Ð¾Ð±ÑÐ°ÑÐ¸Ð»ÑÑ Ð² ÑÑÐ¸ÑÑÐ¸Ð°Ð½ÑÑÐ²Ð¾. \n    target text: You converted to Christianity.\n    generated text: It's a lot of people.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Hallucination\".\nHere is the reasoning the translator provided: The generated text Its a lot of people does not accurately convey the meaning of the input text Ð¢Ñ Ð¾Ð±ÑÐ°ÑÐ¸Ð»ÑÑ Ð² ÑÑÐ¸ÑÑÐ¸Ð°Ð½ÑÑÐ²Ð¾ (You converted to Christianity) and does not align with the target text. It introduces nonsensical information that is not supported by the input or target text, making it a hallucination.\nThis is the probability assigned by the translator: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð¯ Ð·Ð½Ð°Ñ, ÑÑÐ¾ ÑÑ ÑÑÐ¾ Ð½Ðµ ÑÐ¿ÐµÑÐ¸Ð°Ð»ÑÐ½Ð¾. \n    target text: I know that it wasn't intentional.\n    generated text: I know you're not special.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Hallucination\".\nHere is the reasoning the translator provided: The generated text I know youre not special contains additional information that cannot be supported by the input text or the target text. It introduces the concept of not being special, which is not present in the original text or the target translation. This additional information constitutes a hallucination.\nThis is the probability assigned by the translator: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÐ·-Ð·Ð° Ð½Ð¸Ñ Ð¢Ð¾Ð¼Ñ Ð¿ÑÐ¸ÑÐ»Ð¾ÑÑ Ð¿Ð¾Ð¼ÐµÐ½ÑÑÑ ÑÐ²Ð¾Ñ Ð¼Ð½ÐµÐ½Ð¸Ðµ. \n    target text: They made Tom change his mind.\n    generated text: Because of this, he had to change his mind.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the essence of the input text and the target text, conveying the same idea that Tom had to change his mind. There are no nonsensical or factually incorrect information in the generated text, and it does not introduce any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the translator: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÐ¾Ð³Ð´Ð° Ñ Ð¿Ð¾Ð»ÑÐ·Ð¾Ð²Ð°Ð»ÑÑ ÐºÑÐµÑÐ¾ÐºÑÐ¾Ð¼, Ð¾Ð½ ÑÐ»Ð¾Ð¼Ð°Ð»ÑÑ. \n    target text: I was using the photocopier when it broke.\n    generated text: When I used xerox, it broke down.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the action of using the photocopier and its subsequent malfunction, in line with both the input and target texts. It does not introduce any nonsensical information or additional details that are not supported by the input or target text, hence it is not a hallucination.\nThis is the probability assigned by the translator: 0.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÐ° Ð³Ð´Ðµ ÑÐ³Ð¾Ð´Ð½Ð¾ Ð¿Ð¾Ð»Ð¾Ð¶Ð¸. \n    target text: Just put it anywhere.\n    generated text: Yeah, wherever you go.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Hallucination\".\nHere is the reasoning the translator provided: The generated text Yeah, wherever you go. does not accurately convey the meaning of the input text ÐÐ° Ð³Ð´Ðµ ÑÐ³Ð¾Ð´Ð½Ð¾ Ð¿Ð¾Ð»Ð¾Ð¶Ð¸ and the target text Just put it anywhere. It not only fails to preserve the meaning but also introduces a different context that suggests movement or travel, which is not present in the original text. Therefore, the generated text contains additional information that cannot be supported by the input text or the target text, making it a hallucination.\nThis is the probability assigned by the translator: 0.95\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð¯Ð´ÑÑÐ½ Ð±Ð°ÑÐ¾Ð½! \n    target text: Blimey!\n    generated text: Nuclear Baton!\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Hallucination\".\nHere is the reasoning the translator provided: The generated text Nuclear Baton! contains additional information that cannot be supported by the input text or the target text. It introduces the concept of nuclear which is not present in the input or the target text. This additional information makes the generated text a hallucination.\nThis is the probability assigned by the translator: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð­ÑÐ¾ Ð±ÑÐ»Ð¾ ÑÐ»Ð¸ÑÐºÐ¾Ð¼ Ð¿ÑÐ¾ÑÑÐ¾? \n    target text: Was that too easy?\n    generated text: What are you doing?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Hallucination\".\nHere is the reasoning the translator provided: The generated text What are you doing? does not accurately reflect the meaning of the input text Ð­ÑÐ¾ Ð±ÑÐ»Ð¾ ÑÐ»Ð¸ÑÐºÐ¾Ð¼ Ð¿ÑÐ¾ÑÑÐ¾? or the target text Was that too easy? There is no connection between the content of the input and target texts and the generated text. Therefore, the generated text contains nonsensical information and is not supported by the input or target text, making it a hallucination.\nThis is the probability assigned by the translator: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÑ Ð¸Ð·Ð²Ð¸Ð½Ð¸Ð»Ð¸ÑÑ Ð¿ÐµÑÐµÐ´ Ð¢Ð¾Ð¼Ð¾Ð¼. \n    target text: We apologized to Tom.\n    generated text: It's a lot of people.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Hallucination\".\nHere is the reasoning the translator provided: The generated text Its a lot of people does not convey the same meaning as the target text We apologized to Tom and adds nonsensical information that is not supported by the input or target text. There is no mention of a lot of people in the input or target text, making it factually incorrect and containing additional information that cannot be supported. Therefore, it is a hallucination.\nThis is the probability assigned by the translator: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÐ°ÐºÐ°Ñ Ð¸Ð· Ð½Ð¸Ñ ÑÑ? \n    target text: Which one is you?\n    generated text: Which one of them are you?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the meaning of the input and target texts without adding any nonsensical or factually incorrect information. It simply uses a different word order to convey the same meaning. Therefore, it is not a hallucination.\nThis is the probability assigned by the translator: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð¢Ñ Ð±Ñ Ð½Ð° Ð¼Ð¾ÑÐ¼ Ð¼ÐµÑÑÐµ Ð¿Ð¾ÑÑÑÐ¿Ð¸Ð» ÑÐ°Ðº Ð¶Ðµ. \n    target text: You would've done the same thing if you were me.\n    generated text: You would have done the same in my place.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the meaning and intent of the input text and the target text. It does not contain any nonsensical or factually incorrect information, and it does not introduce any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the translator: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð¯ ÑÐµÐ±Ñ Ð¿ÑÐ¸ÐºÑÑÐ». \n    target text: I've got you covered.\n    generated text: I covered you.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the main meaning and intent of the input text and the target text. It does not contain any nonsensical or factually incorrect information, and it does not introduce any additional unsupported information. Therefore, it is consistent with the given inputs and targets.\nThis is the probability assigned by the translator: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð¯ ÑÑÐ¾Ñ ÑÑÐµÐº Ð½Ð° ÑÐµÐ¿Ð¸Ñ Ð¿Ð¾ÑÑÐ°Ð²Ð¸Ð». \n    target text: I put this track on repeat.\n    generated text: I put this track on the shelf.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Hallucination\".\nHere is the reasoning the translator provided: The generated text I put this track on the shelf introduces new and factually incorrect information compared to the input and target texts. It changes the action from on repeat to on the shelf, which is not supported by the original text. This is a clear case of hallucination as it alters the original meaning.\nThis is the probability assigned by the translator: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÐ°Ð²Ð°Ð¹ÑÐµ Ð½Ðµ Ð±ÑÐ´ÐµÐ¼ ÑÐ¿ÐµÑÐ¸ÑÑ. \n    target text: Let's take our time.\n    generated text: Let's not hurry.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the meaning of the input text and the target text without adding any nonsensical or factually incorrect information. It simply conveys the idea of not rushing, which aligns with the intended meaning of Lets take our time. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the translator: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð¢Ñ Ð¿Ð¾ÑÐ¾Ð¼ ÐµÑÑ Ð¿ÑÐ¸Ð´ÑÑÑ? \n    target text: Will you come back later?\n    generated text: Then you'll come again?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the essence of the input text and target text, maintaining the question about coming back later without introducing any nonsensical or factually incorrect information. Therefore, it is not a hallucination.\nThis is the probability assigned by the translator: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÐ¾ÑÐ»Ðµ ÑÐ¾Ð³Ð¾ Ð¢Ð¾Ð¼ Ð½Ð¸ÐºÐ¾Ð³Ð´Ð° Ð½Ðµ Ð²Ð¸Ð´ÐµÐ» ÐÑÑÐ¸. \n    target text: Tom never saw Mary after that.\n    generated text: Then Tom never saw Mary.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the main idea of the input and target texts without adding any nonsensical or factually incorrect information. It simply omits the word after that, which does not significantly alter the meaning of the sentence. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the translator: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð¡Ð¾Ð±Ð°ÐºÑ Ð¿Ð¾ÐºÐ¾ÑÐ¼Ð¸Ð»Ð¸? \n    target text: Has anyone fed the dog?\n    generated text: Did they feed the dog?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the meaning and intent of the input and target text. It does not contain any nonsensical or factually incorrect information, nor does it introduce any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the translator: 0.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð¯ Ð½Ð¸ÑÐµÐ¼ Ð½Ðµ Ð¼Ð¾Ð³Ñ Ð¿Ð¾Ð¼Ð¾ÑÑ Ð¢Ð¾Ð¼Ñ. \n    target text: There's nothing I can do to help Tom.\n    generated text: I can't help Tom.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the main idea of the input text and the target text, which is the inability to help Tom. It doesnt introduce any nonsensical or factually incorrect information and doesnt contain any additional unsupported details. Therefore, it is not a hallucination.\nThis is the probability assigned by the translator: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÐ°Ð¼ Ð¿Ð¾Ð¹ÑÐ¸? \n    target text: Should we go?\n    generated text: Let's go?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text Lets go? is a valid and natural response to the input text ÐÐ°Ð¼ Ð¿Ð¾Ð¹ÑÐ¸? which translates to Should we go? in English. The generated text does not contain any nonsensical or factually incorrect information, and it does not introduce any additional unsupported information. Therefore, it is consistent with the input and target texts and does not qualify as a hallucination.\nThis is the probability assigned by the translator: 0.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð¯ Ð¾Ð±ÑÑÐ½Ð¾ Ð¿ÑÐ¸ÑÐ¾Ð¶Ñ Ð½Ð° ÑÐ°Ð±Ð¾ÑÑ Ð¿ÐµÑÐ²ÑÐ¼. \n    target text: I'm usually the first one to get to work.\n    generated text: I usually go to work first.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the main idea of the input text and the target text, which is about being the first one to arrive at work. It does not contain any nonsensical or factually incorrect information, nor does it introduce any additional unsupported details. Therefore, it is not a hallucination.\nThis is the probability assigned by the translator: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÐ°Ð»Ñ, ÑÑÐ¾ Ñ Ð½Ðµ ÑÐ°ÐºÐ¾Ð¹ ÑÑÐ°Ð±ÑÑÐ¹, ÐºÐ°Ðº Ð¢Ð¾Ð¼. \n    target text: I wish I were as brave as Tom is.\n    generated text: I'm sorry I'm not as brave as Tom.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the meaning of the input text and the target text without adding any nonsensical or factually incorrect information. It maintains the essence of the original sentence and does not introduce any additional unsupported details. Therefore, it is not a hallucination.\nThis is the probability assigned by the translator: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÑÐ´Ð¸ ÑÐ²Ð¾Ð±Ð¾Ð´Ð½Ñ. \n    target text: The people are free.\n    generated text: People are free.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text People are free is a simplification of the target text The people are free and still conveys the same essential meaning without any nonsensical or factually incorrect information. There is no additional information in the generated text that cannot be supported by the input text or the target text. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the translator: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÐ° Ð½Ð°Ñ Ð¼Ð½Ð¾Ð³Ð¸Ðµ ÑÐ°ÑÑÑÐ¸ÑÑÐ²Ð°ÑÑ. \n    target text: Many people rely on us.\n    generated text: Many expect us.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text Many expect us is a valid interpretation of the input text ÐÐ° Ð½Ð°Ñ Ð¼Ð½Ð¾Ð³Ð¸Ðµ ÑÐ°ÑÑÑÐ¸ÑÑÐ²Ð°ÑÑ and the target text Many people rely on us. It conveys a similar meaning and does not introduce any nonsensical or factually incorrect information. The slight difference in wording does not change the overall meaning or introduce any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the translator: 0.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð¢Ð¾Ð¼ Ñ Ð¼ÐµÐ½Ñ ÑÐ°Ð¼ÑÐ¹ Ð¼Ð»Ð°Ð´ÑÐ¸Ð¹. \n    target text: Tom is my youngest.\n    generated text: I have the youngest Tom.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the main meaning of the input text and the target text without introducing any nonsensical or factually incorrect information. It simply reorders the words from the target text and does not add any extra information. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the translator: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð¢Ð¾Ð¼ Ð²ÑÑÑÐ¸Ð» Ð½Ð¾Ð²Ð¾Ðµ ÑÐ»Ð¾Ð²Ð¾. \n    target text: Tom learned a new word.\n    generated text: I found a new book.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Hallucination\".\nHere is the reasoning the translator provided: The generated text I found a new book contains factually incorrect information as it introduces a new element book which is not present in the input or the target text. This additional information cannot be supported by the given inputs and targets, making it a hallucination.\nThis is the probability assigned by the translator: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð¢Ð²Ð¾Ð¸ ÑÑÐ½Ð¾Ð²ÑÑ Ð´Ð¾Ð²Ð¾Ð»ÑÐ½Ð¾ ÑÐ¸Ð¼Ð¿Ð°ÑÐ¸ÑÐ½ÑÐµ. \n    target text: Your sons are quite handsome.\n    generated text: Your children are pretty nice to you.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Hallucination\".\nHere is the reasoning the translator provided: The generated text Your children are pretty nice to you contains additional information that cannot be supported by the input text or the target text. The input text specifically mentions ÑÑÐ½Ð¾Ð²ÑÑ which translates to sons, and the target text translates to Your sons are quite handsome, indicating that the context is about sons, not children in general. Therefore, the addition of children in the generated text is not supported by the input or target text, making it a hallucination.\nThis is the probability assigned by the translator: 0.9\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð¯ Ð¿Ð¾Ð»Ð¾Ð²Ð¸Ð½Ñ Ð½Ð¾ÑÐ¸ Ð½Ðµ ÑÐ¿Ð°Ð»Ð°. \n    target text: I was up half the night.\n    generated text: I didn't sleep for half a night.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the meaning of the input text and the target text without adding any nonsensical or factually incorrect information. It conveys the same idea that the person did not sleep for a significant portion of the night, which aligns with the target text. Therefore, there is no hallucination in the generated text.\nThis is the probability assigned by the translator: 0.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð Ð³Ð¾ÑÑÐ¸Ð½Ð¾Ð¹ Ð±ÑÐ» Ð¾Ð³ÑÐ¾Ð¼Ð½ÑÐ¹ Ð¿Ð°ÑÐº. \n    target text: In the living room there was a huge spider.\n    generated text: There was a huge spider in the hotel.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Hallucination\".\nHere is the reasoning the translator provided: The generated text contains additional information that cannot be supported by the input text or the target text. The input text mentions a living room, while the generated text introduces a hotel, which is not supported by the input or target text. This is an additional unsupported detail and therefore qualifies as a hallucination.\nThis is the probability assigned by the translator: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÐ°Ðº Ð½Ð°Ð¼ Ð¿Ð¾Ð¿Ð°ÑÑÑ Ð² ÐºÐ¾Ð¼Ð°Ð½Ð´Ñ? \n    target text: How can we join the team?\n    generated text: How do we get to the team?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the meaning of the input text and the target text without introducing any nonsensical or factually incorrect information. It simply uses a different phrasing to express the same idea. There is no additional unsupported information in the generated text. Therefore, it is not a hallucination.\nThis is the probability assigned by the translator: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÐ¾Ð³Ð´Ð° Ñ Ð¼ÐµÐ½Ñ Ð¿Ð»Ð¾ÑÐ¾Ðµ Ð½Ð°ÑÑÑÐ¾ÐµÐ½Ð¸Ðµ, Ñ Ð»ÑÐ±Ð»Ñ Ð¿Ð¾Ð´ÑÐ¼Ð°ÑÑ Ð¾ Ð³Ð¾ÑÐ½Ð¾ÑÑÐ°ÑÑ, ÑÑÐ¾Ð±Ñ Ð¿ÑÐ¸Ð¾Ð±Ð¾Ð´ÑÐ¸ÑÑÑÑ. \n    target text: When I'm in a bad mood, I like to think of stoats to cheer myself up.\n    generated text: When I have a bad mood, I like to think about pride in order to get bored.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Hallucination\".\nHere is the reasoning the translator provided: The generated text contains nonsensical information as pride is not a relevant concept in this context, and it introduces additional information that cannot be supported by the input or target text. The mention of pride is unrelated to the original idea of thinking about stoats to cheer up, making it a clear hallucination.\nThis is the probability assigned by the translator: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð¡ÐµÐ¹ÑÐ°Ñ Ñ Ð½Ðµ Ð¼Ð¾Ð³Ñ ÑÐµÐ±Ðµ ÑÑÐ¾Ð³Ð¾ Ð¿Ð¾Ð·Ð²Ð¾Ð»Ð¸ÑÑ. \n    target text: I can't afford that right now.\n    generated text: Now I can't afford it.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the meaning of the input text and the target text without adding any nonsensical or factually incorrect information. It stays true to the original meaning and does not introduce any new information. Therefore, it is not a hallucination.\nThis is the probability assigned by the translator: 0.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÐµÑÐµÐ´ ÑÐµÐ¼ ÐºÐ°Ðº Ð²ÑÐ¹ÑÐ¸ Ð¸Ð· Ð´Ð¾Ð¼Ð°, Ñ Ð²ÑÐµÐ³Ð´Ð° Ð·Ð°Ð²ÑÑÐ°ÐºÐ°Ñ. \n    target text: I always have breakfast before leaving home.\n    generated text: Before I get out of the house, I always have breakfast.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the meaning of the input text and the target text without adding any nonsensical or factually incorrect information. It simply rearranges the sentence structure without introducing any new information. Therefore, it is not a hallucination.\nThis is the probability assigned by the translator: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÐ¾Ð¶Ð°Ð»ÑÐ¹ÑÑÐ°, Ð¿ÑÐ¾ÑÑÐ¾ Ð´ÐµÐ»Ð°Ð¹ÑÐµ Ð²ÑÑ, ÐºÐ°Ðº Ñ. \n    target text: Please just do everything I do.\n    generated text: Please, just do everything like me.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the meaning and intent of the input text and the target text without introducing any nonsensical or factually incorrect information. It stays true to the original content and does not add any unsupported details. Therefore, it is not a hallucination.\nThis is the probability assigned by the translator: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÐ½Ð¸ Ð¿ÑÐ¸Ð²ÐµÑÑÑÐ²Ð¾Ð²Ð°Ð»Ð¸ Ð½Ð°Ñ Ñ ÑÐ°ÑÐ¿ÑÐ¾ÑÑÐµÑÑÑÐ¼Ð¸ Ð¾Ð±ÑÑÑÐ¸ÑÐ¼Ð¸. \n    target text: They welcomed us with open arms.\n    generated text: They welcomed us with disillusioned hugs.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Hallucination\".\nHere is the reasoning the translator provided: The generated text disillusioned hugs does not accurately convey the meaning of the original phrase ÑÐ°ÑÐ¿ÑÐ¾ÑÑÐµÑÑÑÐ¼Ð¸ Ð¾Ð±ÑÑÑÐ¸ÑÐ¼Ð¸, which means open arms in English. Additionally, disillusioned implies a feeling of disappointment or loss of faith, which is factually incorrect in the context of the original phrase. Therefore, the generated text contains nonsensical and factually incorrect information, making it a hallucination.\nThis is the probability assigned by the translator: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð¯ Ð¿Ð¾ÑÑÐ¾ÑÐ½Ð½Ð¾ Ð²ÑÐ°Ð» Ð¶ÐµÐ½Ðµ. \n    target text: I lied constantly to my wife.\n    generated text: I've always been mad at my wife.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Hallucination\".\nHere is the reasoning the translator provided: The generated text Ive always been mad at my wife introduces information that is not supported by the input text Ð¯ Ð¿Ð¾ÑÑÐ¾ÑÐ½Ð½Ð¾ Ð²ÑÐ°Ð» Ð¶ÐµÐ½Ðµ (I constantly lied to my wife) and the target text I lied constantly to my wife. There is a significant shift in meaning from lying to being mad, which is not supported by the original text. This additional information constitutes a hallucination.\nThis is the probability assigned by the translator: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÑ ÐµÑÑ Ð´Ð°Ð»ÐµÐºÐ¾ Ð¾Ñ ÑÐµÐ»Ð¸. \n    target text: Our destination is still far away.\n    generated text: We're still far from our goal.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the meaning of the input text and aligns with the general idea expressed in the target text. There are no nonsensical or factually incorrect information in the generated text, and it does not introduce any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the translator: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð¡Ð¾Ð±Ð°ÐºÐ° ÑÐ²Ð¾Ñ. \n    target text: The dog is yours.\n    generated text: Your dog.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text Your dog accurately conveys the possessive relationship indicated in the input text Ð¡Ð¾Ð±Ð°ÐºÐ° ÑÐ²Ð¾Ñ and the target text The dog is yours. While the word order is different, the essential meaning remains the same. There are no nonsensical or factually incorrect information in the generated text, and it does not contain any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the translator: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð¯ Ð¿Ð¾Ð»ÑÑÐ°Ñ Ð´Ð¾ÑÑÐ°ÑÐ¾ÑÐ½Ð¾. \n    target text: I'm paid enough.\n    generated text: I get enough.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the meaning of the input and the target text without adding any nonsensical or factually incorrect information. It stays true to the original message and does not introduce any unsupported details. Therefore, it is not a hallucination.\nThis is the probability assigned by the translator: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÐ°Ð¼ Ð¿ÑÐ¸Ð´ÐµÑÑÑ Ð±Ð°Ð»Ð¾Ð²Ð°ÑÑ ÐÑÑÐ¸, Ð¿Ð¾ÐºÐ° Ð¾Ð½Ð° Ð½Ðµ Ð¿Ð¾Ð¿ÑÐ°Ð²Ð¸ÑÑÑ. \n    target text: We must baby Mary until she gets well again.\n    generated text: We'll have to beat Mary until she gets right.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Hallucination\".\nHere is the reasoning the translator provided: The generated text Well have to beat Mary until she gets right contains a nonsensical and inappropriate action of beating Mary, which is not supported by the input text or the target text. The correct action should be to take care of Mary, not to cause harm. Additionally, the word beat is a significant deviation from the meaning of balovat which means to pamper or indulge. Therefore, the generated text is factually incorrect and contains additional information that cannot be supported by the input text or the target text.\nThis is the probability assigned by the translator: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÐµ Ð¿Ð¾Ð·Ð²Ð¾Ð»ÑÐ¹ Ð´ÐµÑÑÐ¼ Ð¸Ð³ÑÐ°ÑÑ Ð¾ÐºÐ¾Ð»Ð¾ Ð¿ÑÑÐ´Ð°. \n    target text: Don't let the children go near the pond.\n    generated text: Donât let kids play around.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Hallucination\".\nHere is the reasoning the translator provided: The generated text Donât let kids play around contains additional information that cannot be supported by the input text and the target text. The original text mentions Ð¾ÐºÐ¾Ð»Ð¾ Ð¿ÑÑÐ´Ð° which translates to near the pond, but the generated text does not include this important location. Hence, the generated text contains additional information that changes the original meaning and is not supported by the input and target texts.\nThis is the probability assigned by the translator: 0.9\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÐ½Ðµ Ð¿Ð¾ÑÑÐ¸ Ð½ÐµÑÐµÐ³Ð¾ Ð´ÐµÐ»Ð°ÑÑ. \n    target text: I have almost nothing to do.\n    generated text: There's almost nothing I can do.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the meaning of the input text and the target text without adding any nonsensical or factually incorrect information. It simply rephrases the original statement in a slightly different way. There are no additional unsupported details in the generated text.\nThis is the probability assigned by the translator: 0.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð¯ Ð¼Ð¾Ð³Ñ ÐºÐ¾ÑÐ½ÑÑÑÑÑ Ð»Ð°Ð´Ð¾Ð½ÑÐ¼Ð¸ Ð¿Ð¾Ð»Ð°, Ð½Ðµ ÑÐ³Ð¸Ð±Ð°Ñ ÐºÐ¾Ð»ÐµÐ½ÐµÐ¹. \n    target text: I can place the palms of my hands on the floor without bending my knees.\n    generated text: I can touch the elbows of sex without bending my knees.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Hallucination\".\nHere is the reasoning the translator provided: The generated text contains nonsensical information by mentioning the elbows of sex which is not present in the input text or the target text. Additionally, it introduces new, unsupported information that is factually incorrect. The original text is about touching the floor without bending knees, not touching elbows. Therefore, it is a hallucination.\nThis is the probability assigned by the translator: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð¢Ð¾Ð¼ Ð¿ÑÑÐ°ÐµÑÑÑ Ð·Ð°ÑÐ°Ð±Ð¾ÑÐ°ÑÑ Ð½Ð° Ð½Ð¾Ð²ÑÑ ÑÑÑÐ±Ñ. \n    target text: Tom is trying to earn enough money to buy himself a new trumpet.\n    generated text: Tom's trying to make money on a new pipe.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Hallucination\".\nHere is the reasoning the translator provided: The generated text Toms trying to make money on a new pipe contains additional information that cannot be supported by the input text or the target text. There is no mention of making money or a new pipe in the input or target text, and it deviates significantly from the intended meaning of earning enough money to buy himself a new trumpet. Therefore, the generated text is a hallucination.\nThis is the probability assigned by the translator: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð¡ÑÐ¿ ÐµÑÑ Ð½Ðµ Ð¾ÑÑÑÐ». \n    target text: The soup is still hot.\n    generated text: The soup hasn't stayed yet.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Hallucination\".\nHere is the reasoning the translator provided: The generated text The soup hasnt stayed yet does not accurately convey the meaning of the original text Ð¡ÑÐ¿ ÐµÑÑ Ð½Ðµ Ð¾ÑÑÑÐ» and the target text The soup is still hot. Additionally, the phrase hasnt stayed yet is nonsensical and factually incorrect, as it does not make sense in the context of describing the temperature of the soup. Therefore, the generated text contains nonsensical and factually incorrect information, making it a hallucination.\nThis is the probability assigned by the translator: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð ÐµÑÐµÐ½Ð¸Ðµ ÑÐ°ÐºÑÐ¸ÑÐµÑÐºÐ¸Ñ ÑÐ¿ÑÐ°Ð¶Ð½ÐµÐ½Ð¸Ð¹, Ð¿Ð¾Ð½Ð¸Ð¼Ð°Ð½Ð¸Ðµ ÑÐ»Ð¾Ð¶Ð½Ð¾Ð¹ ÐºÐ¾Ð½ÑÐ¾Ð²ÐºÐ¸, Ð½Ð°Ð±Ð»ÑÐ´ÐµÐ½Ð¸Ðµ Ð·Ð° Ð¶Ð¸Ð²ÑÐ¼ Ð¼Ð°ÑÑÐµÐ¼ Ð¸ Ð¿Ð¾Ð¿ÑÑÐºÐ¸ Â«ÑÐ³Ð°Ð´Ð°ÑÑÂ» ÑÐ¾Ð´Ñ, ÐºÐ¾ÑÐ¾ÑÑÐµ Ð±ÑÐ´ÑÑ ÑÑÐ³ÑÐ°Ð½Ñ. ÐÑÑ ÑÑÐ¾ Ð²ÐµÑÐµÐ»Ð¾. \n    target text: Solving a tactical exercise, understanding a difficult ending, following a live match and trying to \"guess\" the moves that will be played. All of this is fun.\n    generated text: The solution of tactical exercises, understanding complex endings, watching the live match and trying to \"imagine\" the steps that will be played. All this fun.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the main ideas and concepts from the input text and the target text. There are no nonsensical or factually incorrect information, and the additional information in the generated text is supported by the input and target texts. Therefore, it is not a hallucination.\nThis is the probability assigned by the translator: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð¯ Ð¿ÑÐ¸Ð½ÑÑ ÑÑÐ¾ ÑÐµÐ±Ðµ. \n    target text: I brought this for you.\n    generated text: I'll bring it to you.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Hallucination\".\nHere is the reasoning the translator provided: The generated text Ill bring it to you contains additional information (Ill and it) that cannot be supported by the input text Ð¯ Ð¿ÑÐ¸Ð½ÑÑ ÑÑÐ¾ ÑÐµÐ±Ðµ and the target text I brought this for you. The verb bring is also a different tense from the original brought, so the meaning is altered. Therefore, the generated text is a hallucination.\nThis is the probability assigned by the translator: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð ÑÐ¸ ÐÐ¾Ð¿ÐµÑ Ð´Ðµ Ð¡ÐµÐ³ÑÑÐ°, ÑÐ²ÑÑÐµÐ½Ð½Ð¸Ðº Ð¸ Ð¸Ð·Ð²ÐµÑÑÐ½ÑÐ¹ Ð¸ÑÐ¿Ð°Ð½ÑÐºÐ¸Ð¹ ÑÐ°ÑÐ¼Ð°ÑÐ¸ÑÑ XVI Ð²ÐµÐºÐ°, Ð½Ð°Ð¿Ð¸ÑÐ°Ð» ÐºÐ½Ð¸Ð³Ñ Ð½Ð° 150 ÑÑÑÐ°Ð½Ð¸Ñ Ð¿Ð¾Ð´ Ð½Ð°Ð·Ð²Ð°Ð½Ð¸ÐµÐ¼ Libro del Ajedrez, Ð¿Ð¾ÑÐ²ÑÑÐµÐ½Ð½ÑÑ Ð¸ÑÑÐµÑÐ¿ÑÐ²Ð°ÑÑÐ¸Ð¼ Ð¸ÑÑÐ»ÐµÐ´Ð¾Ð²Ð°Ð½Ð¸ÑÐ¼, ÐºÐ¾ÑÐ¾ÑÑÐµ Ð¾Ð½ Ð¿ÑÐ¾Ð²ÐµÐ» Ð² Ð´ÐµÐ±ÑÑÐµ (1.e4 e5 2.âf3 âc6 3 .âb5), Ð½Ð°Ð·Ð²Ð°Ð½Ð½ÑÐ¹ Ð² ÐµÐ³Ð¾ ÑÐµÑÑÑ. \n    target text: Ruy LÃ³pez de Segura, a priest and a famous Spanish chess player of the 16th century, wrote a book of 150 pages, called Libro del Ajedrez, about exhaustive studies he made on the opening (1.e4 e5 2.âf3 âc6 3.âb5) that is named after him.\n    generated text: Rui Lopez de Segura, priest and famous Spanish chess player of the 16th century, wrote a 150-page book called Libro del Ajedrez dedicated to the exhaustive research he conducted in his debut (1.e4 e5 2.f3 c6 3.b5), named in his honor.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the main information from the input and target texts without adding any nonsensical or factually incorrect information. It maintains the correct details about Ruy LÃ³pez de Segura being a priest and a famous Spanish chess player, writing a 150-page book called Libro del Ajedrez, and conducting exhaustive studies on the specific chess opening. The minor differences in punctuation and notation do not change the overall meaning and factual accuracy of the text. Therefore, it is not a hallucination.\nThis is the probability assigned by the translator: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð¢Ð¾Ð¼Ñ Ð½Ð°Ð´Ð¾ Ð±ÑÐ»Ð¾ ÑÑÐ´Ð° Ð¿Ð¾ÐµÑÐ°ÑÑ. \n    target text: Tom had to go there.\n    generated text: That's why we had to go there.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Hallucination\".\nHere is the reasoning the translator provided: The generated text Thats why we had to go there contains additional information we that is not supported by the input text Ð¢Ð¾Ð¼Ñ Ð½Ð°Ð´Ð¾ Ð±ÑÐ»Ð¾ ÑÑÐ´Ð° Ð¿Ð¾ÐµÑÐ°ÑÑ and the target text Tom had to go there. It introduces a first-person plural pronoun we which is not present in the original text, thereby adding information that cannot be supported by the input and target texts. This additional information makes the generated text a hallucination.\nThis is the probability assigned by the translator: 0.95\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð ÑÑÐ¾Ð¼ ÑÐ¶Ðµ Ð½ÐµÑ Ð¾ÑÐ¾Ð±Ð¾Ð¹ Ð½ÐµÐ¾Ð±ÑÐ¾Ð´Ð¸Ð¼Ð¾ÑÑÐ¸. \n    target text: That isn't really necessary anymore.\n    generated text: There is no need for this anymore.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the meaning and intent of the input text and the target text without adding any nonsensical or factually incorrect information. It stays true to the original meaning and does not introduce any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the translator: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð¢Ð¾Ð¼ ÑÐ¾Ð²ÑÐ°Ð». \n    target text: Tom lied.\n    generated text: Tom agreed.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Hallucination\".\nHere is the reasoning the translator provided: The generated text Tom agreed contains additional information that cannot be supported by the input text Ð¢Ð¾Ð¼ ÑÐ¾Ð²ÑÐ°Ð» (Tom lied) or the target text Tom lied. There is no indication of agreement in the input or the target text, so the addition of agreed is unsupported and changes the meaning of the original statement, making it a hallucination.\nThis is the probability assigned by the translator: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð¢Ñ Ð½Ðµ Ð¾Ð±ÑÐ°ÑÐ°ÐµÑÑ Ð½Ð° Ð¼ÐµÐ½Ñ Ð²Ð½Ð¸Ð¼Ð°Ð½Ð¸Ñ. \n    target text: You're ignoring me.\n    generated text: You don't pay attention to me.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately conveys the meaning of the input text and the target text without adding any nonsensical or factually incorrect information. It simply expresses the same idea in a slightly different way, making it not a hallucination.\nThis is the probability assigned by the translator: 0.2\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÐ°Ñ Ð² Ð¿Ð¾ÑÐ»ÐµÐ´Ð½ÐµÐµ Ð²ÑÐµÐ¼Ñ ÑÐ¾Ð²ÑÐµÐ¼ Ð½Ðµ Ð²Ð¸Ð´Ð½Ð¾. \n    target text: You've been absent a lot lately.\n    generated text: You haven't seen anything lately.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Hallucination\".\nHere is the reasoning the translator provided: The generated text You havent seen anything lately does not accurately convey the meaning of the input and target text. It introduces a different context and suggests that the subject hasnt seen anything, which is not supported by the original input and target texts. Additionally, it contains information that is not present in the input or target text, making it a hallucination.\nThis is the probability assigned by the translator: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÐ½Ð° ÑÐ½ÑÐ»Ð° Ñ ÑÐµÐ±Ñ Ð¾Ð´ÐµÐ¶Ð´Ñ. \n    target text: She took off her clothes.\n    generated text: She slept with her clothes.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Hallucination\".\nHere is the reasoning the translator provided: The generated text She slept with her clothes significantly differs from the target text She took off her clothes and introduces nonsensical and factually incorrect information. The addition of slept instead of took off and the lack of coherence with the input and target texts indicate hallucination.\nThis is the probability assigned by the translator: 0.9\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÐ¹ Ð½Ðµ Ð½ÑÐ°Ð²Ð¸ÑÑÑ Ð¼Ð¾Ñ Ð¼Ð°Ð½ÐµÑÐ° Ð³Ð¾Ð²Ð¾ÑÐ¸ÑÑ. \n    target text: She doesn't like the way I speak.\n    generated text: She doesn't like to talk about my manner.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Hallucination\".\nHere is the reasoning the translator provided: The generated text introduces the concept of talking which is not supported by the input text or the target text. It also adds information about talking about my manner which is not present in the input or target text. This additional information changes the meaning and introduces a new concept that is not supported by the original text.\nThis is the probability assigned by the translator: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÐ¾Ð½Ð°Ñ Ð² Ð¼Ð¾Ð½Ð°ÑÑÑÑÐµ. \n    target text: The monk is in the monastery.\n    generated text: Monk in the monastery.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the main idea of the input and target texts without adding any nonsensical or factually incorrect information. It simply omits the is verb from the target text, which does not change the meaning of the sentence. Therefore, it does not contain any hallucinations.\nThis is the probability assigned by the translator: 0.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð¥Ð¾ÑÐ¸ÑÐµ Ð·Ð°Ð¿Ð¸ÑÐ°ÑÑÑÑ Ð½Ð° Ð¿ÑÐ¸ÐµÐ¼? \n    target text: Would you like to make an appointment?\n    generated text: Do you want to sign up for admission?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the meaning of the input text and the target text without adding any nonsensical or factually incorrect information. It simply rephrases make an appointment to sign up for admission, which is a valid synonym. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the translator: 0.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð¯ Ð³Ð¾ÑÐ¾Ð², Ð° Ð²Ñ? \n    target text: I'm ready, and you?\n    generated text: I'm ready, aren't you?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the meaning and sentiment of the input and target text without adding any nonsensical or factually incorrect information. It simply rephrases the original sentence in a slightly different way, maintaining the intended message. Therefore, it is not a hallucination.\nThis is the probability assigned by the translator: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð­ÑÐ¾ Ð½Ðµ Ð´Ð»Ñ Ð²ÑÐµÑ. \n    target text: This isn't everyone's cup of tea.\n    generated text: It's not for everyone.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the essence of the input text and the target text without adding any nonsensical or factually incorrect information. It maintains the meaning and tone of the original text while being a concise translation. Therefore, it is not a hallucination.\nThis is the probability assigned by the translator: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÐ´Ðµ Ð¼Ð½Ðµ ÐµÐ³Ð¾ Ð¸ÑÐºÐ°ÑÑ? \n    target text: Where should I look for it?\n    generated text: Where do I want him?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Hallucination\".\nHere is the reasoning the translator provided: The generated text Where do I want him? does not accurately convey the meaning of the input text ÐÐ´Ðµ Ð¼Ð½Ðµ ÐµÐ³Ð¾ Ð¸ÑÐºÐ°ÑÑ? and the target text Where should I look for it?. The generated text introduces the word want and changes the meaning from searching for something to desiring someone, which is factually incorrect and not supported by the input or target text. This is a clear case of hallucination.\nThis is the probability assigned by the translator: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÐ¾ÑÐ¾Ðº Ð»Ð°Ð²Ñ ÑÐ½Ð¸ÑÑÐ¾Ð¶Ð°Ð» Ð²ÑÑ Ð½Ð° ÑÐ²Ð¾ÑÐ¼ Ð¿ÑÑÐ¸. \n    target text: The lava flow destroyed everything in its path.\n    generated text: The lava flow destroyed everything in its own way.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the main idea of the input text and the target text, describing the destructive nature of the lava flow. Although the phrase in its own way differs from in its path, it does not introduce any nonsensical or factually incorrect information. The meaning remains consistent with the original context. Therefore, it is not a hallucination.\nThis is the probability assigned by the translator: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð¢Ð¾Ð¼ ÑÑÐ°ÑÐ°ÐµÑÑÑ Ð¸Ð·Ð¾ Ð²ÑÐµÑ ÑÐ¸Ð». \n    target text: Tom is trying as hard as he can.\n    generated text: Tom is trying his best.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the meaning of the input text and target text without any nonsensical or factually incorrect information. It does not contain any additional information that cannot be supported by the input text or the target text. Therefore, it is not a hallucination.\nThis is the probability assigned by the translator: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð¡ÐºÐ¾ÑÐµÐµ Ð²ÑÐµÐ³Ð¾, Ð½Ð¸ÐºÑÐ¾ Ð´Ð°Ð¶Ðµ Ð½Ðµ Ð·Ð°Ð¼ÐµÑÐ¸Ñ. \n    target text: No one will likely even notice.\n    generated text: Most likely, no one will even notice.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the meaning and intent of the input text and the target text. It does not introduce any nonsensical or factually incorrect information, and it does not contain any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the translator: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð¡ÐµÐ³Ð¾Ð´Ð½Ñ ÑÐ½ÐµÐ³. \n    target text: Today it's snowing.\n    generated text: It's snowing today.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the meaning and order of the words from the input text and the target text. There are no nonsensical or factually incorrect information, and no additional unsupported information is present. Therefore, it is not a hallucination.\nThis is the probability assigned by the translator: 0.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÑ ÑÑÑÐ°Ð½Ð¾Ð²Ð¸Ð¼ Ð¿ÑÐ¾Ð¶ÐµÐºÑÐ¾ÑÑ. \n    target text: We'll install spotlights.\n    generated text: We'll set up projectors.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Hallucination\".\nHere is the reasoning the translator provided: The generated text Well set up projectors does not accurately reflect the input text ÐÑ ÑÑÑÐ°Ð½Ð¾Ð²Ð¸Ð¼ Ð¿ÑÐ¾Ð¶ÐµÐºÑÐ¾ÑÑ which translates to Well install spotlights. The discrepancy between projectors and spotlights demonstrates a factual inaccuracy. Additionally, projectors introduces information that is not supported by the input text or the target text, making it hallucinatory.\nThis is the probability assigned by the translator: 0.9\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð¯ ÑÐ¸ÑÐ½ÑÐ» Ð¾ÐºÐ¾Ð»Ð¾ Ð´Ð²Ð°Ð´ÑÐ°ÑÐ¸ ÑÐ°Ð·. \n    target text: I sneezed about twenty times.\n    generated text: I walked about twenty times.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Hallucination\".\nHere is the reasoning the translator provided: The generated text I walked about twenty times introduces information that is not supported by the input text or the target text. The original text is about sneezing, not walking, so the generated text contains additional information that cannot be supported by the given inputs and targets. This divergence from the original meaning makes the generated text a hallucination.\nThis is the probability assigned by the translator: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÑÑÐ¸ ÑÑÐ¸ÑÐ°ÐµÑ, ÑÑÐ¾ Ð¾Ð½Ð° ÑÐ°Ð¼Ð°Ñ ÑÐ¼Ð½Ð°Ñ. \n    target text: Mary thinks she's smarter than everyone else.\n    generated text: Mary thinks she's the smartest.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the main idea and sentiment of the original text and the target text. It doesnt contain any nonsensical or factually incorrect information, and it doesnt introduce any additional unsupported information. Therefore, it aligns closely with the inputs and targets without deviating into hallucination.\nThis is the probability assigned by the translator: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð¡ÐºÐ¾Ð»ÑÐºÐ¾ Ð²ÑÐµÐ¼ÐµÐ½Ð¸ ÑÐµÐ±Ðµ Ð½ÑÐ¶Ð½Ð¾, ÑÑÐ¾Ð±Ñ ÐµÐ³Ð¾ Ð¿Ð¾ÑÐ¸Ð½Ð¸ÑÑ? \n    target text: How much time do you need to repair it?\n    generated text: How long do you need to start it?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Hallucination\".\nHere is the reasoning the translator provided: The generated text How long do you need to start it? introduces new information start it which is not supported by the input text or the target text. The original question was about repairing something, not starting it, so the generated text contains additional information that cannot be supported by the given inputs and targets, making it a hallucination.\nThis is the probability assigned by the translator: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÐ´Ð¾ÑÐ¾Ð²ÑÐ¹ ÑÐµÐ»Ð¾Ð²ÐµÐº Ð½Ðµ Ð·Ð½Ð°ÐµÑ ÑÐµÐ½Ñ Ð·Ð´Ð¾ÑÐ¾Ð²ÑÑ. \n    target text: A healthy man does not know the value of health.\n    generated text: A healthy person does not know the prices of health.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the meaning of the original Russian text and the target translation. It conveys the idea that a healthy person underestimates the value of health, which is consistent with the input and target texts. There are no nonsensical or factually incorrect statements, and the generated text does not introduce any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the translator: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð¢Ñ Ð³Ð¾Ð²Ð¾ÑÐ¸ÑÑ Ð¿Ð¾-Ð½ÐµÐ¼ÐµÑÐºÐ¸. \n    target text: You speak German.\n    generated text: You're speaking German.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately conveys the meaning of the input text and the target text without adding any nonsensical or factually incorrect information. The addition of speaking instead of speak does not change the meaning or introduce any new unsupported information. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the translator: 0.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð¯ Ð½Ðµ ÑÐ¾ÑÐµÐ», ÑÑÐ¾Ð±Ñ ÑÐ¾ Ð¼Ð½Ð¾Ð¹ Ð±ÑÐ»Ð¾ ÑÐ¾ Ð¶Ðµ ÑÐ°Ð¼Ð¾Ðµ. \n    target text: I didn't want the same thing to happen to me.\n    generated text: I didnât want it to be the same with me.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the core meaning of the original text and the target text. It conveys the idea that the speaker did not want the same thing to happen to them. Although the wording is slightly different, the essential message remains consistent. There are no nonsensical or factually incorrect information in the generated text, and it does not contain any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the translator: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÑ ÑÐ¾ÑÐ¸ÑÐµ ÑÐºÐ°Ð·Ð°ÑÑ, ÑÑÐ¾ ÑÑÐ¾ Ð²Ð°Ñ Ð½Ðµ Ð¿ÑÐ³Ð°ÐµÑ? \n    target text: Do you mean that doesn't scare you?\n    generated text: You mean it doesn't scare you?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the meaning of the input text and the target text without introducing any nonsensical or factually incorrect information. It stays true to the content and intent of the original text, and does not add any unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the translator: 0.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÐµÐ· ÑÐ²Ð¾ÐµÐ¹ Ð¿Ð¾Ð¼Ð¾ÑÐ¸ ÑÑÐ¾ Ð±ÑÐ»Ð¾ Ð±Ñ Ð½ÐµÐ²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ð¾. \n    target text: It would've been impossible without your help.\n    generated text: Without your help it would be impossible.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the meaning and sentiment of the input text and the target text. It conveys the same message with the reordering of the words. There are no nonsensical or factually incorrect information in the generated text, and it does not contain any additional information not present in the input or target text. Therefore, it is not a hallucination.\nThis is the probability assigned by the translator: 0.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÐ½ Ð´Ð°Ð²Ð½Ð¾ ÐµÑ Ð·Ð½Ð°ÐµÑ. \n    target text: He has known her for a long time.\n    generated text: He knew her a long time ago.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately conveys the temporal aspect of the original sentence, indicating a long-standing familiarity between the two individuals. There are no nonsensical or factually incorrect details in the generated text, and it does not introduce any additional unsupported information. Therefore, based on the given inputs and targets, the generated text is a faithful translation and not a hallucination.\nThis is the probability assigned by the translator: 0.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð¢Ð¾Ð¼ ÑÐ¾Ð»ÑÐºÐ¾-ÑÑÐ¾ ÑÑÐ¾ÑÐ» ÑÐ°Ð¼, Ð¾ÑÐºÑÑÐ² ÑÐ¾Ñ, Ð¸ Ð³Ð»Ð°Ð·ÐµÐ» Ð½Ð° ÐÑÑÐ¸. \n    target text: Tom just stood there with his mouth open, staring at Mary.\n    generated text: Tom just stood there, opened his mouth, and looked at Mary.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the main actions and details described in the input and target texts. It does not contain any nonsensical or factually incorrect information, and it does not introduce any additional unsupported details. Therefore, it aligns well with the input and target texts and is not a hallucination.\nThis is the probability assigned by the translator: 0.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð¢Ð¾Ð¼ Ð²ÐµÑÐ½ÑÐ»ÑÑ Ð² ÐÐ¾ÑÑÐ¾Ð½ Ð¿Ð¾ÑÐ»Ðµ ÑÑÑÑÐ´Ð½ÐµÐ²Ð½Ð¾Ð³Ð¾ Ð¾ÑÑÑÑÑÑÐ²Ð¸Ñ. \n    target text: Tom came back to Boston after being away for three years.\n    generated text: Tom returned to Boston after a three-day absence.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the main idea of the input text and the target text. It mentions Toms return to Boston after a period of absence, which aligns with the input and target texts. There are no nonsensical or factually incorrect details, and no additional unsupported information is present. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the translator: 0.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÐ´Ð¸Ð½ ÐºÐ²Ð°Ð´ÑÐ°ÑÐ½ÑÐ¹ Ð¼ÐµÑÑ ÑÐ¾Ð»Ð½ÐµÑÐ½Ð¾Ð¹ Ð±Ð°ÑÐ°ÑÐµÐ¸ Ð²ÑÑÐ°Ð±Ð°ÑÑÐ²Ð°ÐµÑ Ð¿ÑÐ¸Ð¼ÐµÑÐ½Ð¾ Ð¾Ð´Ð¸Ð½ Ð²Ð°ÑÑ ÑÐ½ÐµÑÐ³Ð¸Ð¸, Ð¿Ð¾ÑÑÐ¾Ð¼Ñ Ð² Ð´Ð°Ð½Ð½ÑÐ¹ Ð¼Ð¾Ð¼ÐµÐ½Ñ Ð½ÐµÐ¿ÑÐ¾ÑÑÐ¾ Ð¸ÑÐ¿Ð¾Ð»ÑÐ·Ð¾Ð²Ð°ÑÑ ÑÐ¾Ð»Ð½ÐµÑÐ½ÑÑ ÑÐ½ÐµÑÐ³Ð¸Ñ Ð² ÐºÑÑÐ¿Ð½ÑÑ Ð¼Ð°ÑÑÑÐ°Ð±Ð°Ñ. \n    target text: The output power of a one square meter solar panel is about one watt, so it is difficult to use solar power on a large scale at present.\n    generated text: One square meter of solar battery produces about one watt of energy, so itâs not easy to use solar energy on a large scale right now.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately reflects the information present in the input text and the target text without introducing any nonsensical or factually incorrect information. It maintains the same meaning and does not add any unsupported details. Therefore, it is not a hallucination.\nThis is the probability assigned by the translator: 0.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð­ÑÐ¾ Ð¾ÑÐµÐ½Ñ Ð²ÐµÑÐµÐ»Ð¾, ÑÐ¾Ð±Ð¸ÑÐ°ÑÑ ÑÐ°Ð·Ð½Ð¾Ð¾Ð±ÑÐ°Ð·Ð½ÑÐµ ÑÐ°ÐºÑÑÐºÐ¸ Ð½Ð° Ð¿Ð»ÑÐ¶Ðµ. \n    target text: It is a lot of fun picking various shells on the sands.\n    generated text: It is very fun to collect various crabs on the beach.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Hallucination\".\nHere is the reasoning the translator provided: The generated text contains nonsensical information by mentioning collecting crabs instead of shells, which is not supported by the input text or the target text. Additionally, it introduces factually incorrect information, which makes it a hallucination.\nThis is the probability assigned by the translator: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÑÐ¼Ð°Ñ, Ð¾Ð½ Ð´ÐµÐ»Ð°ÐµÑ Ð²Ð¸Ð´. \n    target text: I think he's faking.\n    generated text: I think he's making a look.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Hallucination\".\nHere is the reasoning the translator provided: The generated text I think hes making a look contains additional information that cannot be supported by the input text or the target text. There is no indication in the input or target text about making a look, and the intended meaning of faking in the target text is not preserved. Therefore, it is a hallucination.\nThis is the probability assigned by the translator: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÐ¾ÑÑÐ¾Ð¹-ÐºÐ°, ÑÑ ÑÑÐ¾ ÑÐµÑÑÑÐ·Ð½Ð¾? \n    target text: Woah, are you serious?\n    generated text: Wait, are you serious?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the meaning and tone of the input text and the target text. It does not contain any nonsensical or factually incorrect information, and it does not introduce any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the translator: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð¢Ñ ÑÐ»ÑÑÐ°Ð», ÐºÐ°Ðº Ð¿ÑÐ¸ÑÑ ÑÐµÐ±ÐµÑÑÑ? \n    target text: Did you hear the birds tweeting?\n    generated text: Did you hear how the birds smell?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Hallucination\".\nHere is the reasoning the translator provided: The generated text Did you hear how the birds smell? contains nonsensical information as birds do not smell in the context of the original sentence. This introduces factually incorrect information, making it a hallucination. Additionally, the generated text contains additional information that cannot be supported by the input text or the target text, as there is no mention of smelling in the original sentence or the target text.\nThis is the probability assigned by the translator: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð§ÑÐ¾ ÑÑ ÑÐ°Ð¼ Ð¿Ð¾ÑÑÑ? \n    target text: What are you singing?\n    generated text: What are you drinking there?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Hallucination\".\nHere is the reasoning the translator provided: The generated text What are you drinking there? contains additional information that cannot be supported by the input text or the target text. There is no mention of drinking in the input or target text, so this addition is not supported by the original content.\nThis is the probability assigned by the translator: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÐ¾Ð¼Ð±Ð° Ð±ÑÐ»Ð° ÑÑÐ¿ÐµÑÐ½Ð¾ Ð¾Ð±ÐµÐ·Ð²ÑÐµÐ¶ÐµÐ½Ð°. \n    target text: The bomb was successfully defused.\n    generated text: The bomb was successfully decommissioned.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately conveys the action of neutralizing the bomb, which aligns with the input text and the target text. While defused and decommissioned have slightly different meanings, the general idea of rendering the bomb harmless is maintained. There are no nonsensical or factually incorrect information in the generated text, and it does not contain any additional unsupported information. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the translator: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÐ½Ðµ Ð½ÑÐ°Ð²ÑÑÑÑ Ð»ÑÐ´Ð¸, ÐºÐ¾ÑÐ¾ÑÑÐµ Ð½Ðµ Ð±Ð¾ÑÑÑÑ ÑÑÐ°ÑÐµÑÑ. \n    target text: I like people who are not afraid to grow old.\n    generated text: I like people who donât like to be old.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Hallucination\".\nHere is the reasoning the translator provided: The generated text I like people who donât like to be old contains additional information that is not supported by the input text or the target text. The target text emphasizes not afraid to grow old while the generated text introduces a different concept of not like to be old, which is not present in the original text. This additional information changes the meaning and introduces a new idea that is not supported by the original content, making it a hallucination.\nThis is the probability assigned by the translator: 0.9\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð­ÑÐ¾ ÐÑ Ð¼ÐµÐ½Ñ ÑÐ¿Ð°ÑÐ»Ð¸? \n    target text: Are you the one who saved me?\n    generated text: Did you save me?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the main idea of the input text and the target text, which is about the act of saving. It does not contain any nonsensical or factually incorrect information, and there are no additional unsupported details. Therefore, it is not a hallucination.\nThis is the probability assigned by the translator: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð­ÑÐ¾ ÑÑ Ð´Ð°Ð» ÐµÐ¼Ñ Ð¼Ð¾Ð¹ Ð°Ð´ÑÐµÑ? \n    target text: Were you the one who gave him my address?\n    generated text: Did you give him my address?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the essence of the input and target texts. It maintains the same meaning and correctly conveys the question about giving out the address. There are no nonsensical or factually incorrect information in the generated text, and no additional unsupported information is present. Therefore, it is not a hallucination.\nThis is the probability assigned by the translator: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð¡Ð²Ð¾Ð±Ð¾Ð´Ð° Ð±ÐµÑÑÐµÐ½Ð½Ð°. \n    target text: Freedom is invaluable.\n    generated text: Freedom is worthless.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Hallucination\".\nHere is the reasoning the translator provided: The generated text Freedom is worthless is factually incorrect and does not accurately convey the meaning of the original text Ð¡Ð²Ð¾Ð±Ð¾Ð´Ð° Ð±ÐµÑÑÐµÐ½Ð½Ð°, which means Freedom is invaluable in English. The word worthless has a significantly different meaning than invaluable, and it introduces a nonsensical and incorrect interpretation of the original text. Therefore, the generated text is a hallucination.\nThis is the probability assigned by the translator: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÐ° Ð½ÐµÐ¼ÐµÑÐºÐ¾Ð¼ ÑÐ¾Ð¶Ðµ Ð³Ð¾Ð²Ð¾ÑÑÑ? \n    target text: Is German spoken too?\n    generated text: Do they speak German too?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the meaning of the input and target text without introducing any nonsensical or factually incorrect information. It stays faithful to the content and intent of the original text, making it not a hallucination.\nThis is the probability assigned by the translator: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÐ¾Ð·Ð¼Ð¾Ð¶Ð½Ð¾, Ð¼Ð½Ðµ Ð»ÑÑÑÐµ ÑÐ°Ð¼Ð¾Ð¼Ñ Ð¿Ð¾Ð·Ð²Ð°ÑÑ Ð¢Ð¾Ð¼Ð°. \n    target text: Maybe I should call Tom myself.\n    generated text: Maybe I'd better call Tom.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the main idea and intent of the input text and the target text. It does not contain any nonsensical or factually incorrect information, nor does it introduce any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the translator: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð¢Ñ Ð½Ðµ Ð·Ð½Ð°Ð», ÑÑÐ¾ Ð¢Ð¾Ð¼ Ð¶Ð¸Ð» Ð² ÐÐ¾ÑÑÐ¾Ð½Ðµ, ÐºÐ¾Ð³Ð´Ð° Ð±ÑÐ» ÑÐµÐ±ÑÐ½ÐºÐ¾Ð¼? \n    target text: Didn't you know Tom lived in Boston when he was a kid?\n    generated text: You didn't know Tom lived in Boston when he was a kid?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately reflects the information provided in the input text and the target text without any additional information or factual errors. It maintains the same meaning and does not introduce any new details.\nThis is the probability assigned by the translator: 0.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÐ° Ð¼Ð½Ð¾Ð¹ Ð½Ð¸ÐºÐ¾Ð³Ð¾, Ñ Ð¿Ð¾ÑÐ»ÐµÐ´Ð½ÑÑ. \n    target text: There's no one behind me. I'm the last one.\n    generated text: No one's behind me, I'm the last one.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the meaning of the input and target text without adding any nonsensical or factually incorrect information. It stays true to the content and intent of the original text, making it consistent and coherent. Therefore, it is not a hallucination.\nThis is the probability assigned by the translator: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÑÐ¾-ÑÐ¾ ÐºÑÐ¸ÑÐ°Ð». \n    target text: Someone screamed.\n    generated text: Someone was yelling.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text Someone was yelling accurately conveys the action of someone making a loud cry or shout, which aligns with the input text ÐÑÐ¾-ÑÐ¾ ÐºÑÐ¸ÑÐ°Ð» (Someone screamed) and the target text. There are no nonsensical or factually incorrect information in the generated text, and it does not contain any additional unsupported information. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the translator: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÐµÐºÐ¾ÑÐ¾ÑÑÐµ Ð¿ÑÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ ÑÐ»Ð¸ÑÐºÐ¾Ð¼ Ð´Ð»Ð¸Ð½Ð½ÑÐµ. \n    target text: Some sentences are too long.\n    generated text: Some suggestions are too long.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Hallucination\".\nHere is the reasoning the translator provided: The generated text Some suggestions are too long does not accurately convey the meaning of the input and target texts. It introduces new information (suggestions) that is not present in the original text, and it fails to capture the intended meaning about sentences being too long. Therefore, it is a hallucination.\nThis is the probability assigned by the translator: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð¯ ÑÐ¾ÑÑ ÑÐ¾Ð»ÑÐºÐ¾ Ð½Ð°Ð¿Ð¾Ð¼Ð½Ð¸ÑÑ, ÑÑÐ¾ ÑÑÐ¾ Ð±ÑÐ»Ð° Ð½Ðµ Ð¼Ð¾Ñ Ð¸Ð´ÐµÑ. \n    target text: I just want to remind you that this wasn't my idea.\n    generated text: I just want to remember that it wasnât my idea.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the meaning of the original text and the target text without adding any nonsensical or factually incorrect information. It stays true to the content and intent expressed in the input and target text, and does not introduce any unsupported information. Therefore, it can be considered as not a hallucination.\nThis is the probability assigned by the translator: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÐ½Ð° Ð½Ðµ Ð¾ÑÐ¾Ð±ÐµÐ½Ð½Ð¾ Ð¿Ð¾Ð¼Ð¾Ð³Ð»Ð°. \n    target text: She wasn't much help.\n    generated text: She didn't particularly help.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the meaning of the input text and the target text without adding any nonsensical or factually incorrect information. It stays true to the original meaning and does not introduce any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the translator: 0.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð¡Ð¾Ð±Ð°ÐºÐ¸ Ð½Ðµ ÑÐ°Ð·Ð»Ð¸ÑÐ°ÑÑ ÑÐ²ÐµÑÐ°. \n    target text: Dogs can't tell colors apart.\n    generated text: Dogs donât distinguish colors.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the meaning of the input text and the target text without adding any nonsensical or factually incorrect information. The statement Dogs donât distinguish colors aligns with the idea that dogs cannot tell colors apart, as mentioned in the target text. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the translator: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÐ½ Ð±ÐµÐ³Ð»Ð¾ Ð³Ð¾Ð²Ð¾ÑÐ¸Ñ Ð¿Ð¾-ÑÑÑÑÐºÐ¸ â Ð¿Ð¾ ÐºÑÐ°Ð¹Ð½ÐµÐ¹ Ð¼ÐµÑÐµ, Ð¾Ð½ ÑÐ°Ðº Ð¼Ð½Ðµ ÑÐºÐ°Ð·Ð°Ð». \n    target text: He speaks fluent Russian, or at least that's what he told me.\n    generated text: He speaks Russian fluently â at least he told me so.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the meaning of the input text and the target text without adding any nonsensical or factually incorrect information. It stays true to the original meaning and does not introduce any unsupported details. Therefore, it is not a hallucination.\nThis is the probability assigned by the translator: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð Ð¢Ð¾Ð¼, Ð¸ ÐÑÑÐ¸ Ð·Ð½Ð°ÑÑ, ÐºÑÐ¾ ÑÑÐ¾ ÑÐ´ÐµÐ»Ð°Ð». \n    target text: Both Tom and Mary know who did that.\n    generated text: Tom and Mary both know who did it.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the meaning of the input text and the target text without any nonsensical or factually incorrect information. There is no additional information present in the generated text that cannot be supported by the input text or the target text. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the translator: 0.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð¢Ð¾Ð¼ Ð½Ðµ Ð·Ð½Ð°ÐµÑ, ÑÑÐ¾ ÐÑÑÐ¸ ÑÐ¾ÑÐµÑ, ÑÑÐ¾Ð±Ñ Ð¾Ð½ ÐºÑÐ¿Ð¸Ð». \n    target text: Tom doesn't know what Mary wants him to buy.\n    generated text: Tom doesn't know Mary wants him to buy.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the main idea of the input and target texts without introducing any nonsensical or factually incorrect information. It simply omits the word what from the target text, which does not change the meaning of the sentence. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the translator: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÐ´ÐµÐ²Ð°ÐµÐ¼ Ð½Ð°ÑÐ¸ Ð¿Ð°Ð»ÑÑÐ¾ Ð¸ ÑÐ°Ð¿ÐºÐ¸. \n    target text: We put on our coats and hats.\n    generated text: We wear our coats and hats.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately reflects the action described in the input text and the target text without adding any nonsensical or factually incorrect information. It simply uses a different verb (wear instead of put on), which does not change the overall meaning or introduce any additional unsupported information. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the translator: 0.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÑÑÐ¸ ÑÑÐ¸ÑÐ°ÐµÑ, ÑÑÐ¾ Ð¾Ð½Ð° ÑÐ°Ð¼Ð°Ñ ÑÐ¼Ð½Ð°Ñ. \n    target text: Mary thinks she's smarter than everyone else.\n    generated text: Mary thinks she's the smartest.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the main idea of the target text and does not add any unsupported information. It is a valid paraphrase of the target text and does not introduce any nonsensical or factually incorrect information. Therefore, it is not a hallucination.\nThis is the probability assigned by the translator: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÑ Ð²Ð¸Ð´ÐµÐ»Ð¸, ÐºÐ°Ðº ÑÐµÐ±ÐµÐ½Ð¾Ðº ÑÐµÐ» Ð² Ð°Ð²ÑÐ¾Ð±ÑÑ. \n    target text: We saw the child get on the bus.\n    generated text: We saw a child sitting on a bus.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the action of the child getting on the bus, although it uses a different verb tense. There are no nonsensical or factually incorrect information in the generated text, and it does not contain any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the translator: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð£ Ð½ÐµÐ³Ð¾ ÑÐ»Ð¾Ð¼Ð°Ð½Ð° ÑÐµÑ. \n    target text: His neck is broken.\n    generated text: He had a broken neck.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately conveys the same information as the target text without adding any unsupported details or containing nonsensical information. It maintains the same subject and accurately reflects the meaning of the original sentence. Therefore, it is not a hallucination.\nThis is the probability assigned by the translator: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÑ Ð²ÑÐµ ÑÐµÐ±Ñ Ð»ÑÐ±Ð¸Ð¼. \n    target text: We all love you.\n    generated text: We love you all.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text We love you all is a valid translation of the input text ÐÑ Ð²ÑÐµ ÑÐµÐ±Ñ Ð»ÑÐ±Ð¸Ð¼ and conveys the same sentiment as the target text We all love you. There are no nonsensical or factually incorrect information in the generated text, and it does not contain any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the translator: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÐ°Ð¼ Ð½Ðµ ÑÐ°Ðº ÑÐ¶ Ð²Ð°Ð¶Ð½Ð¾, ÑÐºÐ¾Ð»ÑÐºÐ¾ Ð²Ð°Ð¼ Ð»ÐµÑ. \n    target text: We don't really care how old you are.\n    generated text: It doesnât matter how old you are.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the meaning of the input text and target text without introducing any nonsensical or factually incorrect information. It simply conveys the same idea in a slightly different wording. There is no additional information present that goes beyond the content of the input and target texts.\nThis is the probability assigned by the translator: 0.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð¯ ÑÐ¾ÑÐµÐ» Ð±Ñ Ð¾ÑÑÐ°Ð²Ð¸ÑÑ Ð¾ÑÐ·ÑÐ². \n    target text: I'd like to leave feedback.\n    generated text: I would like to leave a comment.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately reflects the meaning of the input text and the target text without adding any nonsensical or factually incorrect information. It stays true to the intent of leaving feedback, which is present in both the input and target texts. The generated text is a valid paraphrase of the target text and does not contain any additional unsupported information.\nThis is the probability assigned by the translator: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð Ð¼Ð¾ÐµÐ¹ ÑÑÑÐ°Ð½Ðµ Ð»ÑÐ´Ð¸ Ð¾Ð±ÑÑÐ½Ð¾ Ð¿ÑÐ¸Ð²ÐµÑÑÑÐ²ÑÑÑ Ð´ÑÑÐ³ Ð´ÑÑÐ³Ð° ÑÑÐºÐ¾Ð¿Ð¾Ð¶Ð°ÑÐ¸ÐµÐ¼. \n    target text: People generally greet each other by shaking hands in my country.\n    generated text: In my country, people usually welcome each other by hand.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Hallucination\".\nHere is the reasoning the translator provided: The generated text In my country, people usually welcome each other by hand does not accurately convey the cultural norm described in the input and target texts, which is about greeting by shaking hands. Additionally, the word welcome implies a different context than the act of greeting, introducing additional unsupported information. Therefore, the generated text contains both factual inaccuracies and additional unsupported information, making it a hallucination.\nThis is the probability assigned by the translator: 0.9\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð¢Ñ ÑÐ°ÑÑÐ¾ ÐºÑÐ¿Ð°ÐµÑÑÑÑ? \n    target text: Do you go swimming often?\n    generated text: Do you often buy?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Hallucination\".\nHere is the reasoning the translator provided: The generated text Do you often buy? is a hallucination because it contains factually incorrect information. The input text Ð¢Ñ ÑÐ°ÑÑÐ¾ ÐºÑÐ¿Ð°ÐµÑÑÑÑ? translates to Do you often swim? and the target text is Do you go swimming often? There is no mention of buying in the input or target text, so the mention of buying in the generated text is factually incorrect and does not align with the input or target text.\nThis is the probability assigned by the translator: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÐ»Ð°Ð²Ð°ÑÑ Ñ Ð´ÐµÐ»ÑÑÐ¸Ð½Ð°Ð¼Ð¸ Ð¾Ð¿Ð°ÑÐ½Ð¾. \n    target text: It is dangerous to swim with dolphins.\n    generated text: Swimming with dolphins is dangerous.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the meaning and message of the input and target texts without adding any nonsensical or factually incorrect information. It maintains the same core idea and does not introduce any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the translator: 0.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð¢Ð¾Ð¼ ÐµÐ´Ð¸Ð½ÑÑÐ²ÐµÐ½Ð½ÑÐ¹ Ð·Ð´ÐµÑÑ, Ñ ÐºÐ¾Ð³Ð¾ Ð½ÐµÑ Ð²Ð¾Ð´Ð¸ÑÐµÐ»ÑÑÐºÐ¸Ñ Ð¿ÑÐ°Ð²? \n    target text: Is Tom the only one here who doesn't have a driver's license?\n    generated text: That's the only one here who has no driver's license?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Hallucination\".\nHere is the reasoning the translator provided: The generated text contains a factual inaccuracy by stating the only one here who has no drivers license instead of the only one here who doesnt have a drivers license. This changes the meaning and introduces nonsensical information. Additionally, the generated text does not accurately convey the information in the input and target texts, making it a hallucination.\nThis is the probability assigned by the translator: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÐ°Ð¼ Ð½Ð°Ð´Ð¾ ÐµÐ³Ð¾ Ð½Ð°Ð½ÑÑÑ. \n    target text: We should hire him.\n    generated text: We have to hire him.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the meaning of the input text and the target text without adding any nonsensical or factually incorrect information. It simply uses a slightly different wording, which does not change the overall meaning of the statement. Therefore, it can be considered as a faithful translation without hallucination.\nThis is the probability assigned by the translator: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÐ¾Ð¶ÐµÑÐµ ÑÑÐ¾Ð´Ð¸ÑÑ, ÐµÑÐ»Ð¸ ÑÐ¾ÑÐ¸ÑÐµ. \n    target text: You may leave if you want to.\n    generated text: You can leave if you want.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the essence of the input text and the target text without adding any nonsensical or factually incorrect information. It conveys the same meaning as the target text, albeit with slightly different wording. The difference in wording does not alter the core meaning of the sentence. Therefore, based on the input text and the target text, the generated text is not a hallucination.\nThis is the probability assigned by the translator: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð¯ Ð¸Ñ Ð½Ðµ Ð±Ð¾ÑÑÑ. \n    target text: I don't fear them.\n    generated text: I'm not afraid of them.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the meaning and sentiment of the input text and the target text without adding any nonsensical or factually incorrect information. It stays true to the original meaning and does not introduce any unsupported information.\nThis is the probability assigned by the translator: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÐ¾Ð³Ð´Ð° Ñ Ð²ÑÑÑÐµÑÐ¸Ð» ÐµÑ Ð½Ð° Ð´Ð½ÑÑ, Ð¾Ð½Ð° Ð²ÑÐ³Ð»ÑÐ´ÐµÐ»Ð° Ð¾ÑÐµÐ½Ñ ÑÑÐ°ÑÑÐ»Ð¸Ð²Ð¾Ð¹. \n    target text: When I saw her recently, she looked very happy.\n    generated text: When I met her during the day, she looked very happy.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the main idea and sentiment of the input and target text. It provides a slightly different interpretation of the time (during the day vs recently), but this does not introduce any nonsensical or factually incorrect information. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the translator: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð¢Ñ Ð´ÐµÐ¹ÑÑÐ²Ð¸ÑÐµÐ»ÑÐ½Ð¾ Ð´ÑÐ¼Ð°ÐµÑÑ, ÑÑÐ¾ Ñ Ð¼Ð¾Ð³Ñ Ð»ÐµÑÐ°ÑÑ? \n    target text: You really think I can fly?\n    generated text: Do you really think I can fly?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the meaning and intent of the input text and the target text without adding any nonsensical or factually incorrect information. It stays true to the content provided and is a faithful translation. Therefore, it is not a hallucination.\nThis is the probability assigned by the translator: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð¯ Ð»ÑÑÑÐµ Ð½Ðµ Ð±ÑÐ´Ñ Ð¾ÑÐ²ÐµÑÐ°ÑÑ Ð½Ð° ÑÑÐ¾Ñ Ð²Ð¾Ð¿ÑÐ¾Ñ. \n    target text: I'd rather not answer that question.\n    generated text: I'd better not answer that question.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the meaning and sentiment of the input text and the target text. It does not contain any nonsensical or factually incorrect information, and it does not introduce any additional unsupported information. The translation is faithful to the original meaning and context.\nThis is the probability assigned by the translator: 0.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð¢Ð¾Ð¼ ÑÑÐ°Ð» Ð¾ÑÑÐ¾Ð¼. \n    target text: Tom is a father now.\n    generated text: Tom became a father.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the main information from the input and target texts without adding any nonsensical or factually incorrect details. It stays true to the meaning and content of the original text.\nThis is the probability assigned by the translator: 0.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð¯ ÐµÐ³Ð¾ ÑÐ·Ð½Ð°Ð»Ð°. \n    target text: I recognized him.\n    generated text: I knew him.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text I knew him is a valid interpretation of the input text Ð¯ ÐµÐ³Ð¾ ÑÐ·Ð½Ð°Ð»Ð° as it conveys the idea of recognizing someone, which aligns with the target text I recognized him. There are no nonsensical or factually incorrect information in the generated text, and it does not contain any additional unsupported information. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the translator: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð£Ð±Ð¾ÑÑÐ¸ÑÐ° Ð¿ÑÐµÑÐ²Ð°Ð»Ð° ÑÐ°Ð·Ð³Ð¾Ð²Ð¾Ñ. \n    target text: The cleaning lady interrupted the conversation.\n    generated text: The locksmith interrupted the conversation.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Hallucination\".\nHere is the reasoning the translator provided: The generated text The locksmith interrupted the conversation is factually incorrect as it introduces a completely different profession (locksmith) that is not present in the input text or the target text. This additional and incorrect information makes the generated text a hallucination.\nThis is the probability assigned by the translator: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð¯ ÐµÐ³Ð¾ Ð² Ð¿Ð¾ÑÐ»ÐµÐ´Ð½ÐµÐµ Ð²ÑÐµÐ¼Ñ Ð½Ðµ Ð²Ð¸Ð´ÐµÐ»; Ð¿ÐµÑÐµÐ´Ð°Ð²Ð°Ð¹ ÐµÐ¼Ñ Ð¿ÑÐ¸Ð²ÐµÑ. \n    target text: I haven't seen him lately; give him my regards.\n    generated text: I haven't seen him lately; give him hello.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Hallucination\".\nHere is the reasoning the translator provided: The generated text incorrectly translates Ð¿ÐµÑÐµÐ´Ð°Ð²Ð°Ð¹ ÐµÐ¼Ñ Ð¿ÑÐ¸Ð²ÐµÑ as give him hello instead of give him my regards, which is factually incorrect and nonsensical. The addition of hello is not supported by the input text or the target text, making it a hallucination.\nThis is the probability assigned by the translator: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð£ Ð½Ð°Ñ Ð¾Ð½Ð¾ ÑÐ¶Ðµ ÐµÑÑÑ. \n    target text: We already have one.\n    generated text: We already have it.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately conveys the same meaning as the target text while maintaining the essence of the input text. It and one are interchangeable in this context and do not introduce any nonsensical or factually incorrect information. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the translator: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð¢Ð²Ð¾Ñ ÑÐ¾Ð±Ð°ÐºÐ° ÑÐ¼ÐµÐµÑ Ð¿Ð»Ð°Ð²Ð°ÑÑ? \n    target text: Can your dog swim?\n    generated text: Is your dog able to swim?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the meaning of the input text and the target text without introducing any nonsensical or factually incorrect information. It simply rephrases the question in a slightly different way, maintaining the original intent.\nThis is the probability assigned by the translator: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð­ÑÐ¾Ñ Ð½Ð¾Ð¶ Ð¾ÑÐµÐ½Ñ Ð¼Ð½Ðµ Ð¿ÑÐ¸Ð³Ð¾Ð´Ð¸Ð»ÑÑ. \n    target text: This knife was very useful to me.\n    generated text: This knife was very good for me.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Hallucination\".\nHere is the reasoning the translator provided: The generated text This knife was very good for me introduces additional information that cannot be supported by the input text or the target text. It goes beyond the meaning of useful in the original text, and thus qualifies as a hallucination.\nThis is the probability assigned by the translator: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð¢Ð¾Ð¼ Ð²Ð¾Ð¾ÑÑÐ¶Ð¸Ð»ÑÑ Ð²Ð¸Ð½ÑÐ¾Ð²ÐºÐ¾Ð¹ Ð¸ Ð½Ð¾Ð¶Ð¾Ð¼. \n    target text: Tom armed himself with a gun and a knife.\n    generated text: Tom was armed with a rifle and knife.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Hallucination\".\nHere is the reasoning the translator provided: The generated text includes the word rifle, which is not present in the input or target text. Additionally, the word gun in the target text is replaced by rifle in the generated text, introducing an unsupported change in the type of weapon. This constitutes a factual inaccuracy and introduces additional information not supported by the input or target text, making it a hallucination.\nThis is the probability assigned by the translator: 1.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð¢Ð¾Ð¼ ÑÐºÐ°Ð·Ð°Ð», ÑÑÐ¾ ÑÑÐ¸Ð¶Ð´Ñ Ð¿ÑÑÐ°Ð»ÑÑ ÑÑÐ¾ ÑÐ´ÐµÐ»Ð°ÑÑ. \n    target text: Tom said that he's tried doing that three times.\n    generated text: Tom said he tried to do it three times.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the essential information from the input and target texts without introducing any nonsensical or factually incorrect details. It maintains the core meaning and does not add any unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the translator: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð¢Ð¾, ÑÑÐ¾ ÑÐºÐ°Ð·Ð°Ð» Ð¢Ð¾Ð¼, Ð¿Ð¾Ð´ÑÐ²ÐµÑÐ´Ð¸Ð»Ð¾ÑÑ. \n    target text: What Tom said proved true.\n    generated text: What Tom said was confirmed.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the meaning of the input and target text. It conveys the idea that what Tom said was proven to be true, although using a slightly different word. There is no nonsensical or factually incorrect information, and no additional unsupported information is present in the generated text.\nThis is the probability assigned by the translator: 0.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÐ´Ðµ Ð¢Ð¾Ð¼ Ð²Ð·ÑÐ» ÑÑÐ¸ ÑÐ¾ÑÐ¾Ð³ÑÐ°ÑÐ¸Ð¸? \n    target text: Where did Tom get these pictures?\n    generated text: Where did Tom take those photos?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the meaning and context of the input text and the target text. It does not contain any nonsensical or factually incorrect information, nor does it introduce any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the translator: 0.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÑÐ¿ÑÐ°Ð²Ñ ÐµÐ³Ð¾, Ð¿Ð¾Ð¶Ð°Ð»ÑÐ¹ÑÑÐ°. \n    target text: Please fix it.\n    generated text: Just fix it, please.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text Just fix it, please accurately captures the meaning of the input text ÐÑÐ¿ÑÐ°Ð²Ñ ÐµÐ³Ð¾, Ð¿Ð¾Ð¶Ð°Ð»ÑÐ¹ÑÑÐ° and the target text Please fix it. It does not contain any nonsensical or factually incorrect information, nor does it introduce any additional unsupported information. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the translator: 0.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð­ÑÐ¾ ÑÐ²Ð¾Ð¹ Ð¿ÐµÑÐ²ÑÐ¹ ÑÑÐ¸Ð¿? \n    target text: Is this your first time tripping?\n    generated text: Is this your first trip?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the essence of the input and target texts by conveying the concept of first time tripping without introducing any nonsensical or factually incorrect information. It stays true to the meaning and intent of the original text, making it not a hallucination.\nThis is the probability assigned by the translator: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÐµÐºÐ¾ÑÐ¾ÑÑÐµ ÑÐ°Ð·Ð³Ð¾Ð²Ð°ÑÐ¸Ð²Ð°ÑÑ Ð²Ð¾ ÑÐ½Ðµ. \n    target text: Some people talk in their sleep.\n    generated text: Some people talk in their dreams.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the meaning of the input text and the target text, without introducing any nonsensical or factually incorrect information. Both the input text and the target text suggest that people talk while they are asleep, which aligns with the concept of talking in dreams. The generated text does not contain additional unsupported information and stays true to the original meaning.\nThis is the probability assigned by the translator: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÐµ Ð¿Ð¾Ð»ÑÐ·ÑÐ¹ÑÐµÑÑ ÑÐµÐ»ÐµÑÐ¾Ð½Ð¾Ð¼ Ð²Ð¾ Ð²ÑÐµÐ¼Ñ Ð²Ð¾Ð¶Ð´ÐµÐ½Ð¸Ñ. \n    target text: Don't use your phone while driving.\n    generated text: Do not use your phone while driving.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the meaning of the input text and the target text without introducing any nonsensical or factually incorrect information. It does not contain any additional information beyond the original meaning. Therefore, it is not a hallucination.\nThis is the probability assigned by the translator: 0.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÐ¾Ð´Ð¾Ð¶Ð´Ð¸, ÑÑ ÑÑÐ¾ ÑÐµÑÑÑÐ·Ð½Ð¾? \n    target text: Whoa, are you serious?\n    generated text: Wait, are you serious?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the meaning and tone of the input and target texts without introducing any nonsensical or factually incorrect information. It stays faithful to the original intent and does not add any unsupported details. Therefore, it is not a hallucination.\nThis is the probability assigned by the translator: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÐ½Ðµ Ð½ÐµÑÐµÐ³Ð¾ ÑÐµÐ±Ðµ Ð´Ð°ÑÑ. \n    target text: I've got nothing to give you.\n    generated text: I don't have anything to give you.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the meaning and intent of the input text and the target text. It does not contain any nonsensical or factually incorrect information, and it does not introduce any additional information beyond what is supported by the input and target texts. Therefore, it is not a hallucination.\nThis is the probability assigned by the translator: 0.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð§ÑÐ¾ ÑÑ ÐµÐ¹ ÐºÑÐ¿Ð¸Ð»? \n    target text: What did you buy for her?\n    generated text: What did you buy her?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text is a shortened version of the target text and does not contain any nonsensical or factually incorrect information. It also does not add any unsupported information. Therefore, it aligns closely with the input and target texts, making it not a hallucination.\nThis is the probability assigned by the translator: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÑ Ð·Ð°Ð±ÑÐ»Ð¸ ÑÐ¿Ð¾Ð¼ÑÐ½ÑÑÑ ÑÑÐ¾. \n    target text: You forgot to mention that.\n    generated text: You forgot to mention it.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the meaning of the input and target texts without introducing any nonsensical or factually incorrect information. It does not contain any additional information that goes beyond the scope of the input and target texts. Therefore, it is not a hallucination.\nThis is the probability assigned by the translator: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÐ° Ð´ÐµÐ²Ð¾ÑÐºÐµ Ð±ÑÐ»Ð° Ð±Ð¾Ð»ÑÑÐ°Ñ ÐºÑÐ°ÑÐ½Ð°Ñ ÑÐ»ÑÐ¿Ð°. \n    target text: The girl had a large red hat on.\n    generated text: There was a big red hat on the girl.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the main idea of the input and target texts without adding any nonsensical or factually incorrect information. It maintains the same subject (the girl) and the description of her wearing a large red hat. There is no additional information that cannot be supported by the input and target texts. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the translator: 0.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÐ½ Ð² Ð±Ð¾Ð»ÑÐ½Ð¸ÑÐµ. \n    target text: He is in hospital.\n    generated text: He's in the hospital.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately conveys the information from the input text and aligns with the target text without introducing any nonsensical or factually incorrect information. There are no unsupported additional details. Therefore, it is not a hallucination.\nThis is the probability assigned by the translator: 0.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÐ´Ð½Ð¾ÐºÐ»Ð°ÑÑÐ½Ð¸ÐºÐ¸ Ð¢Ð¾Ð¼Ð° Ð¾Ð±Ð·ÑÐ²Ð°Ð»Ð¸ ÐµÐ³Ð¾. \n    target text: Tom's classmates called him names.\n    generated text: Tom's classmates called him.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Hallucination\".\nHere is the reasoning the translator provided: The generated text Toms classmates called him is missing the crucial detail of names that the classmates called him, which is present in the input and target text. This missing information changes the meaning of the sentence and introduces an unsupported deviation from the original meaning, making it a hallucination.\nThis is the probability assigned by the translator: 0.9\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÐ¾Ð¶ÐµÑÑ Ð±Ð¾Ð»ÑÑÐµ ÑÑÐ¾Ð³Ð¾ Ð½Ðµ Ð´ÐµÐ»Ð°ÑÑ. \n    target text: You don't have to do that anymore.\n    generated text: You can't do that anymore.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text You cant do that anymore is a close paraphrase of the target text You dont have to do that anymore and retains the general meaning of the original sentence. There are no nonsensical or factually incorrect information in the generated text. While there is a difference in the modality (dont have to vs cant), the overall meaning remains consistent with the original intention of not needing to do something anymore. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the translator: 0.2\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÐ¾ÑÐ¼Ð¾ÑÑÐ¸Ð¼, ÑÑÐ¾ Ð¢Ð¾Ð¼ Ð¿ÑÐ¸Ð´ÑÐ¼Ð°ÐµÑ. \n    target text: We'll see what Tom comes up with.\n    generated text: Let's see what Tom's coming up with.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text closely matches the meaning of the target text, with only minor differences in wording. It does not contain any nonsensical or factually incorrect information, nor does it introduce any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the translator: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÐ½Ðµ Ð½ÑÐ¶Ð½Ð¾ ÑÐµÐ±Ðµ ÐºÐ¾Ðµ-ÑÑÐ¾ Ð¾Ð±ÑÑÑÐ½Ð¸ÑÑ. \n    target text: I have something I need to explain to you.\n    generated text: I need to explain something to you.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the main idea of the input text and the target text without any nonsensical or factually incorrect information. It does not contain any additional information that cannot be supported by the input or target text.\nThis is the probability assigned by the translator: 0.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð¢Ð¾Ð¼ ÑÐ¾ÑÐ¾ÑÐ¾ Ð²ÑÐ³Ð»ÑÐ´Ð¸Ñ. \n    target text: Tom looks well.\n    generated text: That looks good.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text That looks good is a reasonable rephrasing of the target text Tom looks well without adding any nonsensical or factually incorrect information. It stays true to the meaning of the input and target text without introducing any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the translator: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð¢Ð¾Ð¼ Ð¿Ð¾Ð´Ð¾ÑÑÐ» Ðº ÐÑÑÐ¸ Ð¸ Ð¾Ð±Ð½ÑÐ» ÐµÑ. \n    target text: Tom walked over to Mary and hugged her.\n    generated text: Tom came to Mary and hugged her.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately conveys the main idea and action described in the input text and the target text. It does not contain any nonsensical or factually incorrect information, and there are no additional unsupported details. Therefore, it is not a hallucination.\nThis is the probability assigned by the translator: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÐµ Ð´ÑÐ¼Ð°Ñ, ÑÑÐ¾ Ð¢Ð¾Ð¼ Ð±ÑÐ´ÐµÑ Ð¿Ð¾Ð¼Ð¾Ð³Ð°ÑÑ Ð½Ð°Ð¼ ÑÑÐ¾ Ð´ÐµÐ»Ð°ÑÑ. \n    target text: I don't think Tom is going to help us do that.\n    generated text: I don't think Tom's gonna help us do this.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the meaning and intent of the input text and the target text. It does not contain any nonsensical or factually incorrect information, and it does not introduce any additional unsupported information. The only difference is the use of gonna instead of is going to, which is a common colloquial expression in English. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the translator: 0.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð Ð¾ÑÑÐ¸Ñ Ð¿ÑÐµÐ²ÑÐ°ÑÐ¸Ð»Ð°ÑÑ Ð²Ð¾ Ð²ÑÐ¾ÑÑÑ ÑÐ²ÐµÑÑÐ´ÐµÑÐ¶Ð°Ð²Ñ. \n    target text: Russia had emerged as a second superpower.\n    generated text: Russia has turned into a second superpower.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the main idea of the input text and aligns with the target text. There are no nonsensical or factually incorrect information in the generated text, and it does not contain any additional unsupported information. Therefore, based on the input text and the target text, the generated text is not a hallucination.\nThis is the probability assigned by the translator: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: ÐÐµÑÐ¸ Ð¿Ð¾Ð»ÑÑÐ¸Ð»Ð¸ Ð¿Ð¾Ð´Ð°ÑÐºÐ¸. \n    target text: The children got some presents.\n    generated text: The children received gifts.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the meaning of the input text and the target text without adding any nonsensical or factually incorrect information. It stays true to the original message and does not introduce any unsupported details. Therefore, it is not a hallucination.\nThis is the probability assigned by the translator: 0.1\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are an intelligent AI assisstant. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ð£ Ð¼ÐµÐ½Ñ Ð½ÐµÑ Ð´ÐµÐ½ÐµÐ³, ÑÑÐ¾Ð±Ñ ÐºÑÐ¿Ð¸ÑÑ ÑÐ»Ð¾Ð²Ð°ÑÑ. \n    target text: I have no money to buy the dictionary with.\n    generated text: I don't have any money to buy a dictionary.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA translator evaluated the generated text looking at the input text and the target text. The translator decided that the generated text is \"Not Hallucination\".\nHere is the reasoning the translator provided: The generated text accurately captures the meaning and intent of the input text and the target text. It does not contain any nonsensical or factually incorrect information, and it does not introduce any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the translator: 0.0\n",
        "query": "I would like you to reevaluate inputs taking the reasoning and the probability score provided by the annotator into account.\nPlease also remember that different human annotators are likely to judge the same input differently. They tend to disagree on the same input.\nWhen you assign a probability score, please consider if it would be considered a hallucination by 5 different human annotators or not.\nFeel free to change the answer and adjust the probability scores if you find it appropriate. Now it is time to make a final decision. \nIs the generated text a hallucination or not? For your answer, use the following json format: \n{\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    }
]