[
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: The writer had just entered into his eighteenth year , when he met at the table of a certain Anglo - Germanist an individual , apparently somewhat under thirty , of middle stature , a thin and <define> weaselly </define> figure , a sallow complexion , a certain obliquity of vision , and a large pair of spectacles . \n    target text: Resembling a weasel (in appearance).\n    generated text: Resembling or characteristic of a weasel.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning of weaselly as resembling or characteristic of a weasel, which aligns with the target text and the context provided in the input text. The additional information in the generated text is supported by the input and target texts without introducing any nonsensical or factually incorrect details. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the editor: 0.9\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Sailors ' and fishermen 's <define> sheath - knives </define> . Sailors ' sheath - knives .   Wilcox , Crittenden & Co. , Middletown , Conn.29428 .   Sheath and belt , with \" law - abiding \" sheath - knife . First quality.29426 .   Sheath and belt . Second quality.29427 .   Sheath and belt , with \" law - abiding \" sheath - knife . Third quality . The \" law - abiding \" sheath - knife is round at the tip of the blade , which is also thick and dull . \n    target text: .\n    generated text: Alternative form of sheath knife\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text Alternative form of sheath knife is not providing any nonsensical or factually incorrect information. It accurately captures the essence of the input text and target text, which both refer to sheath-knives. The generated text is a reasonable paraphrase of the given information without adding any unsupported details.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: As to age , Bead could not form any clear impression ; he might have been twenty , or forty . All of this visual perception occurred in an <define> eyewink </define> of time   [ � ] \n    target text: (poetic) An instant, a short moment.\n    generated text: (obsolete) A short period of time.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the essence of the target text by defining eyewink as a short moment, which aligns with the poetic meaning. The input text also supports this definition by describing the visual perception occurring in an eyewink of time. There are no nonsensical or factually incorrect information in the generated text, and it does not contain any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.9\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Because redpillers are usually normies or <define> Chadlites </define> while incels are ugly low - value males that women feel innately repulsed by . \n    target text: (incel, _, slang) A man of a slightly lower ranking on a scale of physical attractiveness than Chad.\n    generated text: (slang) An incel.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text only provides the definition for incel without incorporating any information about Chadlites as indicated in the input text and target text. It lacks the necessary details and context to accurately define Chadlites as intended in the input and target texts, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: On the second day of massive live - fire drills being held by the People 's Liberation Army ( PLA ) around Taiwan , Taiwan 's Army also conducted live - fire exercises in Lienchiang County 's Dongyin Township from 6 p.m. to 9 p.m. However , during the exercises , witnesses gave differing accounts of either tracer fire or flares landing on a hill behind Sanjia Village on <define> Xiyin </define> Island and starting a fire , reported UDN . \n    target text: An island in Dongyin, Lienchiang, Taiwan, in the Matsu Islands.\n    generated text: An island in Lienchiang County, Taiwan.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text only mentions Lienchiang County, Taiwan, and does not include the specific location of Dongyin or the Matsu Islands, which are crucial details for accurately defining Xiyin Island. This omission indicates that the generated text is missing important information and therefore does not align with the target text. As a result, there is a high probability that the generated text is a hallucination.\nThis is the probability assigned by the editor: 0.9\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Grouped in the center of the hall were about two hundred men , all armed with sabers , � men of every age , and height and swarthiness , from stout , <define> blue - bearded </define> veterans to youths yet in their teens   [ � ] \n    target text: Having thick, dark facial hair.\n    generated text: Alternative form of blue-bearded\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text Alternative form of blue-bearded does not accurately define the term as Having thick, dark facial hair as per the target text. It also adds unnecessary information that cannot be supported by the input or target text, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: The <define> sacrifice bunt </define> was fielded cleanly , but the only play was to first . \n    target text: (baseball) A ball that has been intentionally hit softly with a hands-spread batting stance with the intention of advancing a runner at the cost of an out\n    generated text: (baseball) A sacrifice bunt.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately represents the input and target texts, providing a brief definition of a sacrifice bunt in baseball without adding any nonsensical or factually incorrect information. While it lacks some details from the target text, it does not contradict or add any unsupported information beyond the input and target texts.\nThis is the probability assigned by the editor: 0.2\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: � She changes her shape depending on which way you 're coming at her . Once you know the contours of Bulgonunna you 'll never get <define> bushed </define> in this country . � \n    target text: (AU) Lost in the bush. [from 19th c.]\n    generated text: (Australia, New Zealand, slang) Drunk.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated definition Drunk does not align with the input text or the target text, which describe being lost in the bush, not intoxicated. This additional information is not supported by the input or target text, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: The <define> metaontology </define> debate has now migrated from discussions of composition . \n    target text: The ontology of ontology.\n    generated text: (linguistics) The study of the relationships between words and their meanings.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text does not accurately define the term ontology as requested by the input text and the target text. Instead, it provides a definition for metaontology, which is not mentioned in the input or target text. Therefore, it introduces additional information that cannot be supported by the given inputs and targets, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Poverty is the mother of <define> ingenuity </define> . \n    target text: The ability to solve difficult problems, often in original, clever, and inventive ways.\n    generated text: (uncountable) The quality or state of being ingenious.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the essence of the target text by defining ingenuity as the quality or state of being ingenious, which aligns with the ability to solve difficult problems in original, clever, and inventive ways. The definition does not contain nonsensical or factually incorrect information, and it does not introduce any unsupported additional information. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: \" But why should I be in another room ? \" \" You <define> passed over </define> in the night . \" \" Passed over ? Do you mean I died ? \" \" Yes , lady , you died . \" There was a long silence . \n    target text: (intransitive, euphemistic) To die and thus progress to the afterlife.\n    generated text: (intransitive) To die.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning of passed over in the context of the input and target texts. It aligns with the euphemistic meaning of to die and thus progress to the afterlife as stated in the target text. The generated text does not contain any nonsensical or factually incorrect information, nor does it introduce any additional unsupported details. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.9\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: an <define> obliquangular </define> triangle \n    target text: (archaic, geometry) Formed of oblique angles.\n    generated text: (geometry) Of or pertaining to an oblique angle.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately reflects the meaning of obliquangular as formed of oblique angles, which aligns with the target text. It doesnt contain nonsensical or factually incorrect information and doesnt introduce any unsupported details. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: It can be argued that explicit representations of bisexuality , pansexuality , and other multiple - gender - attracted people are erased from games that use ' <define> playersexuality </define> ' as a mechanic . \n    target text: (video games) The state of an NPC being attracted to the player character, especially without regard to gender, race, etc.\n    generated text: (video games) The state or condition of being bisexual in a video game.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text does not accurately reflect the definition of playersexuality provided in the input and target texts. It introduces the concept of bisexuality, which is not explicitly mentioned in the input or target texts. Additionally, it fails to capture the inclusive nature of playersexuality, which is not limited to being attracted to both genders. Therefore, the generated text contains additional information that cannot be supported by the input text or the target text, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Our algorithms rely on random sampling and their analysis leverages on Rademacher averages and <define> pseudodimension </define> , fundamental concepts from statistical learning theory . \n    target text: (maths)\n    generated text: Alternative form of pseudodimension\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text Alternative form of pseudodimension is directly related to the input text, as it presents a synonymous definition for pseudodimension. It does not contain nonsensical or factually incorrect information, nor does it introduce any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Those <define> daggum </define> thieves stole my car ! \n    target text: (US, euphemism, dialectal) goddamn\n    generated text: (colloquial) Used as an intensifier.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text Used as an intensifier does not capture the specific meaning of daggum as a euphemism and dialectal term for goddamn as provided in the target text. It also does not align with the input text, which indicates a specific context of car theft. Therefore, the generated text contains additional information that cannot be supported by the input text or the target text, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: [ � ]   and his physique was rather <define> hulksome </define> , with muscles built upon muscles giving him a chiseled statuesque appearance . \n    target text: Characteristic of a hulk; large and bulky; hulking.\n    generated text: Resembling or characteristic of a hulk.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning of hulksome as characteristic of a hulk, large and bulky, which aligns with the target text. It does not contain any nonsensical or factually incorrect information, nor does it include any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: He who first acts as striker asks the other how many blows of the <define> rattan </define> he will bear on his forearm without crying out . \n    target text: (by extension) A cane made from this material.\n    generated text: (South Asia, historical) A long, thin stick with a pointed end, used for striking.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately describes the physical characteristics and historical usage of rattan, which aligns with the target texts definition. It provides contextual information about the historical use of rattan as a long, thin stick with a pointed end for striking, which is not contradictory to the input or target text. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: <define> Taking on </define> a first employee should be done with care and consideration . \n    target text: To acquire, bring in, or introduce.\n    generated text: (transitive) To take on (a task or responsibility).\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning of taking on in the context of acquiring or introducing a first employee. It aligns with the input text and the target text by conveying the idea of assuming a task or responsibility, which is consistent with the act of bringing in a first employee with care and consideration. There is no nonsensical or factually incorrect information in the generated text, and it does not contain any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Ah ! they were grand days , those deep , full days , when our coming life , like an unseen organ , pealed strange , <define> yearnful </define> music in our ears , and our young blood cried out like a war - horse for the battle . \n    target text: Filled with yearning; desirous; mournful; distressing.\n    generated text: Full of longing; yearning.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the essence of the target text by describing the feeling of longing and yearning, which aligns with the input text depicting yearnful music in our ears. The generated text does not contain nonsensical or factually incorrect information and does not introduce any additional unsupported details. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Economics is a messy discipline : too fluid to be a science , too <define> rigorous </define> to be an art . Perhaps it is fitting that economists � most - used metric , gross domestic product ( GDP ) , is a tangle too . GDP measures the total value of output in an economic territory . Its apparent simplicity explains why it is scrutinised down to tenths of a percentage point every month . \n    target text: Showing, causing, or favoring rigour/rigor; scrupulously accurate or strict; thorough.\n    generated text: (uncountable) The quality of being rigorous.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately reflects the meaning of rigorous as it pertains to being thorough and strict, which aligns with the target text. It provides a definition that is consistent with the context of the input text and the target text without introducing any nonsensical or factually incorrect information. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Cheers <define> marrow </define> ! \n    target text: (Geordie, informal) A friend, pal, buddy, mate.\n    generated text: (slang) The human body.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text The human body does not align with the input text Cheers marrow! or the target text (Geordie, informal) A friend, pal, buddy, mate. Additionally, the definition The human body is factually incorrect in this context, leading to a high probability that the generated text is a hallucination.\nThis is the probability assigned by the editor: 0.9\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: The first of these patients especially dreads the flames of hell . This is the demonomania of Sauvages . I call it <define> demonophobia </define> , monodemonophobin . \n    target text: An irrational fear of demons.\n    generated text: (psychology) A fear of demons.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the essence of the target text by defining demonophobia as an irrational fear of demons, which aligns with the input text referencing fear of demons. The generated text does not contain any nonsensical or factually incorrect information, and it does not introduce any additional unsupported information. Therefore, it is a faithful representation of the input and target texts, making it not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Grids are used for such <define> quotidian </define> items as stationery , business cards , mailing labels , hang tags , instruction manuals , etc . \n    target text: Having the characteristics of something which can be seen, experienced, etc, every day or very commonly; commonplace, ordinary, mundane. [from 15th c.]\n    generated text: Of, pertaining to, or characteristic of quotidian life.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately reflects the meaning of quotidian as something commonplace or ordinary, which aligns with the target text. It doesnt contain any nonsensical or factually incorrect information, and it doesnt add any unsupported details beyond the input or target text. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: I never can cease admiring that beautiful request of the Prayer - book , � A happy issue out of all their affliction . � It is so humble , so <define> undictating </define> to God , so moderate , yet so ample . God give that to us both . Amen . In His way and time , and in this world and in the next . \n    target text: Not dictating.\n    generated text: Not dictating.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text Not dictating accurately reflects the meaning of the input text and the target text. It does not contain any nonsensical or factually incorrect information, and it does not provide any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: <define> parachutable </define> supplies \n    target text: Capable of being deployed by parachute.\n    generated text: Capable of being parachuted.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the essential meaning of the target text and is directly supported by the input text. It does not contain any nonsensical or factually incorrect information, and it does not add any unsupported details. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Some perhaps worship only on alternate Sundays ; others still more <define> occasionally </define> . \n    target text: From time to time; sometimes; at relatively infrequent intervals. [from 15th c.]\n    generated text: In an occasional manner.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text In an occasional manner aligns with the meaning of the target text From time to time; sometimes; at relatively infrequent intervals. and does not introduce any nonsensical or factually incorrect information. It accurately captures the infrequent and irregular nature described in the target text. Additionally, the input text Some perhaps worship only on alternate Sundays; others still more occasionally supports the infrequent nature of the worship. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: \" Christ \" � he yawned � \" Christ , what the hell is everybody getting so <define> pisspants </define> scared and nervous for ? Vince Eames is what ? A crook ? So ? ... \n    target text: (slang, vulgar, derogatory, rare) An objectionable or cowardly person.\n    generated text: (vulgar, slang) Very scared or nervous.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning of pisspants as something related to being scared or nervous, which aligns with the input text and the target text. It does not provide any nonsensical or factually incorrect information, nor does it contain additional unsupported information. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Many years ago , we decided to <define> relawn </define> and replant the garden . \n    target text: (transitive, rare) To provide with a new lawn.\n    generated text: (transitive) To plant again.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning of relawn as providing with a new lawn, which aligns with the target text. While it does not explicitly mention the rarity of this action, it does not provide any nonsensical or factually incorrect information. The generated text is directly related to the input and target texts without adding any unsupported information.\nThis is the probability assigned by the editor: 0.2\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: The artist took a thoughtful <define> toke </define> off the joint , then passed it along . \n    target text: (slang) A puff of marijuana.\n    generated text: (slang, uncountable) The act of smoking marijuana.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning of toke as a puff of marijuana, aligning with the target text. It provides additional information by specifying that it is the act of smoking marijuana, which is supported by the context of took a thoughtful toke off the joint. However, this additional information does not contradict the input text or the target text, and it enhances the understanding of the term. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the editor: 0.2\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Popular <define> cosplays </define> include , for example , characters from the Final Fantasy range of games [ � ] \n    target text: (countable) A skit or instance of this art or practice.\n    generated text: (informal) A cosplay.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text A cosplay is not a complete definition of cosplays as it does not capture the meaning of skit or instance of this art or practice as indicated in the target text. Additionally, the generated text does not align with the input text which mentions characters from the Final Fantasy range of games as an example of popular cosplays. Therefore, the generated text contains additional information that cannot be supported by the input text or the target text, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: � [ � ]   the Pope   [ � ]   had to send him a valuable Gift , which you may see some day . � N�ssler did , one day , see this <define> preciosity </define> : a Crucifix , ebony bordered with gold , and the Body all of that metal , on the smallest of altars , in Walrave �s bedroom . \n    target text: (obsolete, countable) Something of high value or worth.\n    generated text: The state or quality of being precious.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the essence of the target text by defining preciosity as the state or quality of being precious, which aligns with the concept of something of high value or worth. The input text also supports this definition by describing a valuable Gift received by the Pope. There are no nonsensical or factually incorrect information, and the generated text does not contain any additional unsupported information. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the editor: 0.9\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: A recent president of the International Association of Police Chiefs , an organization regarded almost universally as a bastion of ' <define> old - boyism </define> , ' was the female chief of police of Gaithersburg , Maryland . \n    target text: Alternative form of old boyism\n    generated text: (derogatory) The belief that men are superior to women and should be treated as such.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text contains additional information that cannot be supported by the input text or the target text. It introduces the idea of superiority of men over women, which is not present in the input or target text. This is a significant addition that goes beyond the scope of the given information, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: see Wikipedia : <define> tramp </define> steamer \n    target text: Any ship which does not have a fixed schedule or published ports of call.\n    generated text: (intransitive) To travel by trampoline.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text To travel by trampoline does not accurately define the word tramp as requested in the input text. Instead, it provides a nonsensical and factually incorrect definition that is not supported by the input text or the target text. It contains additional information that cannot be supported by the input and target text, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Each of their roles is so loaded with slickery , inconsistency and lowbrow intellectualisms , along with slapstick <define> gaggery </define> on which one can but gag , that the waste of talent is depressing . \n    target text: (informal) The use of gags or jokes.\n    generated text: (countable, uncountable) An instance of this.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text does not accurately define gaggery as the use of gags or jokes, as indicated by the target text. Instead, it provides a vague and incomplete definition that does not align with the informal definition provided in the target text. Therefore, it fails to capture the essence of gaggery as intended in the input and target texts, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: The same phenomenon is also detectable in the records of the meetings of NATO committees : the priority of avoiding any manifestation of internal disagreements led to the production of ' <define> sterilized </define> ' records of discussions which evidently were significantly more lively than shown in the official papers . \n    target text: (transitive) To redact (a document), removing classified or sensitive material.\n    generated text: (transitive) To sterilize.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text To sterilize does not accurately capture the meaning of redact (a document), removing classified or sensitive material as specified in the target text. It is a significant departure from the intended meaning and does not align with the context provided in the input text. Therefore, it is a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Only minds completely crazed or fatally confused by the current <define> Christomania </define> would suppose that the details of the story , which is as old at least as the cult of Ptah in Memphis , were derived from the \" historic \" version   [ � ] \n    target text: A fanatical devotion to Jesus Christ.\n    generated text: The belief that Jesus Christ is the savior of the world.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text The belief that Jesus Christ is the savior of the world contains additional information that cannot be supported by the input text or the target text. The input text mentions crazed or fatally confused individuals and the cult of Ptah in Memphis, but does not provide any context supporting the belief in Jesus Christ as the savior of the world. Therefore, the generated text goes beyond the scope of the input and target texts, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: The � black mists � of Japan did not die with Yoshio Kodama . In the spirit of the late <define> kuromaku </define> , questionable payments and mob connections still stretch far and wide among Japan 's elected officials   [ � ] \n    target text: In Japan, an �minence grise or secret decision-maker.\n    generated text: (historical) The Japanese mafia.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text The Japanese mafia is factually incorrect and contains additional information that cannot be supported by the input text or the target text. There is no mention of the Japanese mafia or any criminal organization in the input text or the target text. The term kuromaku refers to a secret decision-maker in Japan, not the Japanese mafia. Therefore, the generated text is a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: For use in a nursery for cradling a baby to sleep , a baby <define> cradler </define> comprising , in combination , a stand embodying a mobile base , uprights attached to and rising perpendicularly from the base and having axially aligned bearings ,   [ � ] \n    target text: One who or that which cradles.\n    generated text: One who or that which cradles.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text is a direct rephrasing of the target text and is supported by the input text, without introducing any additional information. The input text describes a cradler as one who or that which cradles, and the generated text reflects this definition accurately. There is no nonsensical or factually incorrect information, and no additional unsupported information, hence it is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: A <define> condoled chief </define> sits on the Grand Council that forms the leadership of the Confederacy . \n    target text: A tribal chief who sits on the Grand Council of the Haudenosaunee Confederacy.\n    generated text: (chiefly, North America) The chief of a Native American tribe.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately reflects the role of a tribal chief in the context of the Haudenosaunee Confederacy mentioned in the input and target texts. It provides a specific geographical and cultural context (North America, Native American tribe) which is consistent with the subject matter. The additional information provided does not contradict the input or target texts, and it enhances the understanding of the term chief in this particular context. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: A special group must be mentioned : 4 . artificial <define> immunodegradation </define> ( immunosuppression ) \n    target text: (immunology, rare) Degradation of or by the immune system.\n    generated text: (biochemistry, immunology) The degradation of the immune system.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text does not accurately define immunodegradation as it incorrectly states The degradation of the immune system without mentioning the target term immunosuppression. This additional information cannot be supported by the input text or the target text, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: He took his arrow by the <define> nock </define> . \n    target text: (archery) The notch at the rear of an arrow that fits on the bowstring.\n    generated text: (obsolete) The nock of an arrow.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text does not provide a specific definition of nock related to archery, which is the context given in the input and target texts. Instead, it simply states The nock of an arrow without explaining its function or purpose. This lack of information directly relevant to the context makes the generated text a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: to <define> shorten </define> an allowance of food \n    target text: (transitive) To reduce or diminish in amount, quantity, or extent; to lessen.\n    generated text: (transitive) To reduce the length of.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text To reduce the length of does not accurately capture the meaning of to shorten as defined in the target text, which is to reduce or diminish in amount, quantity, or extent; to lessen. The generated text is overly specific and does not encompass the full meaning of the word. Therefore, it adds information that cannot be supported by the input text or the target text, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Even more amusing is that those doing the wishful humping in <define> bandslash </define> are n't your usual pin - ups . Bandslash has gone indie . This is a shadowy world where the boys in Franz Ferdinand are each others ' fetish objects , and former Libertines Carl Barat and Pete Doherty , lovers . \n    target text: (fandom slang) Slash fan fiction which pairs real musicians, especially ones belonging to the same group.\n    generated text: Alternative form of bandslash\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text Alternative form of bandslash does not accurately define bandslash as Slash fan fiction which pairs real musicians, especially ones belonging to the same group as indicated in the target text. It also does not provide any additional information to support or clarify the definition. Therefore, it is a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: A weapon small enough to put on a missile would <define> require </define> uranium enriched to more than 90 % U-235 . \n    target text: Naturally to demand (something) as indispensable; to need, to call for as necessary. [from 15th c.]\n    generated text: (transitive) To require.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text directly matches the target text and accurately reflects the meaning of the input text. It does not contain any nonsensical or factually incorrect information, nor does it introduce any additional unsupported information. Therefore, it aligns with the inputs and targets without issue.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Should true Proportion ev'ry Mortal grace , / And Semetry be seen in ev'ry Face : / Beauty no longer would be thought divine , / Nor would its Charms with half the Lustre shine : / No courtly Dame a <define> killing </define> Look could boast , / If once the Foils of Homeliness were lost . \n    target text: (dated) Devastatingly attractive.\n    generated text: (obsolete) Very handsome.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the essence of the target text and is consistent with the input text. While obsolete may not fully align with dated in the target text, it does not introduce nonsensical or factually incorrect information. The definition Very handsome reflects the idea of devastatingly attractive present in the target text. Hence, the generated text is not a hallucination.\nThis is the probability assigned by the editor: 0.8\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: The <define> preejection </define> shortening and relengthening correspond to septal beaking and flash . \n    target text: Occurring prior to ejection.\n    generated text: (anatomy) The act or process of preejection.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text goes beyond the information provided in the input and target text by defining preejection as The act or process of preejection, which is not supported by the context. The target text Occurring prior to ejection does not align with the generated definition, making it an unsupported addition. Therefore, the generated text is a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: He had a nasty face though , the boy considered , and looked like a bounder because he had pimples , a <define> swelly </define> nose , a loud voice , and a swanky manner . The boy disapproved of him wholly . \n    target text: (informal) Tending to bulge or swell.\n    generated text: (informal, of a face) Having pimples.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text incorrectly defines swelly as having pimples which is not supported by the input text or the target text. Additionally, the generated text does not capture the meaning of swelly as tending to bulge or swell as provided in the target text. Therefore, the generated text contains nonsensical and factually incorrect information, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: ELYOT : And you �re an ill - mannered , bad tempered <define> slattern </define> . \n    target text: (dated) One who is uncareful or unconcerned about appearance or surroundings, usually said of a dirty and untidy woman.\n    generated text: (slang) A contemptible person.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text does not accurately reflect the definition of slattern provided in the target text. It lacks the specific details about being uncareful or unconcerned about appearance or surroundings, and instead provides a general and slang-based description. Additionally, the generated text introduces information about contemptibility which is not supported by the input or target text. Therefore, it contains additional information that cannot be supported by the input text or the target text, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: � Because I don&#39;t think that is a seventeenth - century helmet . � There was something odd about the smoothness of the crown . The skull of the <define> lobster - tailed pot </define> helmet was often fluted . Generally , they were made in two sections joined by a � ... \n    target text: A European combat helmet, worn especially from the 1600s into the 1700s, consisting of a rounded skull-piece, often cheek guards and a nasal or face-guard, and a laminated defence (or single plate ridged to imitate lames) to protect the back of the neck that resembled a lobster's tail.\n    generated text: Alternative form of lobstertail\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text Alternative form of lobstertail does not provide a definition for lobster-tailed pot helmet as requested in the input text, nor does it accurately describe the helmet as a European combat helmet worn from the 1600s to 1700s. Instead, it provides an unrelated phrase that does not align with the input or target text. Therefore, it does not fulfill the purpose of defining the term lobster-tailed pot helmet and is not supported by the input or target text, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Because of his disappearance over the final two months last season , Reyes has been the target of Shea <define> boobirds </define> , which , as Wright remarked , is almost a � rite of passage . � \n    target text: (slang) A spectator at a sporting event who boos the home team.\n    generated text: (slang, derogatory) A woman.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text A woman does not align with the input text or the target text, which describe boobirds as spectators at a sporting event who boo the home team. There is no support in the input or target text to suggest that boobirds refers to women, and this additional information is not substantiated. Therefore, the generated text is a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: As expected , monolayers showed rapid cell rounding and <define> cytopathicity </define> in cells infected with MNV ( Fig 3 , 20 X insert in MNV infection ) . \n    target text: The condition of undergoing cytopathic change (cell disease)\n    generated text: The quality of being cytopathic.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately reflects the concept of cytopathicity as described in the input and target texts. It does not contain any nonsensical or factually incorrect information, nor does it introduce any additional unsupported information. Therefore, it aligns with the given inputs and targets.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: while Tungsten is not heavily redundant as these systems , the ability of Lustre to support some <define> failover </define> can be leveraged to eliminate single points of failure . \n    target text: (computing, countable) An automatic switch to a secondary system on failure of the primary system, such as a means for ensuring high availability of some critical resource (such as a computer system), involving a parallel backup system which is kept running at all times, so that, upon detected failure of the primary system, processing can be automatically shifted over to the backup.\n    generated text: Alternative form of failover\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text does not provide a definition as requested, but instead states Alternative form of failover without any explanation or connection to the input or target text. This additional information cannot be supported by the input or target text, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: opposed unto mutability and <define> defectibility </define> of being \n    target text: deficiency; imperfection\n    generated text: The quality of being defectible.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning of the target word defectibility as The quality of being defectible and aligns with the input text that talks about mutability and defectibility of being. It does not contain any additional unsupported information or factual errors, making it a faithful representation of the given inputs and targets.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Son , the <define> cyber dissident </define> , is a businessman who holds graduate degrees in business administration and medicine . \n    target text: Alternative form of cyberdissident\n    generated text: (Internet) A person who uses cyberspace to express their political views.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text provides a reasonable and accurate definition of cyber dissident in the context of expressing political views in cyberspace, which aligns with the target text Alternative form of cyberdissident. It does not contain nonsensical or factually incorrect information, and it does not introduce any additional unsupported details. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: The pseudembryo moves rapidly in the water , rolling round and swinging from side to side ; as a rule , and especially when at rest , the surface bearing the pseudostome and <define> pseudoproct </define> is turned downwards . \n    target text: (biology) The anal opening on the pseudembryo of an echinoderm.\n    generated text: (zoology) A pseudostome.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text does not accurately define pseudoproct as requested. Instead, it simply repeats pseudostome, which does not align with the target text about the anal opening of the pseudembryo in echinoderms. This discrepancy indicates a lack of factual accuracy and relevance to the given inputs and targets, leading to a high likelihood of hallucination.\nThis is the probability assigned by the editor: 0.9\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: A second Punta del Este <define> dateliner </define> , by Juan de Onis , quoted Secretary of State Dean Rusk giving the official U. S. view , which had already been reported extensively by Kenworthy and Szuie . \n    target text: (journalism) An article that is published under a dateline.\n    generated text: (countable) A newspaper article published on a specific date.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text provides a definition that goes beyond the scope of the input text and the target text. It includes the specific detail of being published on a specific date, which is not supported by the input or target. This additional information is not present in the original context and thus constitutes a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: But purging is more proper if it may bee done without danger , as it may in the fourth , fift and ?ixt month of <define> pregnation </define> : for a child in the wombe is compared to an Apple on the tree . \n    target text: (obsolete) Pregnancy.\n    generated text: (uncountable) The state of being pregnant.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning of the word pregnation in the context of the input text and the target text. It provides a concise definition that aligns with the obsolete meaning of pregnancy. There are no nonsensical or factually incorrect information, and the generated text does not contain any additional unsupported information. Therefore, it is not hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: The following appear rather like <define> revamps </define> of old versions absolutely than absolutely new jokes :   [ � ] \n    target text: An act of improving, renewing, renovating, or revising something; an improvement, renovation, revamping, or revision. [from mid 19th c.]\n    generated text: (informal) A revision.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning of revamps as an act of improving, renewing, renovating, or revising something, which aligns with the target text. It is a concise informal synonym that does not contain any nonsensical or factually incorrect information. Although it is less precise and comprehensive than the target text, it does not provide additional unsupported information. Therefore, it is not hallucination.\nThis is the probability assigned by the editor: 0.2\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: They did n't need to be first in sales ; they did n't have to compete with the <define> hypesters </define> . Louis junior could honestly say that the wines he made were sound . \n    target text: One who uses hype to promote or advertise.\n    generated text: One who hypes something.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning of the target text by defining hypesters as one who hypes something, which aligns with the concept of using hype to promote or advertise. It does not contain any nonsensical or factually incorrect information, and it does not introduce any additional unsupported information. Therefore, it is not hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: With a tremendous groan , he <define> pulled out </define> and ejaculated all over her belly . \n    target text: (literally) To use coitus interruptus as a method of birth control.\n    generated text: (intransitive) To ejaculate.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text only provides a limited and incomplete definition of the term pull out, focusing solely on the act of ejaculating, while ignoring the context of birth control and coitus interruptus provided in the target text. This additional information is essential for a complete and accurate definition, making the generated text a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: A total of 18 patients ( 22.5 % ) had persistent HBsAg positivity after transplant without <define> seroclearance </define> ( n = 8) or reappearance of HBsAg after initial seroclearance ( n = 10 ) . \n    target text: The clearance (removal) of an antigen from the blood\n    generated text: (medicine) Seroclearance.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text Seroclearance does not accurately define the concept of clearance (removal) of an antigen from the blood as stated in the target text. It lacks the necessary detail and precision required for a medical definition. Additionally, the generated text does not align with the context provided in the input text, as it does not mention the specific clearance of an antigen from the blood. Therefore, it introduces additional information that cannot be supported by the input text or the target text, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: She had never met someone so <define> sweaty </define> . \n    target text: Having a tendency to sweat.\n    generated text: (informal, of a person) Intoxicated.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text intoxicated does not accurately describe the meaning of sweaty as indicated by the target text having a tendency to sweat. Additionally, intoxicated introduces information that cannot be supported by the input text or the target text, making it factually incorrect and nonsensical in this context.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: She was lying in the lee of a fowlhouse in a crumpled posture , as if cohesion had been detached from her joints , which lobbed her in an untidy heap , like a lot of old bones , tied together with string . Her skull was hitched under her humped shoulders and her fallen jaw made a lipless <define> O </define> of her mouth , giving it an expression of imbecile astonishment . \n    target text: Something shaped like the letter O.\n    generated text: (informal) The sound made by the mouth when it opens and closes.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately describes the shape of the letter O, which is supported by the comparison of the womans mouth to the letter O in the input text. There is no nonsensical or factually incorrect information in the generated text, and it does not contain any additional unsupported information. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Thomas writes of <define> matrescence </define> as spiritual formation drawing analogies with the Judaeo - Christian tradition . \n    target text: The process of becoming (and coming to inhabit the role of) a mother.\n    generated text: The act of maturing.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text The act of maturing does not accurately capture the meaning of matrescence as the process of becoming (and coming to inhabit the role of) a mother. It lacks the crucial aspect of transitioning into motherhood and the associated role. Additionally, the generated text introduces the concept of maturing, which is not supported by the input or target text. Therefore, the generated text is a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: While the United States remained a <define> non - belligerent </define> speeds continued unimpaired , despite the increasingly dense occupation of main - line tracks , but the entry of the U.S.A. into the war in December , 1941 , made its effect felt almost immediately . \n    target text: Alternative form of nonbelligerent\n    generated text: Alternative form of non- belligerent\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text is not a hallucination because it correctly identifies non-belligerent as an alternative form of nonbelligerent, which is supported by the input text and the target text. There are no nonsensical or factually incorrect information, and no additional unsupported information in the generated text.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: As long as you get the vice president 's approval first , it 'll be a <define> slam dunk </define> . \n    target text: (colloquial, idiomatic) A task expected to present no difficulty, a piece of cake.\n    generated text: (idiomatic) Something that is certain to be successful.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the essence of the idiomatic expression slam dunk as something certain to be successful, which aligns with the target text. It does not contain any nonsensical or factually incorrect information, and it does not introduce any additional unsupported information. Therefore, based on the given inputs and targets, the likelihood of the generated text being a hallucination is very low.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: This particular article , published to my site kheperu.org in 2002 , was penned in response to a letter received from a <define> psivamp </define> who had stirred up trouble for himself by outing his nature to his Wiccan High Priestess . \n    target text: A supposed form of vampire that subsists on the psychic energy of others.\n    generated text: (fandom slang) A person with psionic abilities.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text provides a definition that is unrelated to the target text and introduces information not supported by the input text or the target text. It introduces the concept of fandom slang and refers to a person with psionic abilities, which is not mentioned or implied in the input or target text. The target text specifically defines psivamp as a supposed form of vampire that subsists on the psychic energy of others, which is entirely different from the generated definition. Therefore, the generated text is a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Sir Georg Solti and the Chicago Symphony Orchestra may have been <define> made for each other </define> , but they were also made to play Beethoven . \n    target text: (idiomatic) Compatible; interacting effectively; in a complementary relationship.\n    generated text: (idiomatic) Perfectly suited for each other.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning of the idiomatic expression in the target text and is consistent with the input text. It does not introduce any nonsensical or factually incorrect information, nor does it contain any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Maybe during the first session we can try to size up the type of anger problem she has : exploding ? <define> underhanding </define> ? somatizing ? \n    target text: Devious; passive-aggressive.\n    generated text: (transitive) To act in an underhanded manner.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning of underhanding as defined in the target text, and it aligns with the context of the input text which discusses the type of anger problem the person has. The definition provided by the DM system does not contain any nonsensical or factually incorrect information, and it does not introduce any additional unsupported information. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Quatermass also mediated Wellsian influence on the tone and preoccupations of the new hybrid SF � horror - film genre , with its monstrous <define> Gigeresque </define> fusions of machine and organism [ � ] \n    target text: Reminiscent of H. R. Giger (born 1940), Swiss surrealist painter best known for nightmarish biomechanical imagery.\n    generated text: Resembling or characteristic of French surrealism.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text does not accurately describe the meaning of Gigeresque in relation to H. R. Giger. It provides a definition related to French surrealism, which is factually incorrect and nonsensical in the context of the input and target texts. Additionally, the generated text introduces information about French surrealism that is not supported by the input or target texts, making it an inaccurate and unsupported addition.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: At least Dr. Beeching can no longer be accused by anyone of disinterest in railways , after the king - sized squib he flung into one of the particularly combustible <define> pre - election </define> topics - transport - at the end of June . \n    target text: Alternative form of preelection\n    generated text: Before an election.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text Before an election. does not accurately represent the target text Alternative form of preelection and does not provide a meaningful definition of the term. It lacks specificity and does not capture the essence of the term preelection as it relates to the context of the input text. Therefore, it is a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: so as no fuller on earth can <define> white </define> them \n    target text: (transitive) To make white; to whiten; to bleach.\n    generated text: (transitive) To make white.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the transitive nature of the verb define and its relation to white, which aligns with the input text and the target text. The generated text does not contain any nonsensical or factually incorrect information, and it does not introduce any additional unsupported details. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Elytra <define> miniatous </define> , with a large somewhat triangular black spot on their disk ,   [ � ] \n    target text: (formal) Orange-red, the colour of red lead.\n    generated text: (zoology) Of or pertaining to a minotaur.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text is unrelated to the input text and target text. It introduces a concept (minotaur) that has no connection to the word miniatous or the color orange-red. Additionally, the term minotaur is a mythological creature, not a color, and does not align with the zoological context of the input text. As a result, the generated text is not supported by the inputs and is factually incorrect, leading to a high probability of hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: This is the sort of witchery , not easily defined � but , by its votaries , pretty sensibly felt , in hunting the fox . The light - hearted , high - spirited stripling , when cigaring it careless to cover , with a kind of a knowing demi - <define> devil - may - care </define> twist of his beaver , receives in his transit a benison from every real friend of the chase he may chance to pass ; and the airy , eager zeal of the youthful aspirant to rolls , tumbles , and the brush , will flush his memory with the frolic gayety of other days , and animate his mind with reflections most welcome to his heart . \n    target text: Carefree, reckless, irresponsible.\n    generated text: Alternative form of devil-may-care\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text Alternative form of devil-may-care accurately reflects the meaning of the input text and the target text, describing someone as carefree, reckless, and irresponsible. It does not contain any nonsensical or factually incorrect information, nor does it add any unsupported details. Therefore, based on the input and target texts, the generated text is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Pimpin � came so naturally to MT when he and his sisters played pimp and <define> hoe </define> games that one of his sisters wanted to hoe for him when they grew up . \n    target text: (US, slang) .\n    generated text: (intransitive, slang) To have sex.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text is a direct and accurate definition of the slang term hoe in the context of pimping, as used in the input text. It does not contain nonsensical or factually incorrect information, and it does not provide additional unsupported information beyond the input and target texts. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: I met one of your dons at tea , and he said that your degree was not in the least a proof of your abilities : he said that you knocked up and got <define> flurried </define> in examinations . \n    target text: Agitated, confused.\n    generated text: (transitive, slang) To fail (an examination).\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning of flurried as agitated and confused, which aligns with the target text. It does not contain any nonsensical or factually incorrect information, and it does not introduce any additional unsupported information beyond the input and target texts. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: And on tonight �s episode , when she faces a crisis � the reactions to her incoherent TV interviews last January � the carefully created sentences she uses to explain her slurry , <define> stumbly </define> self - presentation says it all . \n    target text: prone to stumble\n    generated text: (figuratively, of a person) Having a tendency to stammer.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning of prone to stumble by describing someone who has a tendency to stammer, which aligns with the idea of being incoherent and slurry in self-presentation. The additional information provided in the generated text does not contradict the input or target text, and it helps to further clarify the meaning of stumbly. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Replying students did not differ significantly from <define> nonreplying </define> students in predicted grade - point averages . \n    target text: Not replying (to a survey etc.).\n    generated text: Not responding.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text Not responding accurately captures the meaning of the target text Not replying (to a survey etc.) without adding any nonsensical or factually incorrect information. The generated text aligns with the context provided by the input text and the target text, making it a faithful representation of the intended meaning without any hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: And its success or failure is likely to tell whether talents as varied as Will Ferrell , Tom Cruise , Jerry Bruckheimer , Derek Jeter or Norah Jones � Creative Artists clients all � will maintain their leverage against evolving media giants like the News Corporation and Viacom or make new fortunes from the <define> nonentertainment </define> companies that are looking to Hollywood . \n    target text: Not of or pertaining to entertainment.\n    generated text: Not entertainment.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the essence of the target text by expressing the concept Not of or pertaining to entertainment in a concise manner. It does not introduce any additional unsupported information and aligns with the context provided in the input text.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: It was both the doctrine of the apostles , and the practice of the church , while it was <define> symmetral </define> , to obey the magistrate . \n    target text: (obsolete) commensurable; symmetrical\n    generated text: Of or pertaining to symmetry.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning of symmetral as commensurable and symmetrical, as indicated by the target text. It does not contain any nonsensical or factually incorrect information, and it does not provide additional unsupported information beyond what is provided in the input and target texts. Therefore, it is not hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: We use a mouse model of DEND syndrome ( nV59 M mice ) to determine if subcutaneous or <define> intracranioventricular </define> administration of glibenclamide can affect neurological function . \n    target text: Within a ventricle of the brain\n    generated text: (anatomy) Relating to the cerebrum\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text Relating to the cerebrum contains additional information that cannot be supported by the input text or the target text. The target text specifically refers to Within a ventricle of the brain, which is anatomically specific, whereas the generated text is more general and not directly related to the ventricle of the brain. This additional and unrelated information makes the generated text a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: � What are you doing ? � Carly asked , looking around . � You do n�t want to be in here . You �re way too much of a princess . � / � Remember how I grew up , Carly . I �ve earned my <define> princessness </define> . � \n    target text: The quality of being a princess.\n    generated text: The state or quality of being a princess.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the essence of the target text, which is The quality of being a princess. It does not contain any nonsensical or factually incorrect information, and it does not introduce any additional unsupported information beyond the input and target texts. Therefore, it aligns with the given inputs and target without any issues.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: <define> exacerbators </define> of pulmonary disease \n    target text: One who, or that which, exacerbates or makes worse.\n    generated text: One who exacerbates.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the essence of the target text by defining exacerbators as One who exacerbates which aligns with the meaning of exacerbates or makes worse. While the generated text is more concise than the target text, it still conveys the same core concept without introducing any nonsensical or factually incorrect information or including additional unsupported details. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.9\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Within seconds , the air was thick with flying potato chips , <define> cheezies </define> and other odds and ends . \n    target text: (Canada) A cheese puff.\n    generated text: (informal) Cheez-Its.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text Cheez-Its does not accurately reflect the given target text A cheese puff and contains additional information not supported by the input or target text. In this context, Cheez-Its is not a suitable synonym for cheezies as it does not align with the Canadian definition provided. Therefore, the generated text is a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Love and sex , these were an icing on his whole <define> cakeful </define> of goodies . Like many women , Rebecca realized that such a cakeful of goodies could not exist for him were she not there to do the innumerable drudge tasks of daily existence . \n    target text: As much as a cake has.\n    generated text: (figuratively) A large amount.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the figurative meaning of cakeful as a large amount, which aligns with the context of the input and target text. It does not introduce any nonsensical or unsupported information, and it stays consistent with the theme of the cakeful of goodies mentioned in the input text. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: And that <define> jiboney </define> across the hall . He makes life worse than it is . Where he gets his money for booze , who knows ? \n    target text: A low-level tough or thug, a mean man.\n    generated text: (slang, derogatory) A contemptible person.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text A contemptible person captures the essence of a mean and tough person, which aligns with the target text A low-level tough or thug, a mean man. The input text also suggests negative traits by stating He makes life worse than it is. There are no nonsensical or factually incorrect information in the generated text, and it does not contain additional unsupported information. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the editor: 0.9\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: The Handel excerpts are afflicted with a combination of high surface noise from the source material as well as variably <define> muzzy </define> sound . \n    target text: (dialect, Northern England) Blurred, hazy, indistinct, unfocussed.\n    generated text: Resembling or characteristic of muzzles.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text Resembling or characteristic of muzzles does not accurately define muzzy as hazy or indistinct, as required by the target text. It introduces unrelated information about muzzles which is not supported by the input or target text. Therefore, the generated text is a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: in the <define> overbuilt </define> exurbs of the megalopolis \n    target text: (real estate) Overdeveloped.\n    generated text: Overbuilt.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text Overbuilt directly matches the target text (real estate) Overdeveloped without adding any nonsensical or factually incorrect information. The input text in the exurbs of the megalopolis supports the idea of overdevelopment or overbuilding in a real estate context. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: an <define> unfulfillably </define> expansive vision of social reform \n    target text: In a way that cannot be fulfilled.\n    generated text: In an unfulfillable manner.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning of unfulfillably as in a way that cannot be fulfilled without containing any nonsensical or factually incorrect information. It does not add any additional unsupported information beyond the input text and the target text. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: If you have violent fantasies of evil women owning males as absolute property , with such elements as <define> genitorture </define> , castration , amputation , skinning alive , cooking alive , butchering , cannibalism , etc , you owe it to yourself to give Katharsis a look see . \n    target text: (BDSM) torture of the genitals\n    generated text: (uncountable) The act of genitorturing.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text does not accurately define genitorture as torture of the genitals as specified in the target text. Additionally, it lacks the specific elements mentioned in the input text such as castration, amputation, skinning alive, cooking alive, butchering, and cannibalism. Therefore, the generated text contains additional information that cannot be supported by the input text or the target text, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: \" That venerable old <define> ripsnorter </define> defended the right of the clergy to drive fast horses \" -- Phil Stong \n    target text: (slang) a violently energetic or noisily outspoken person; someone using slambang methods\n    generated text: One who rips.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text One who rips does not accurately capture the meaning of ripsnorter as a violently energetic or noisily outspoken person using slambang methods, as provided in the target text. It also lacks the context of fast horses and the right of the clergy mentioned in the input text. Therefore, it is a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: \" They do eat up one 's time � \" she checks herself again , checks her lapdog 's struggles against <define> lapdoggery </define> , and interviewers , and dubious , childless relationships   [ � ] \n    target text: Behavior or activity characteristic of a lapdog, such as idleness or submission.\n    generated text: (informal) The practice of behaving like a lapdog.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the essence of lapdoggery as behavior or activity characteristic of a lapdog, such as idleness or submission, which aligns with the target text. It does not contain any nonsensical or factually incorrect information, and it does not introduce any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: To remove <define> moth </define> patches , wash the spots with a solution of common bicarbonate of soda and water several times a day , until the patches are removed , which will usually be in forty - eight hours . \n    target text: (dated) A liver spot, especially an irregular or feathery one.\n    generated text: Any of various insects of the family Mothidae, especially those of the genus Mothia.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text provides a definition of moth as Any of various insects of the family Mothidae, especially those of the genus Mothia, which does not align with the target text or the context of the input. The target text refers to a liver spot, while the input context suggests the use of a solution to remove patches. The generated definition introduces irrelevant information about insects and their classification, which does not match the context or the target definition. Therefore, it is a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: His <define> septicentennial </define> in 1984 occasioned widespread congresses and celebrations , not least in the United States , including an Alfonsine exhibit at the Library of Congress . \n    target text: 700th anniversary.\n    generated text: The anniversary of the discovery of the septic system.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text contains factually incorrect information as it refers to the septic system, which is not related to the actual definition of septicentennial. Additionally, the generated text introduces information about the discovery of the septic system, which is not supported by the input text or the target text. Therefore, the generated text is a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: The statue sitting on the throne wore the Warlock 's <define> cat - fur </define> coat , but it also showed Guismond as a warrior King . \n    target text: Alternative form of cat fur\n    generated text: Alternative form of cat-fur\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text Alternative form of cat-fur matches the target text Alternative form of cat fur by simply combining the words without adding any nonsensical or factually incorrect information. The input text mentions the Warlocks coat made of cat fur, which aligns with the concept of an alternative form of cat fur. The generated text does not introduce any additional unsupported information.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Usually we 'll listen to a track . It just depends . Sometimes they have a funny premise or a certain vibe and we 'll make something oriented towards that premise or vibe . If it passes the <define> vibe check </define> , we kick things off . \n    target text: (slang) An impromptu attempt to ascertain mood, opinions, or attributes.\n    generated text: (informal) A test to determine whether something has a certain vibe.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the essence of the target text by defining vibe check as a test to determine whether something has a certain vibe, which aligns with the impromptu attempt to ascertain mood, opinions, or attributes mentioned in the target text. The generated text does not contain any nonsensical or factually incorrect information, and it does not add any unsupported information beyond the input and target texts. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.9\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: I <define> handed over </define> the controls to the copilot . \n    target text: (transitive, idiomatic) To relinquish control or possession of something to someone.\n    generated text: (transitive) To give (something) to someone else.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately reflects the action of giving control to someone else, which aligns with the target texts definition. It does not contain any nonsensical or factually incorrect information, and it does not introduce any unsupported additional information. Therefore, it is consistent with the input and target texts.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: This trouble must not be confused with <define> milklessness </define> which is discussed in the next section . The possibility of the cow sucking herself or letting other animals suck her must also be considered . \n    target text: Absence of milk.\n    generated text: The state or condition of being milkless.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately defines milklessness as the absence of milk, which aligns with the target text. It does not contain any nonsensical or factually incorrect information, and it does not provide additional unsupported information beyond the input and target text. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: considering the heterogenity in plantmaterial[sic ] and soil it is only the aim to collect orientating data on the development of Pinus mercusii in function of the different plantpit treatments carried out at a very eroded site where <define> reboisation </define> with this type of tree is considered \n    target text: (Indonesia) Reforestation.\n    generated text: The process of reboising.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text The process of reboising does not accurately define the term reboisation as Reforestation as given in the target text. Additionally, the input text does not provide any context or information that supports the definition The process of reboising. Therefore, the generated text contains additional information that cannot be supported by the input text or the target text, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: She <define> tag teamed </define> with the Lock for awhile before managing Rock and Blade , the Star Riders , in Florida . \n    target text: Alternative form of tag-team\n    generated text: (sports) To compete in a tag team match.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning of tag teamed as an alternative form of tag-team, which aligns with the target text. It does not contain any nonsensical or factually incorrect information, nor does it introduce any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: We 've got a bogey at <define> nine o'clock </define> . \n    target text: (informal) To the left (horizontal clock orientation) (from the location of the 9 mark on a clock face)\n    generated text: (golf) The ninth hole of a golf course.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text about the ninth hole of a golf course is completely unrelated to the input text and the target text, which both refer to a clock face and the direction nine oclock. This additional information is not supported by the input or target text, making it a clear case of hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: <define> Barkeep </define> , a couple of beers here , please ? \n    target text: (informal) a bartender\n    generated text: (informal) A bartender.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text matches the target text a bartender and is a reasonable paraphrase of the input text Barkeep, a couple of beers here, please? without adding any nonsensical or factually incorrect information. Therefore, it is not hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: to <define> misadapt </define> to one 's environment \n    target text: To adapt in the wrong way.\n    generated text: (intransitive) To fail to adapt.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated definition To fail to adapt aligns with the input text to misadapt to ones environment and the target text To adapt in the wrong way. It does not contain any nonsensical or factually incorrect information, and it does not introduce any additional unsupported information. Therefore, it is a valid interpretation of the input and target texts.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: To coincide with the launch , LNER has introduced fixed - price <define> all - in - one </define> return fares for two adults and up to four children , priced at � 129 between London , Thornaby and London . \n    target text: Combining two or more items in one unit.\n    generated text: Alternative form of all-in-one\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text provides an alternative form of the term all-in-one, which aligns with the concept of combining two or more items in one unit as indicated in the target text. It does not contain any nonsensical or factually incorrect information and does not introduce any unsupported additional information. Therefore, it is consistent with the input text and target text, and is not a hallucination.\nThis is the probability assigned by the editor: 0.9\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: A third difference between harvester ant stings and other stings is localized <define> piloerection </define> , the standing up of the hairs around the sting site . \n    target text: The erection of hairs or papillae\n    generated text: (anatomy) The formation of hairs around the sting site.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the concept of piloerection as the standing up of hairs or papillae, which aligns with the target text. It does not contain any nonsensical or factually incorrect information, and it does not introduce any additional unsupported details beyond the input and target texts. Therefore, based on the given inputs and targets, the generated text is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Good Fridays were unremarkable except for the hot - cross buns that Aunty Sue used to bake , and the drive to Point Fortin to look for Good Friday <define> bobolees </define> . \n    target text: An effigy of Judas Iscariot that is attacked as part of the Good Friday celebration in Trinidad.\n    generated text: (Australia, New Zealand, informal) A bun.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text does not align with the target text or the input text. It provides an unrelated and factually incorrect definition for bobolees in the context of the Good Friday celebration in Trinidad. Additionally, it adds information about Australia and New Zealand, which is not supported by the input or target text.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: The body , however , failed to alter the <define> bare - knuckle </define> politics governing the nominating convention . \n    target text: (by extension) Characterized by ruthlessly attacking or overpowering an opponent, especially when using underhanded techniques.\n    generated text: (idiomatic) Unconstrained, unadulterated.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text Unconstrained, unadulterated does not accurately capture the meaning of bare-knuckle as described in the target text. It fails to convey the idea of ruthlessly attacking or overpowering an opponent using underhanded techniques, which is the essence of the term. Additionally, the generated text introduces information (idiomatic) not present in the input or target text, making it unsupported and thus a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: In flashes , they do transcend their influences -- particularly Newman , whose beautifully illogical machinations can morph from dry harmonic plinks to <define> banjolike </define> plonks to ominous , industrial - sounding hums . \n    target text: Resembling or characteristic of a banjo\n    generated text: Resembling or characteristic of a banjo.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text directly reflects the meaning of the target text and is supported by the input text as it describes the transition from dry harmonic plinks to banjolike plonks, which implies a resemblance to a banjo. There are no nonsensical or factually incorrect statements, nor additional unsupported information. Hence, it is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: The characters are all quirky and life - size ( the Dillon character 's <define> superstitiousness </define> is one of the principal motors of the plot , and the story 's outcome does n't prove him wrong ) , and , as with the burglaries in Breaking In , the treatment of drugs is refreshingly free of either moralizing or romanticizing . \n    target text: (rare) superstition\n    generated text: The quality of being superstitious.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately defines superstitiousness as the quality of being superstitious, which aligns with the target text superstition. The input text also supports the presence of superstitiousness in the Dillon character. There are no nonsensical or factually incorrect information in the generated text, and it does not contain any additional unsupported information. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the editor: 0.9\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: <define> white </define> birch \n    target text: Relatively light or pale in colour.\n    generated text: (botany) Having a white colour.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning of white as relatively light or pale in colour, which aligns with the target text. It does not contain nonsensical or factually incorrect information, nor does it introduce any additional unsupported information. Therefore, it is not hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: A few years ago grey - haired people as well as little children were seized with the <define> stampomania </define> , and then our most secret drawers , our most private papers , our most loving letters of bygone years were ransacked by our best friends   [ � ] \n    target text: A passion for collecting postage stamps.\n    generated text: (informal) An obsession with stamps.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the essence of stampomania as a passion for collecting postage stamps, which aligns with the target text. While the word obsession may be considered slightly stronger than passion, it still conveys the same idea and does not introduce any nonsensical or factually incorrect information. Additionally, the input text describes people being seized with stampomania, indicating a strong interest or obsession, supporting the use of obsession in the generated text. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the editor: 0.9\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: [ ... ] paddled by lavalava clad men , numerous press motorboats , a few Hobies and windsurfers , and one police motorboat accompanied the 40 - foot double - hulled canoe that carried Santos and her attendants , pageant officials , and an \" <define> islandly </define> \" Triton trumpeteer to the coronation site . \n    target text: Like, relating to, or typical of an island; islandy\n    generated text: Of or pertaining to an island.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning of islandly by defining it as Of or pertaining to an island, which aligns with the target texts definition of Like, relating to, or typical of an island; islandy. The input text also provides context about the scene being described, which supports the idea of islandly being related to an island. There are no nonsensical or factually incorrect statements in the generated text, and it does not introduce any additional unsupported information. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Trugge , therefore , ( who has a foul mouth of his own , when he pleases ) talked <define> balderdash </define> to Mrs. Sudberry , through the key - hole , which she did not answer , for , indeed , she seems a civil spoken woman , truly [ ... ] \n    target text: (obsolete) Obscene language or writing.\n    generated text: (archaic, or, dialectal, or, obsolete) Belligerent talk; nonsense.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text contains additional information such as belligerent talk that cannot be supported by the input text or the target text. There is no indication of belligerence in the context provided, and the target text specifically refers to obscene language or writing, which is different from the generated definition. Therefore, the additional information in the generated text makes it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Rosaceae is the 19th largest family and there are about hundred genera which are distributed from cosmopolitan to <define> subcosmopolitan </define> and diversified to northern hemisphere [ 2 ] . \n    target text: (biology, ecology, of a taxon) Not completely cosmopolitan\n    generated text: (ecology) Relating to a subcosmopolitan region.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately reflects the definition of subcosmopolitan as it relates to a region that is not completely cosmopolitan, which aligns with the target texts definition in the context of biology and ecology. The input text also provides the context of the distribution of genera from cosmopolitan to subcosmopolitan, supporting the generated definition. There are no nonsensical or factually incorrect information in the generated text, and it does not contain any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: The pamphlet also makes no mention of the C.T.E. cases , whose increasing number is convincing many experts that <define> subconcussive </define> brain trauma can have cumulative effects . \n    target text: Below the threshold of concussion.\n    generated text: (medicine) Not causing concussions.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning of subconcussive as being below the threshold of concussion, which aligns with the target text Below the threshold of concussion. The definition is supported by the input text that mentions convincing many experts that subconcussive brain trauma can have cumulative effects. The generated text does not contain nonsensical or factually incorrect information, and it does not introduce any additional unsupported details. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: But , as the principal of the loan , or , if you will , the capital lent , is generally consumed in consequence of this transfer , public loans produce an <define> improductive </define> consumption , a destruction of capital . \n    target text: (rare, chiefly, NNSE) .\n    generated text: (economics) Of or pertaining to an increase in the cost of goods and services.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text provides a definition related to the increase in the cost of goods and services, which is not supported by the input text or the target text. The input text and target text do not mention anything about the cost of goods and services, so this additional information is not supported by the given inputs and targets, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: You 're a <define> fad </define> , that means you 're something that we 've already had , but once you 're gone , you do n't come back . \n    target text: A phenomenon that becomes popular for a very short time.\n    generated text: (informal) A fad.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning of the input and target texts without adding any nonsensical or factually incorrect information. It directly reflects the definition provided and aligns with the target text, making it a faithful representation of the given inputs and targets.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Men[dozo ] . How did you kill him ? / Mal[evole ] . <define> Slatted </define> his braines out , then ?ow?t him in the brinie ?ea . / Men . Braind him and drownd him too ? \n    target text: To slap; to strike; to beat; to throw down violently.\n    generated text: (transitive) To strike with a slat.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text To strike with a slat does not align with the input text or the target text, which describe actions of slapping, striking, beating, and throwing down violently. There is no mention of slat in the input or target text, making this additional information unsupported and not in line with the given context. Hence, the generated text is a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: <define> momental </define> ellipsoid \n    target text: (obsolete, engineering) Of or relating to moment or momentum.\n    generated text: (anatomy) Of or pertaining to the mother.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text Of or pertaining to the mother does not align with the input text momental or the target text (obsolete, engineering) Of or relating to moment or momentum. This additional information about the mother cannot be supported by the input or target text, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: The joke was not that funny , but he went into <define> conniptions </define> laughing . \n    target text: A fit of laughing; convulsion.\n    generated text: (informal) A fit of uncontrollable laughter.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text provides a clear and accurate definition that aligns with the target text. It accurately captures the meaning of conniptions as a fit of uncontrollable laughter, which is synonymous with a fit of laughing; convulsion. The input text also supports the idea of uncontrollable laughter, indicating that the person went into conniptions laughing. Therefore, the generated text is not a hallucination as it accurately reflects the meaning in the given context.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: There does seem to have been some mutation among plants [ � ] but in animal life where are the <define> mutants </define> ? When or where has a new species originated in this way ? \n    target text: (genetics) That has mutated, with one or more new characteristics from a mutation.\n    generated text: (biology) An organism that has undergone a mutation.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the essence of the target text by defining mutants as organisms that have undergone a mutation, which aligns with the genetics context. The generated text does not contain any nonsensical or factually incorrect information, and it does not introduce additional unsupported details. Therefore, it closely matches the target text and is consistent with the input text, making it not a hallucination.\nThis is the probability assigned by the editor: 0.9\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Everybody crowded around   very <define> excitedly </define> and talked about the Australian crawl , a stroke I can not do because there is something wrong with my flutter kick . \n    target text: In an excited manner.\n    generated text: In an excited manner.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text matches the target text perfectly without any additional information or nonsensical content. It accurately reflects the input text and stays true to the meaning of excitedly. There is no unsupported information present in the generated text.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: a <define> continuous </define> line of railroad \n    target text: Without intervening space; continued.\n    generated text: Continuing.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text Continuing does not accurately reflect the meaning of continuous as intended in the input text and the target text. The target text Without intervening space; continued suggests a sense of uninterrupted and ongoing, which is not fully captured by Continuing. Additionally, Continuing does not convey the specific idea of something being continued without interruption as specified in the target text. Therefore, the generated text is a hallucination.\nThis is the probability assigned by the editor: 0.9\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: And what difference is there between the credibleness and <define> rationalness </define> of any of these wonders and the credibleness and rationalness of Papal infallibility ? \n    target text: (archaic) The quality or state of being rational.\n    generated text: The quality of being rational.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the essence of the target text, The quality or state of being rational, and does not contain any nonsensical or factually incorrect information. It directly reflects the input texts context and meaning without adding unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: I have spent much of my life a recovering <define> sportaholic </define> . If it bounced , rolled , slid , or flew , I chased it . Or watched it . \n    target text: A sportsaholic.\n    generated text: (informal) A person who is addicted to sport.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately defines sportaholic as a person addicted to sport, which aligns with the input text and the target text. It does not contain any nonsensical or factually incorrect information, and it does not introduce any additional unsupported information. Therefore, it is not hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: If the design of the weapon is moderate enough to be successful as an all wood <define> selfbow </define> then the addition of sinew and horn will probably result in a net loss of arrow performance . \n    target text: (archery) A bow that is made from a single piece of wood (often referred to as a bow stave).\n    generated text: Alternative form of selfbow\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text Alternative form of selfbow does not accurately define selfbow as requested by the input and target texts. It does not provide the specific definition of a selfbow as a bow that is made from a single piece of wood, and instead, it offers a vague and incomplete statement. Therefore, the generated text is a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: I sincerely hope we �re the only research group to lose <define> Malaise traps </define> to fire , hail , and flood in the same season . \n    target text: A large tent-like structure used for trapping flying insects.\n    generated text: (archaeology) A type of trap used in the study of mollusks.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text provides a definition that is completely unrelated to the input text or the target text. It mentions archaeology and mollusks, which have no relevance to the context of the input or the target. Additionally, the generated text does not align with the purpose of a Malaise trap as a large tent-like structure used for trapping flying insects. Therefore, it introduces information that cannot be supported by the input or target texts, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: I thought I had <define> canned </define> it , but it just missed , and I tapped in the second one for a par . \n    target text: (golf, slang, transitive) To hole the ball.\n    generated text: (transitive, golf) To hit (a golf ball) into the hole.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning of canned in the context of golf, which is to hole the ball. It does not contain any nonsensical or factually incorrect information, and it does not introduce any unsupported additional information. Therefore, it aligns with the input text and the target text without any issues.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: He gradually rose in the estimation of the booksellers for whom he <define> drudged </define> . \n    target text: (intransitive) To labour in (or as in) a low servile job.\n    generated text: (intransitive) To work hard.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the essence of the target text by conveying the idea of laboring in a low servile job, which aligns with the input text describing the individual laboring for booksellers. Although the generated text is more general by stating to work hard instead of labour in (or as in) a low servile job, it does not contain any nonsensical or factually incorrect information and does not introduce any unsupported additional information. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.2\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: I prefer this � the pork fat made the sauce a little too oily for absolute comfort , and I am no <define> fatphobe </define> , as you know � and more pointedly so do my children . \n    target text: A person who worries excessively about the fat content of their food.\n    generated text: (informal) A person who is afraid of fat.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text contains additional information that cannot be supported by the input text or the target text. The target text specifies that a fatphobe is a person who worries excessively about the fat content of their food, but the generated text just states that a fatphobe is a person who is afraid of fat without emphasizing the excessive worry about the fat content of their food. Therefore, it adds information that is not supported by the input and target texts, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: to <define> tackify </define> rubber \n    target text: (transitive) To make (a material) tacky.\n    generated text: (transitive) To make tacky.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the transitive action of making a material tacky, as specified in the target text. It does not contain any nonsensical or factually incorrect information, and it does not introduce additional unsupported details. Therefore, it aligns with the input text and the target text without any issues.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: The fact that <define> comp�res </define> routinely wait no more and no less than eight seconds before interrupting means that they decide at just that point that an audience has been clapping long enough , [ ... ] \n    target text: (chiefly, British)\n    generated text: (music) A member of a musical ensemble.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text A member of a musical ensemble does not accurately define the word <define> in the context of the input text, which is about interrupting and clapping. Additionally, the target text specifies (chiefly, British), which is not reflected in the generated text. Therefore, the generated text contains additional information that cannot be supported by the input text or the target text, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: And straightway the minions of the law led forth from their donjon keep one whom the <define> sleuthhounds </define> of justice had apprehended in consequence of information received . \n    target text: (informal) A detective; a sleuth.\n    generated text: (informal) A detective.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the essence of the target text by defining sleuthhounds as detective, which aligns with the informal meaning of the word. The input text provides the context of minions of the law and donjon keep, indicating a legal or law enforcement setting, which supports the concept of sleuthhounds as detectives or sleuths. The generated text doesnt contain any nonsensical or factually incorrect information, and it doesnt introduce any additional unsupported information. Therefore, it is a faithful representation of the target text and not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: A voice came <define> muffledly </define> from inside the closet . \n    target text: In a muffled manner; indistinctly.\n    generated text: In a muffled manner.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning of muffledly as in a muffled manner, which aligns with the target text In a muffled manner; indistinctly. The generated text does not contain any nonsensical or factually incorrect information, and it does not introduce any additional unsupported details. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: To suggest that the term could have come from <define> Anglo - Indian English </define> into British thieves ' ca nt and Chinese Pidgin English while also becoming widely dispersed into British dialect use would be to beg the question . \n    target text: The variety of English used in South Asia during the colonial era, having as a feature numerous borrowings from Hindustani and other local languages.\n    generated text: Alternative form of Anglo-Indian English\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text Alternative form of Anglo-Indian English does not accurately reflect the complexity and historical context of Anglo-Indian English as described in the input text and target text. The input text and target text imply that Anglo-Indian English is a variety of English used in South Asia during the colonial era, heavily influenced by borrowings from Hindustani and other local languages. The generated text oversimplifies this rich linguistic heritage by categorizing it as an alternative form without providing any evidence or support from the input or target text. This oversimplification and lack of supporting information make the generated text a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: � <define> Kurkuls </define> are our enemy , � he shouted , � and we must exterminate them as a social class . There should be no place for the sharks among the harmless fish , � he added . Then he described the kurkuls as an evil tool of capitalists who were preparing an attack on the Soviet Union . \n    target text: (historical) A rich or supposedly rich peasant, targeted during Soviet collectivization, especially in the context of Ukraine or Ukrainians; kulak.\n    generated text: (rare) A kurkul.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text only provides a rephrased version of the input text without adding any new information or context, and it does not align with the target texts specific historical and cultural references related to Soviet collectivization in Ukraine. It lacks the crucial details about the socio-economic context and the specific targeting of rich peasants during that period. As a result, it does not accurately convey the historical and cultural significance of the term kurkul as indicated in the target text.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: In such an India , two things are of utmost priority : land and an heir ( preferably a <define> cisheterosexual </define> , masculine male ) to inherit it . \n    target text: Cisgender and heterosexual.\n    generated text: (of a person) Having a gender identity that matches one's sex assigned at birth.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text contains additional information that cannot be supported by the input text or the target text. The input text only mentions cisheterosexual and masculine male, but the generated text provides a definition related to gender identity and sex assigned at birth, which goes beyond the scope of the input and target text. This additional information constitutes a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Wu Hai , whose objections to contamination of the patrilineal line were cited above , described an <define> ancestral hall </define> ( tz'u - t'ang )   of the Lins of Lo - t'ien ( Hupei ) . \n    target text: An ancestral shrine.\n    generated text: (chiefly, _, historical) An ancestral home.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text chiefly, historical is additional information not supported by the input text or the target text. The term ancestral home is not an accurate synonym for ancestral shrine and introduces ambiguity. Therefore, the generated text is a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: 33 In a historical irony , the Daleks have been taken as metaphors for the Nazis ; the other main <define> Whovian </define> adversaries , the Cybermen , were likewise metaphors for Cold War Communists . \n    target text: Of or pertaining to the fictional universe of Doctor Who.\n    generated text: (fandom slang) Of or pertaining to the television series Doctor Who.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the essence of the target text by defining Whovian as pertaining to the fictional universe of Doctor Who, which aligns with the input text referring to Daleks and Cybermen as adversaries in the context of Doctor Who. The additional information in the generated text, specifically television series, is consistent with the broader context of Doctor Who being a TV series. Therefore, the generated text is not a hallucination as it aligns with the input text and target text without introducing nonsensical or factually incorrect information.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: There 's ferment is Philadelphia where the ad agency with the oldest name in the business after a very bad year is picking itself up and <define> coming out swinging </define> . \n    target text: (idiomatic) To display spunk and strength of character, especially when rising above or when fighting back against trouble or adversity.\n    generated text: (idiomatic, intransitive) To begin a new endeavor with vigor.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the intended meaning of coming out swinging as displaying spunk and strength of character, especially when rising above trouble or adversity. It aligns with the context of the input text, which describes an ad agency picking itself up after a bad year. The generated text does not contain any nonsensical or factually incorrect information, nor does it introduce any unsupported additional information. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: We drove 15 <define> ks </define> before we realised Billy was n't in the back seat . \n    target text: (colloquial) kilometre or kilometres.\n    generated text: (Australia, New Zealand) Initialism of kilometre.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text introduces additional information (such as Initialism of) that is not supported by the input text or the target text. It also fails to provide the colloquial usage of ks as kilometre or kilometres as per the target text, which makes it factually incorrect and nonsensical.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Hey , <define> babe </define> , how 's about you and me getting together ? \n    target text: (affectionate) Darling (term of endearment).\n    generated text: (colloquial) A term of endearment.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning of the term babe as an affectionate term of endearment, which aligns with the target text. It does not contain any nonsensical or factually incorrect information, and it does not introduce any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: [ � ]   the cows , tails <define> aswish </define> , clustering already for milking \n    target text: Swishing, making a rustling sound while moving.\n    generated text: (obsolete) With the tail wagging.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text With the tail wagging does not accurately represent the target text Swishing, making a rustling sound while moving. The generated text introduces information about the tail wagging, which is not supported by the input text or the target text. This additional information makes the generated text a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: But if you 're training like a lot of ' <define> gym bros </define> ' you 'll only be doing sarcoplasmic training . \n    target text: (slang) A man who spends much of his free time working out at a gym.\n    generated text: (informal) A man who works out at a gym.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text is a concise and accurate paraphrase of the target text, capturing the essence of gym bros as men who spend much of their free time working out at a gym. The generated text does not contain any nonsensical or factually incorrect information, and it does not introduce any additional unsupported details. Therefore, it is not hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: In true \" <define> silent service </define> \" tradition , the Royal Canadian Navy says little about itself . \n    target text: (military, informal, sometimes, capitalized, possibly, _, dated) The navy.\n    generated text: (nautical) A service in which the crew of a vessel does not speak.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text provides a definition that is not supported by the input text or the target text. The input and target suggest a military context, but the generated definition refers to nautical operations and the absence of speaking on a vessel, which introduces additional and unrelated information. This discrepancy indicates that the generated text is a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: The femtocaching idea was proposed as a solution to compensate for the weak backhaul capacity , by deploying coverage - limited nodes with high storage capacity called <define> femtocaches </define> ( FCs ) . \n    target text: (computing) The use of femtocaches\n    generated text: (computing) A femtocache.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately reflects the concept of femtocaching as a computing term, which aligns with the input text and target text. There are no nonsensical or factually incorrect information, and the generated text does not contain additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: As Shepheardes curre , that in darke eveninges shade / Hath tracted forth some salvage beastes <define> trade </define> \n    target text: (obsolete) A track or trail; a way; a path; passage.\n    generated text: (obsolete, intransitive) To trade.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text To trade does not align with the input text or the target text, which describe a track or trail, not the act of trading. This additional information cannot be supported by the input or target text, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: The City <define> Chiuchow </define> is Kowloon 's other top restaurant and is famous for its goose dishes and other specialties from the Chiuchow region ( you may also wish to try the beef satay done in a creamy sauce ) . \n    target text: The Chaoshan region where the Teochew dialect is spoken.\n    generated text: A district of Kowloon, China.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text A district of Kowloon, China does not accurately represent the Teochew dialect spoken in the Chaoshan region as mentioned in the target text. Additionally, the generated text introduces information about a district in Kowloon, which is not supported by the input or target text. These inaccuracies and additional unsupported information make the generated text a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: [ � ]   the atmosphere was now animated with the efficient principle of vegetative life ; the <define> arbustive </define> hills , gay lawns , and green meadows   [ � ] \n    target text: containing copses of trees or shrubs; covered with shrubs\n    generated text: (obsolete) Of or pertaining to trees.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text arbustive is defined as (obsolete) Of or pertaining to trees, which does not align with the target text containing copses of trees or shrubs; covered with shrubs. Additionally, the input text does not provide any context or support for the definition provided by the DM system. Therefore, the generated text is a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Noah did n't realize when he stayed on the job - he was then about 600 years old and built the ark and drove the animals in two by two , the <define> hatfish </define> and the kangaroo � � he did n't realize he was laying the foundation for an occupation for old men in New York , several years later . \n    target text: (colloquial) Synonym of halibut\n    generated text: (Australia, New Zealand, colloquial) A hatfish.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text provides a definition for hatfish as A hatfish, which is not supported by the input text or the target text. It does not align with the colloquial synonym of halibut provided in the target text, and it lacks clarity and specificity. There is no indication or context in the input text to support the definition of hatfish as provided in the generated text. Therefore, the generated text is a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: footwear ; outdoor <define> wear </define> ; maternity wear \n    target text: (uncountable) (in combination) clothing\n    generated text: (uncountable) Clothing.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the uncountable nature of clothing and the fact that it can be used in combination with other words, which aligns with the target text. It also maintains a general definition without adding any nonsensical or factually incorrect information. The generated text is consistent with the input and target texts, making it not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Culture was the work of some more or less <define> pithecanthropoid </define> type of hominid ( e.g. Telanthropus ) at a period when the Australopithecines were still flourishing . \n    target text: Pertaining to or characteristic of the pithecanthropoids.\n    generated text: Of or pertaining to pithecanthropes.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning of pithecanthropoid as pertaining to or characteristic of the pithecanthropoids, which aligns with the target text. The generated text does not contain any nonsensical or factually incorrect information, and it does not introduce any unsupported additional information. Therefore, it is not hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: The TV critic had the results of the June rating survey by Arbitron and Nielsen .   [ � ]   He has the hard numbers on the June book plus the recent Nielsen <define> overnights </define> . \n    target text: (television, in the plural) Viewership ratings for a television show that are published the morning after it is broadcast, and may be revised later on.\n    generated text: (television) An overnight broadcast of a television program.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text does not accurately reflect the meaning of overnights in the context of television ratings. It simply defines overnights as a broadcast of a television program, which is factually incorrect and does not align with the target texts definition of overnights as viewership ratings for a television show that are published the morning after it is broadcast. Additionally, the generated text does not include the concept of ratings being published the morning after the broadcast and the possibility of revisions, which are key aspects mentioned in the target text. Therefore, the generated text is a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Local demogerontes of Larnaca , Paphos ( Ktema ) , Limasol and Chrysochou are mentioned in connexion with the massacre of 1821 , as well as a <define> demogeron </define> of the tribunal of Nicosia and two demogerontes of the Saray ( Kepiades , pp . 17 , 19 , 20 ) . \n    target text: Member of a demogerontia.\n    generated text: (historical) A magistrate in Ancient Greece.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately defines demogeron as a member of a demogerontia, which aligns with the input text mentioning demogerontes of different locations. The definition provided by the DM system does not contain any nonsensical or factually incorrect information, nor does it include additional unsupported details. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Sullen , desponding , and <define> foreboding </define> nothing but wars and desolation , as the certain consequence of Caesar 's death . \n    target text: To be prescient of (some ill or misfortune); to have an inward conviction of, as of a calamity which is about to happen; to augur despondingly.\n    generated text: (intransitive) To be foreboding.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning of the target text by defining foreboding as To be prescient of (some ill or misfortune); to have an inward conviction of, as of a calamity which is about to happen; to augur despondingly. The input text also suggests a sense of foreboding. The generated text aligns with both the input and target texts without introducing any nonsensical or unsupported information, making it a valid definition without hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: He moved the boat onward very slowly , <define> lipping </define> the glossy surface delicately with the light oars . \n    target text: (transitive, figurative) (of something inanimate) To touch lightly.\n    generated text: (transitive, nautical) To stroke (a surface) with the oars.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text adds the qualifier nautical and implies the use of oars, which is not supported by the input text or the target text. There is no mention of the activity being nautical or involving oars in the input or target. This additional information constitutes a clear hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: They can be as prone to <define> lipophobia </define> ( the irrational fear of fat ) as the population as a whole . \n    target text: A fear of dietary fat.\n    generated text: The irrational fear of fat.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text provides a concise and accurate definition of lipophobia, aligning with the target text A fear of dietary fat and the input text mentioning the irrational fear of fat. There are no nonsensical or factually incorrect information in the generated text, and it does not contain any additional unsupported information beyond the input and target texts. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Despite the opposition of professional politicians of unsavory reputation and men the Tribune described as � irresponsible <define> soreheads </define> , � the Medill ticket swept into office with a flatteringly large vote . \n    target text: (derogatory, US, political slang) A politician who is dissatisfied through failure, lack of recognition, etc. [from 19th c]\n    generated text: (informal, pejorative) A person who is easily offended.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated definition does not accurately reflect the meaning of soreheads in the context of professional politicians and the political slang usage. It lacks the derogatory and political connotations described in the target text, and instead focuses on a general trait of being easily offended, which is not supported by the input or target texts. This departure from the specific political context and negative connotations makes the generated text a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: a <define> tetaniform </define> spasm \n    target text: Resembling tetanus.\n    generated text: (anatomy) Of, pertaining to, or resembling a tetanus.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning of tetaniform as resembling tetanus and does not contain any nonsensical or factually incorrect information. It also does not introduce any additional unsupported information. Therefore, based on the given inputs and targets, the generated text is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: For all the hype and initial success of devices like the Kindle , they threaten to strip traditional books of much of their <define> transportive </define> appeal . \n    target text: Serving to transport to another place.\n    generated text: Of or pertaining to transport.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text Of or pertaining to transport does not accurately capture the meaning of transportive as serving to transport to another place. It is a significant deviation from the target text and does not effectively convey the intended meaning. Additionally, the generated text introduces a different aspect (pertaining to transport) that is not supported by the input or target text. Therefore, it is a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: They enjoyed a wet summer and a <define> bountiful </define> harvest . \n    target text: Having a quantity or amount that is generous or plentiful; ample.\n    generated text: (figuratively) Full of food; bountiful.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text is a hallucination because it adds information about being full of food which cannot be supported by the input text or the target text. This additional information goes beyond the scope of the original sentence and does not align with the intended meaning of bountiful as used in the context.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: And now she was vppon the <define> weary </define> way , \n    target text: Causing weariness; tiresome.\n    generated text: (obsolete) Worn out; tired.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the essence of weariness by describing something as worn out and tired, which aligns with the meaning of weary. While the word obsolete is not explicitly supported by the input or target text, it does not contradict the given context. Therefore, the generated text is not hallucination.\nThis is the probability assigned by the editor: 0.2\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: It was a concert of some sort . Five or so <define> blokes </define> were on stage in a TV studio ; [ ... ] The blokes did n't look like any pop group as I knew them . They were multiracial , knotted of brow , their garb was distinctive , involving a lot of what I later found out to be cheesecloth and kaftans along with ripped , faded denims . \n    target text: (Britain, informal) A fellow, a man; especially an ordinary man, a man on the street. [From 1847]\n    generated text: (Australia, New Zealand, slang) A man.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the informal nature of the term blokes and its usage to refer to ordinary men. It aligns with the context of the input text and the target text, which both convey the meaning of blokes as referring to men. The generated text does not contain any nonsensical or factually incorrect information, and it does not introduce any additional unsupported details. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.9\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: This chapter has also <define> set the scene </define> by reviewing the operational structure of benchmarking , as well as outlining the research materials central to this study . \n    target text: To prepare for something by providing a background, a description, etc.\n    generated text: (idiomatic) To set the scene.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning of set the scene as preparing for something by providing a background or description, which aligns with the target text and the context of the input. It does not contain any nonsensical or factually incorrect information, nor does it provide additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: When man is <define> unional </define> , the spirit conceives and brings forth strength , the soul listens to wisdom and is led into security , the body has issue in stedfastness and peace . \n    target text: Pertaining to a union.\n    generated text: (rare) Of or pertaining to the unional.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning of unional by defining it as pertaining to a union, which aligns with the target text. The additional information provided in the generated text, (rare) Of or pertaining to the unional, does not contradict the input or target text and provides further context. Therefore, there are no nonsensical or factually incorrect elements in the generated text, and it does not contain any unsupported information. Hence, it is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Kamal moved Fathi's things into his own room , and the two became <define> flatmates </define> . \n    target text: A person with whom one shares a flat.\n    generated text: A person with whom one shares a flat.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately defines the term flatmates as A person with whom one shares a flat, which directly corresponds to the target text. Additionally, the input text provides context by describing Kamal moving Fathis things into his own room, indicating a shared living arrangement. The generated text does not contain any nonsensical or factually incorrect information, nor does it introduce any unsupported additional details. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: \" Hear she 's bangin ' that science teacher . \" \" Elliott ? That needle - dicked little <define> bugfucker </define> ? Nah . \" \n    target text: (vulgar, slang, derogatory, offensive) One who has a very small penis; an inadequate male lover.\n    generated text: (vulgar, slang, derogatory) A contemptible person.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text A contemptible person does not accurately capture the meaning provided in the target text, which describes a specific derogatory term related to male anatomy. The generated text lacks the crucial aspect of having a very small penis and an inadequate male lover, which are essential components of the target definition. Additionally, the input text does not provide sufficient context for the generated definition, leading to an unsupported and unrelated interpretation. Therefore, the generated text is a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: No one , however , would have anything to do with him , as Mr. Keeson 's orders in those respects were very strict   ; he had often threatened any one of his employ�s with <define> instant </define> dismissal if he found him in company with one of these touts . \n    target text: Occurring immediately; immediate; present.\n    generated text: Immediately; without delay.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text Immediately; without delay accurately captures the meaning of the target text Occurring immediately; immediate; present without adding any nonsensical or factually incorrect information. It stays faithful to the input text by reflecting the urgency and strictness in Mr. Keesons orders. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the editor: 0.95\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: <define> umbery </define> gold \n    target text: Of or pertaining to umber; like umber.\n    generated text: Resembling or characteristic of umber.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning of the input and target texts, using synonymous language and conveying the same concept without adding any nonsensical or factually incorrect information. It stays true to the context and meaning provided by the input and target texts.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: ... and that the court was \" therefore unimpressed by Mr Gill 's assertion that incidents of this kind are deviant behaviour and an aberration on the part of individual members of the force . \" But there was more to <define> unimpress </define> the Supreme Court . \n    target text: Too fail to impress positively; to leave very little impression or a bad impression;\n    generated text: (transitive) To fail to impress.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the essence of the target text by stating that unimpress means to fail to impress, which aligns with the idea of leaving very little impression or a bad impression. The input text also supports this by mentioning that the court was unimpressed by Mr. Gills assertion. There are no nonsensical or factually incorrect information in the generated text, and it does not contain any additional unsupported information. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the editor: 0.9\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: A central kitchen serves a <define> cafeterie </define> , seating two hundred ; a caf� , seating seventy ; and a lunch counter with stools for forty . \n    target text: (dated) Cafeteria.\n    generated text: (countable) A caf�.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text only provides a general definition of caf� without specifying that it is a cafeteria, which is the actual meaning of the term in the given context. It does not align with the specific context of the central kitchen serving a cafeterie, a caf�, and a lunch counter mentioned in the input text. Therefore, the generated text contains additional information that cannot be supported by the input text or the target text, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: The country �s � self - serving and bogus view of history , � which pities the rest of the world for its disorder , hides what he sees as � the lumpen and <define> louty </define> , coarse , unsubtle , beady - eyed , beefy - bummed herd of England . � \n    target text: (rare) loutish\n    generated text: (informal) Loutish.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text loutish is a rare synonym for louty and aligns with the context of the input text, which describes England as a herd of coarse and unsubtle individuals. The generated text does not contain any nonsensical or factually incorrect information, and it does not add any unsupported information beyond the input text or the target text. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.9\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: <define> pervert </define> one 's words \n    target text: to misinterpret designedly.\n    generated text: (transitive, obsolete) To corrupt; to pervert.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text directly aligns with the input and target texts, providing a concise and accurate definition without any nonsensical or factually incorrect information. It does not contain any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: The pandemic is also weighing on preparations , with election administrations hyperaware that Covid cases could <define> throw a wrench in </define> their plans at the last minute . \n    target text: (idiomatic, US) To introduce a problem, dilemma or obstacle in; to complicate.\n    generated text: (idiomatic, transitive) To throw a wrench in.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning of the idiom throw a wrench in as defined in the target text. It does not contain any nonsensical or factually incorrect information, and it does not introduce any additional unsupported information. The generated text aligns with the input text and the target text without any issues, hence it is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: The Great Russians ought to be carefully distinguished from � the Malo - Russians � or the � Little Russians . � The inhabitants of the Ukraine , or of the governments Tchernigof , Poltava , Kharkof , call the great Russians or the Muscovites � kazaps , goats , � from their wearing beards , and are in their turn termed by the Great Russians <define> khokhols </define> , � hair tufts , � which they themselves call tchub , tchupran , a tuft of the same kind as that which the Chinese wear on the top of the head ; this is an old Slavonian custom , as appears from history , which mentions such a one being worn by the Russian Prince Sviatoslav , when carrying on war in Bulgaria . \n    target text: (pejorative, in a Russian context) A Ukrainian.\n    generated text: (archaic) A tuft of hair on the top of the head.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text provides a historical context and explanation for the term khokhols which aligns with the input text describing the term as hair tufts and the historical reference to the Russian Prince Sviatoslav. It does not contain any nonsensical or factually incorrect information, and it does not introduce additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: <define> keen </define> satire or sarcasm \n    target text: Acrimonious, bitter, piercing.\n    generated text: Having a keen sense of humor.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text Having a keen sense of humor does not accurately reflect the input text keen satire or sarcasm or the target text Acrimonious, bitter, piercing. It adds information about humor which is not supported by the input or target text, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: The belfry , which rises from the eastern gable of the nave , is peculiarly unsuited to its style and position , being of that combination of <define> bellcot </define> ( for three bells in two stories ) and little spire , which is only tolerable at the west end of a small First or early Middle - Pointed building , but is totally inadequate for the place which it is made to occupy in the present design . \n    target text: Alternative form of bell cot\n    generated text: (architecture) A belfry.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately defines bellcot as an alternative form of belfry, which aligns with the architectural context of the input text. It does not contain any additional unsupported information and accurately captures the essence of the target text.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: 2 <define> balikbayans </define> kidnapped in Zamboanga City . \n    target text: (Philippines) A Filipino returning to the Philippines after spending time in another country. [from 20th c.]\n    generated text: (Philippines) A member of the Balikbayan.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text incorrectly defines balikbayans as a member of the Balikbayan, which is factually incorrect and does not accurately reflect the meaning provided in the target text. Furthermore, the generated text lacks the context of a Filipino returning to the Philippines after spending time in another country, as mentioned in the target text. Therefore, the generated text is a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Forbid it , O my God , that ever I should be so unhappy as to <define> unglorify </define> my Father , my Saviour , or my Sanctifier \n    target text: (transitive) To deprive of glory.\n    generated text: (transitive) To make less glorious.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning of unglorify as to make less glorious which aligns with the target text to deprive of glory. The generated text does not contain any nonsensical or factually incorrect information, and it does not introduce any additional unsupported information. Therefore, based on the given inputs and targets, the generated text is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: a <define> sandyish </define> soil \n    target text: Somewhat sandy.\n    generated text: Somewhat sandy.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning of sandyish by using the word sandy and adding the qualifier somewhat, which aligns with the target text as well. There are no nonsensical or factually incorrect information present, and the generated text does not contain any additional unsupported information. Therefore, it is not hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Then I began to <define> unclimb </define> the Rocky Mountains . \n    target text: (transitive) To undo the climbing of; to climb down or back from.\n    generated text: (transitive) To climb again.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text To climb again does not accurately capture the meaning of unclimb as to undo the climbing of; to climb down or back from in the target text. It introduces additional information that is not supported by the input text or the target text, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Are you going to any <define> outfires </define> this year ? Yes , Barcombe and Glynde I think . \n    target text: (Sussex) A visit by one bonfire society to join in with the celebrations of another.\n    generated text: Alternative form of outfire\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text does not accurately define outfires based on the input text and the target text. It only provides an alternative form without explaining the meaning or context, which does not align with the target definition. Additionally, the generated text does not reflect the specific context of bonfire societies and their celebrations, as described in the target text. Therefore, the generated text is not supported by the input or target text, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Let 's face it , they 're there for a good stroll on a Sunday afternoon when it 's <define> pissing </define>   outside . \n    target text: (ambitransitive, mildly, _, vulgar) To rain heavily.\n    generated text: (intransitive, colloquial) To be very hot.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated definition To be very hot does not align with the target text (ambitransitive, mildly, _, vulgar) To rain heavily or the input text about a good stroll on a Sunday afternoon when it s pissing outside. There is no support for the meaning To be very hot in the input or target text. Therefore, it contains additional information that cannot be supported by the input text or the target text, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: When the surfer has passed the point where the waves are breaking , and is among the waves which are known as � <define> greenbacks </define> � , he may either dive through them or float over them ,   [ � ] \n    target text: (surfing) A wave that has not yet begun to break.\n    generated text: (surfing, slang) A large wave.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text inaccurately defines greenbacks as a large wave, which contradicts the target text defining it as a wave that has not yet begun to break. Additionally, the input text does not provide any support for the definition of greenbacks as a large wave, making it an unsupported addition. Therefore, the generated text is a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: Just as there are <define> all - cargo </define> aircraft , there are all - cargo airports . \n    target text: that only carries cargo, and no passengers\n    generated text: Alternative form of all-cargo\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text Alternative form of all-cargo does not accurately reflect the meaning of the input and target texts. It fails to convey the specific meaning of all-cargo as that only carries cargo, and no passengers as indicated in the target text. Additionally, the generated text introduces the concept of an alternative form which is not supported by the input or target texts. Therefore, it contains additional information that cannot be supported by the input text or the target text, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: He gave an <define> inconsistent </define> account of the evening , saying he called her before eight , but later that he had not talked to her until after nine . \n    target text: Lacking internal consistency; self-contradicting; not compatible with itself.\n    generated text: Not consistent.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the essence of the target text by conveying the idea of lacking consistency and self-contradiction. It does not contain any nonsensical or factually incorrect information, and it does not introduce any additional unsupported details. The generated text directly corresponds to the input and target texts, making it a faithful representation without any hallucinations.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated definitions by a definition modeling (DM) system for the words in <>. You are given three inputs: \n    input text: The factor invoked by Kalecki to rationalize the phenomenon , however , <define> appropinquates </define> Sraffa 's observations on capital markets . \n    target text: (rare, literary, ambitransitive) To approach; to near.\n    generated text: (transitive) To agree with; to concur with.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text To agree with; to concur with does not align with the target text To approach; to near and introduces an entirely different meaning unrelated to the input text. There is no support in the input or target text for the generated definition, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: I haven't been contacted by anybody. \n    target text: Nobody's contacted me.\n    generated text: I have not been contacted.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately conveys the same meaning as the target text by expressing that the speaker has not been contacted by anyone. It does not contain any nonsensical or factually incorrect information, and it does not introduce any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: I thought so, too. \n    target text: That was my general impression as well.\n    generated text: I thought you'd be surprised at me too.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text contains additional information that cannot be supported by the input text or the target text. It also changes the meaning of the original statement completely.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Is she gonna be okay? \n    target text: She be all right?\n    generated text: Is she gonna be okay?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text is not hallucination because it exactly matches the input text and is very close to the target text. There is no nonsensical or factually incorrect information, and no additional unsupported information is present in the generated text.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: How long before you make that happen? \n    target text: How long will it take?\n    generated text: How long before you're making that happen?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text closely mirrors the target text by asking about the time it will take for something to happen, which aligns with the input texts inquiry. Although there is a slight change in phrasing with before youre making instead of before you make, the overall meaning remains consistent. The generated text does not introduce any nonsensical or factually incorrect information and does not contain any additional unsupported details. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: You've got a client. \n    target text: You got a customer.\n    generated text: You've got a customer.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text closely matches the target text and is a valid paraphrase of the input text. There are no nonsensical or factually incorrect information in the generated text, and it does not contain any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Have you seen Norman? \n    target text: You seen, uh, Norman?\n    generated text: Have you seen Norman in the last two days, or what?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text contains additional information that cannot be supported by the input text or the target text, as it introduces a time frame (in the last two days) that was not present in the original conversation. This additional information is not supported by the input or target text, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Eddie, please, give me the gun. \n    target text: Eddie, please, just... just give me the gun.\n    generated text: Eddie, I'm begging you, I'm gonna need you to give me the gun.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text closely follows the request in the input text and the target text, asking Eddie to give the gun. It doesnt introduce any nonsensical or factually incorrect information and doesnt contain additional unsupported information. Therefore, it aligns with the meaning and intent of the input and target texts, making it not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Are we resolved? \n    target text: Do we have a deal?\n    generated text: So, what, we're in the clear now?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text So, what, were in the clear now? does not accurately represent the meaning of the input text Are we resolved? or the target text Do we have a deal?. It introduces new information that is not supported by the input or target text, and it deviates significantly from the original intent. Therefore, it is a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Have you practiced? \n    target text: You been practicing?\n    generated text: You been practicing yet?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text You been practicing yet? is not a hallucination because it maintains the core meaning and intent of the input text Have you practiced? and the target text You been practicing? while adding a simple question word yet for emphasis. This addition does not change the overall meaning or introduce any nonsensical or factually incorrect information. Therefore, it does not qualify as a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Do you recognize anyone? \n    target text: Recognize anybody in there?\n    generated text: Do you recognize any of them?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text is not factually incorrect or nonsensical, and it closely matches the target text with minor variations. There are no additional unsupported details in the generated text. It stays within the context of the input and target text.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: This is going to end up bad. \n    target text: This is not gonna end well.\n    generated text: This ain't going to end up too good.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the negative outcome indicated in the input and target texts, without introducing any nonsensical or factually incorrect information or adding any unsupported details. The paraphrased text aligns with the overall sentiment and meaning of the original and target texts.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: We've got to be quick. \n    target text: We need to be fast.\n    generated text: We've got to be a little bit fast.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text Weve got to be a little bit fast retains the meaning of the target text We need to be fast while incorporating a slight emphasis on speed, which does not deviate from the original intent. It does not introduce any nonsensical or factually incorrect information, nor does it include any additional unsupported information. Therefore, it aligns with the input text Weve got to be quick and the target text without introducing any hallucinations.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: We've been watching you. \n    target text: We've had our eye on you.\n    generated text: I'm sorry, but we've been watching you for a couple of hours.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text contains additional information (for a couple of hours) that cannot be supported by the input text or the target text, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: I shall love you always. \n    target text: I will love you forever.\n    generated text: I'll love you forever and ever.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text Ill love you forever and ever is a slightly modified version of the target text I will love you forever. It does not contain any nonsensical or factually incorrect information, and it does not introduce any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: I'll take good care of you. \n    target text: I'm gonna look after you.\n    generated text: I'm going to take a good care of you now.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text closely captures the meaning and intention of the target text while adding a few extra words for emphasis. It does not contain any nonsensical or factually incorrect information, and the additional words do not significantly change the meaning or introduce unsupported information. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the editor: 0.2\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Where did everybody go? \n    target text: Where have they all gone?\n    generated text: Where'd all the kids go to?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text maintains the core meaning of the input and target text, expressing the same idea of people disappearing. It does not contain any nonsensical or factually incorrect information, and it does not introduce any additional unsupported details. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: He did not pull through. \n    target text: He didn't make it.\n    generated text: He didn't make it through.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text He didnt make it through stays true to the meaning of the input text He did not pull through and the target text He didnt make it. It does not introduce any nonsensical or factually incorrect information and does not contain additional unsupported details. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Leave the talking to me. \n    target text: Let me do all the talking.\n    generated text: You're gonna leave the talking to me alone.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the essence of the target text by expressing the same idea in slightly different words. While it includes an additional word alone, it does not change the meaning of the original sentence. Therefore, it does not contain any nonsensical or factually incorrect information, and the additional word does not significantly alter the original meaning. Hence, the generated text is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: I didn't kill her. \n    target text: I wasn't the one who killed her.\n    generated text: I'm telling you, I didn't kill her, that's all.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately conveys the denial of responsibility for the killing, which is consistent with both the input text and the target text. It doesnt introduce any new or unsupported information. The only addition is the phrase Im telling you, which doesnt change the meaning or introduce any new information. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: I cannot let that happen. \n    target text: This I cannot allow.\n    generated text: I can't allow that.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text I cant allow that accurately conveys the meaning of the target text This I cannot allow without introducing any nonsensical or factually incorrect information. It stays true to the original sentiment and does not add any unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: I'm just not coming. \n    target text: I'm not gonna go.\n    generated text: I'm just, uh, I'm not coming in.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text closely matches the target text in terms of meaning and intent. It maintains the negation and the decision not to go, which aligns with the input and target texts. There are no nonsensical or factually incorrect information, and no additional unsupported information is present. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: How long you've been back? \n    target text: When did you get back?\n    generated text: How long's you been back in town?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text contains additional information that cannot be supported by the input text or the target text, as it introduces the location in town which is not present in the original input or target text. This additional information constitutes a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: We'll leave you with that. \n    target text: You can keep it.\n    generated text: We'll leave you with that.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text closely matches the target text and does not contain any additional information or nonsensical content. It accurately reflects the idea of leaving something behind, as indicated in the input text and the target text. Therefore, it is not hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: How was the trip in? \n    target text: How was your journey?\n    generated text: So how'd the trip get in?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text maintains the general meaning and intent of the target text by asking about the journey, which aligns with the input text. Although there are slight differences in phrasing, the core message remains consistent. There are no nonsensical or factually incorrect information in the generated text, and it does not introduce any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.9\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: How long have you known? \n    target text: How long you known that?\n    generated text: How long have you known this?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text is a direct and accurate paraphrase of the target text and does not introduce any nonsensical or factually incorrect information. It stays true to the original meaning and does not add any unsupported details. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Leave your message after the beep. \n    target text: Please leave a message at the sound of the tone.\n    generated text: You'll leave your message after the beep, and you'll be on your way.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text contains additional information that cannot be supported by the input text or the target text, as it introduces the concept of being on your way which is not present in the original message or the target text. This additional information is not supported by the given inputs and targets, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: No way is this happening. \n    target text: This can't happen.\n    generated text: There's no way this is going to happen.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the essence of the target text by conveying the same idea that something is not going to happen. It does not contain any nonsensical or factually incorrect information, nor does it introduce any additional unsupported information. Therefore, it aligns with the input text and the target text, making it not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: I don't question that. \n    target text: I have no doubt.\n    generated text: I do not question that.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning of the target text while maintaining the same sentiment and context as the input text. It does not introduce any nonsensical or factually incorrect information, nor does it contain any additional unsupported information. Therefore, it aligns with the original meaning and does not qualify as a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: I'm not gonna leave you. \n    target text: I will not leave you behind.\n    generated text: I'm not leaving you behind.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text maintains the core meaning of the target text and does not introduce any nonsensical or factually incorrect information. It simply rephrases the original statement in a slightly different way. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: I am penniless. \n    target text: I don't have any money.\n    generated text: I don't know what I'm going to do.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text I dont know what Im going to do does not contain any nonsensical or factually incorrect information, and it does not introduce any additional unsupported information compared to the input text I am penniless and the target text I dont have any money. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: There's got to be a different way. \n    target text: There has to be another way.\n    generated text: There's got to be a different way out.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text is not hallucination because it stays true to the meaning of the input and target texts without introducing nonsensical or factually incorrect information. It simply adds a clarifying detail that does not contradict the original meaning.\nThis is the probability assigned by the editor: 0.2\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: That's what he said. \n    target text: Yeah, he said that.\n    generated text: That's what he's saying.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text Thats what hes saying is a close paraphrase of the input text Thats what he said and aligns with the target text Yeah, he said that. There is no nonsensical or factually incorrect information in the generated text, and it does not contain any additional unsupported information. Therefore, based on the given inputs and targets, the generated text is a faithful paraphrase and not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Look closely at it. \n    target text: Take a good look.\n    generated text: Take a close look at it.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text Take a close look at it is not a hallucination because it captures the essence and meaning of the target text Take a good look while adding a slight emphasis on proximity. The additional phrase at it does not introduce any nonsensical or factually incorrect information, nor does it deviate from the meaning of the input and target texts. Therefore, the generated text is consistent with the given inputs and targets without introducing hallucinated information.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Do appreciate your time. \n    target text: Well, thank you for your time.\n    generated text: You're very kind of your time.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text Youre very kind of your time does not accurately convey the meaning of the input text Do appreciate your time or the target text Well, thank you for your time. It not only fails to express gratitude, but also introduces nonsensical language that is not supported by the original context. Therefore, it is a clear case of hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Have a nice time. \n    target text: Well, you enjoy yourself.\n    generated text: You're gonna be a good cop.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text Youre gonna be a good cop is not only factually incorrect and nonsensical in the context of the input text Have a nice time and the target text Well, you enjoy yourself, but it also contains additional information that cannot be supported by the input or target text. There is no connection or relevance between the input, target, and the generated text, making it a clear case of hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Thank you - for everything. \n    target text: Thank you for all of this.\n    generated text: Thank you, thank you for everything.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text closely follows the input text and the target text, with the only addition being a repetition of the phrase thank you. There are no nonsensical or factually incorrect information in the generated text, and the additional repetition does not introduce any unsupported information. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Still not too late. \n    target text: There's still time.\n    generated text: I'm gonna be there for a few days.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text Im gonna be there for a few days does not relate to the input text Still not too late or the target text Theres still time. It introduces new information that is not supported by the input or target text, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Do you want something to drink? \n    target text: So, you want a drink or something?\n    generated text: Hey, do you want to get something to drink, by the way?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text closely captures the meaning and intent of the target text while adding a casual phrase at the beginning. It does not introduce any nonsensical or factually incorrect information, nor does it contain any additional unsupported information. Therefore, it aligns with the input and target texts without any hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: I've been busy. \n    target text: I had something to do.\n    generated text: I've been kind of on my mind.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text Ive been kind of on my mind does not accurately represent the meaning of the input text Ive been busy or the target text I had something to do. It introduces new information that is not supported by the input or target text, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: What's your solution? \n    target text: What are you proposing?\n    generated text: What is your solution?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text is a simple rephrasing of the input text and closely matches the target text without adding any nonsensical or factually incorrect information. It stays true to the original question and the expected response, hence it is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: I'm ordering it. \n    target text: That is an order.\n    generated text: I'll order it.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text Ill order it is a valid and natural paraphrase of the input text Im ordering it and the target text That is an order. There are no nonsensical or factually incorrect information in the generated text, and it does not contain any additional unsupported information compared to the input and target texts. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Hey, that's not your concern. \n    target text: It's really none of your business.\n    generated text: Hey, that's not your concern, that's all I can say.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text simply adds a phrase thats all I can say to the original input, without introducing any nonsensical or factually incorrect information. It does not contain any additional unsupported information beyond the input and the target text. Therefore, it does not meet the criteria for hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Talk to you later, pal. \n    target text: We'll talk later.\n    generated text: I'll talk to you later, okay, man?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text closely captures the essence of the target text by expressing the intention to talk later, which aligns with the input text Talk to you later, pal. Although it includes additional words like okay and man, they do not significantly alter the meaning or introduce nonsensical information. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the editor: 0.2\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Guilty as charged. \n    target text: It was a guilty verdict.\n    generated text: Guilty as charged, Mr. Reese.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text Guilty as charged, Mr. Reese. contains additional information (Mr. Reese) that cannot be supported by the input text Guilty as charged. or the target text It was a guilty verdict. This additional information is not present in the input or target, making it a clear case of hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: No other way around it. \n    target text: There's no other way.\n    generated text: There's no other way around it.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text is not hallucination because it directly aligns with the input text and the target text. The only difference between the generated text and the target text is the addition of the phrase around it, which does not introduce any nonsensical or factually incorrect information. It simply adds a spatial context to the statement. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: This'll only take a second. \n    target text: This won't take long.\n    generated text: This won't take more than a second, okay?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning and intent of the input and target texts without adding any nonsensical or factually incorrect information. It stays true to the original message and does not introduce any unsupported details. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: It is no concern of yours. \n    target text: That's not your concern.\n    generated text: It's none of your business, my friend.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately conveys the same message as the target text while using different wording. It does not introduce any nonsensical or factually incorrect information, nor does it contain any additional information that is not supported by the input and target texts. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: I'll be seeing you soon. \n    target text: See you in a little bit.\n    generated text: I'll see you soon, all right?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text maintains the core meaning of the input and the target text, expressing the intention of meeting soon. There are no nonsensical or factually incorrect information in the generated text, and it does not contain any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: It's none of your business. \n    target text: It's not your affair.\n    generated text: I-I-I don't have to do this.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text I-I-I dont have to do this does not accurately reflect the input text Its none of your business or the target text Its not your affair. There is a clear deviation in meaning and tone, and the generated text introduces additional information not present in the input or target text. Therefore, it is a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: I'll give it a shot. \n    target text: Sure gonna try.\n    generated text: I'll test it.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text Ill test it is a valid alternative for Ill give it a shot and Sure gonna try as it conveys the same meaning of trying something. There is no nonsensical or factually incorrect information and no additional unsupported information in the generated text. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Um, I need you to leave. \n    target text: You have to go.\n    generated text: I need you to leave now.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text I need you to leave now is a natural and reasonable expansion of the target text You have to go without adding any nonsensical or factually incorrect information. The addition of now is a minor detail that does not significantly alter the meaning or introduce new unsupported information. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Would you care to join? \n    target text: You want to come with me?\n    generated text: Would you like to come with me for a moment?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text stays true to the intent of the input and target texts by inviting someone to come along, maintaining the core meaning without adding nonsensical or factually incorrect information. The addition of for a moment does not significantly alter the meaning or introduce new unsupported information. Therefore, it does not qualify as a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: How come you're asking? \n    target text: Why would you ask me that?\n    generated text: How come you're asking me to do this?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text closely follows the structure and meaning of the target text, Why would you ask me that? while incorporating some elements from the input text, How come youre asking? The addition of me to do this does not introduce nonsensical or factually incorrect information, and it does not contain any additional unsupported information. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Now, what gives you that idea? \n    target text: What makes you think that?\n    generated text: What makes you think that?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text is not hallucination because it is identical to the target text and does not contain any nonsensical or factually incorrect information. It does not introduce any additional unsupported information. Therefore, it aligns with the input and target texts.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: I do see your point. \n    target text: I know what you mean.\n    generated text: I do see what you mean.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately reflects the meaning of the target text and does not introduce any nonsensical or factually incorrect information. It maintains the essence of the original statement and aligns with the intended message. There is no additional unsupported information in the generated text compared to the input and target texts.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: This going somewhere? \n    target text: What's your point?\n    generated text: You're going somewhere else?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text closely reflects the target text Whats your point? by expressing a similar sentiment and questioning the purpose, without introducing nonsensical or factually incorrect information. While it does contain additional information, it is supported by the context and does not deviate significantly from the input and target texts.\nThis is the probability assigned by the editor: 0.2\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: You're not done yet. \n    target text: You haven't finished yet\n    generated text: You're not finished yet.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text Youre not finished yet accurately captures the meaning and intent of the target text You havent finished yet while staying true to the input text Youre not done yet. The generated text does not introduce any nonsensical or factually incorrect information, nor does it contain any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Because you're a scientist. \n    target text: You are a man of science.\n    generated text: That's because you're a science officer.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text contains additional information that cannot be supported by the input text or the target text. The input text Because youre a scientist does not support the claim of being a science officer, and the target text You are a man of science does not mention anything about being a science officer. Therefore, the generated text contains additional unsupported information, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Let's go through this again. \n    target text: Okay, let's run through it one more time.\n    generated text: All right, let's go over this one again, and we'll be back in business.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the main idea of going through something again, which is consistent with the input text and the target text. It does not contain any nonsensical or factually incorrect information, and it does not introduce any additional unsupported information. Therefore, it aligns closely with the meaning and intent of the input and target texts, making it not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Do you have a suspect? \n    target text: Have you identified a suspect?\n    generated text: Do you have a suspect in the murders?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text stays closely within the scope of the input and target texts, maintaining the focus on the existence of a suspect. It does not introduce any nonsensical or factually incorrect information, nor does it include any additional unsupported details. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: I beg to differ. \n    target text: I can't agree.\n    generated text: I'm not in the same position.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning of the target text by expressing a different perspective, without introducing any nonsensical or factually incorrect information. It does not contain any additional unsupported information beyond the input and target texts. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: She's been sleeping with my boss. \n    target text: She slept with my boss, so.\n    generated text: She's been sleeping with my boss for a few days.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text introduces new information about the duration of the affair (for a few days) that is not present in the input or target text. This additional detail cannot be supported by the given inputs and targets, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: I have made an improvement. \n    target text: I made it better.\n    generated text: I've done better.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text Ive done better is a close paraphrase of the target text I made it better and does not contain any nonsensical or factually incorrect information. The generated text does not introduce any additional information that cannot be supported by the input text or the target text. Therefore, it is not hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Don't call me pudding. \n    target text: Don't you pudding me.\n    generated text: Don't call me a poodle.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text Dont call me a poodle contains additional information that cannot be supported by the input text Dont call me pudding or the target text Dont you pudding me. There is no logical connection between pudding and poodle, and the addition of a in the generated text introduces new information not present in the input or target text. Therefore, the generated text is a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Can you identify him? \n    target text: You think you could ID him?\n    generated text: Do you have any way of ID'ing the man's body?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text introduces new information about the mans body, which is not present in the input text or the target text. It also deviates significantly from the original meaning by focusing on the mans body instead of identifying the person. Therefore, it is a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: This is an essential service route. \n    target text: This route is for essential traffic only.\n    generated text: This is a very important, very important service route, Mr. President.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text contains additional information that cannot be supported by the input text or the target text, and it is factually incorrect. It introduces the mention of Mr. President which is not present in the input or target text, and it does not accurately convey the essential traffic restriction mentioned in the target text. Therefore, the generated text is a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Then why'd they send him to prison? \n    target text: Then why did he go to jail?\n    generated text: Then why did they send him to jail?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text closely follows the structure and meaning of the target text while maintaining the core information from the input text. It does not introduce any nonsensical or factually incorrect information, nor does it contain any additional unsupported details. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Seventy - five a month. \n    target text: Seventy-five dollars a month.\n    generated text: Seventy-one-five-a-month-old, man.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text Seventy-one-five-a-month-old, man contains nonsensical and factually incorrect information that is not supported by the input text Seventy - five a month and the target text Seventy-five dollars a month. Additionally, it introduces irrelevant and unsupported information (old, man) that does not align with the original context. Therefore, it is a clear case of hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Rick, what do you want? \n    target text: What do you need, Rick?\n    generated text: Rick, what do you want from me?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text stays true to the context and meaning of the input and target texts without introducing nonsensical or factually incorrect information. It simply adds from me which does not alter the overall meaning or introduce unsupported information. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Do you think I'm a monster? \n    target text: You think I'm some kind of a monster?\n    generated text: What do you think I'm, like, a monster, like, \"A monster\"?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning and sentiment of the input and target texts. It rearranges the words and adds some filler words, but it does not introduce any nonsensical or factually incorrect information. The question asked in the generated text aligns with the original question in the input text and the target texts assertion, making it a reasonable paraphrase. The additional like and A monster do not change the overall meaning or introduce new information, as they serve as filler words and emphasis. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: I'll get you somewhere safe. \n    target text: I'll take you to safety.\n    generated text: I'm going to get you someplace safe, okay?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text maintains the core meaning and intent of the input and target texts. It expresses the idea of taking someone to safety, which is consistent with the original message. Although it adds someplace and okay for clarification and reassurance, these additions do not change the main message or introduce any nonsensical or factually incorrect information. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Haven't you got anything better to do? \n    target text: You have nothing else better to do with your time?\n    generated text: You don't have anything better to do, or you don't know what else to do?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text captures the meaning of the input and target texts accurately without adding any nonsensical or factually incorrect information. It stays true to the intent and content of the original sentence while rephrasing it slightly differently. There are no unsupported or additional details that deviate from the original context.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Missile still closing distance and tracking steady. \n    target text: Missile still tracking steady and closing distance.\n    generated text: Missile still closing distance and tracking steady as we can see.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text introduces additional information that is not present in the input text or the target text, implying a different order of events compared to the target text. Also, the phrase as we can see is not supported by the original input or the target text, making it factually incorrect.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: They don't have to die. \n    target text: We can save them.\n    generated text: They don't have to.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text They dont have to is a hallucination because it deviates significantly from the target text We can save them. The generated text lacks the crucial information about saving them, which is present in the target text. Thus, it introduces a different concept and fails to maintain the core meaning of the target text. This deviation indicates that the generated text is not a faithful representation of the target text and introduces unsupported information, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: And he sometimes watches Oliver. \n    target text: He occasionally watches Oliver, sometimes.\n    generated text: And he watches Oliver all the time.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text And he watches Oliver all the time not only deviates from the original input and target text, but it also introduces a completely different frequency of the action, which cannot be supported by the given inputs and targets. This introduces nonsensical and factually incorrect information, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: I wanted to be good. \n    target text: I was just being kind.\n    generated text: I'd like to be good.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text closely captures the intent and meaning of the target text by expressing a desire to be good, which aligns with the notion of being kind. It does not introduce any nonsensical or factually incorrect information, nor does it contain additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: How come you didn't call me back? \n    target text: Why didn't you return my calls?\n    generated text: How come you didn't call me back, you're a cop?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text introduces new information (the person being a cop) that is not supported by the input text or the target text. This additional information is not present in the original conversation and is therefore a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: I couId've predicted this. \n    target text: This is predictable.\n    generated text: I could've predicted this one.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text I couldve predicted this one is not hallucination because it closely aligns with the input text I couldve predicted this and the target text This is predictable. The addition of one does not introduce nonsensical or factually incorrect information and does not provide any additional unsupported information. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: You look worried. \n    target text: You seem distraught.\n    generated text: You look unsettled.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text You look unsettled is a valid interpretation of the input text You look worried and the target text You seem distraught. The word unsettled conveys a similar meaning to worried and distraught, indicating a state of unease or concern. There are no nonsensical or factually incorrect statements in the generated text, and it does not contain any additional unsupported information. Therefore, based on the given inputs and targets, the generated text is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: I think I'm going to need it. \n    target text: I think I may have need of it.\n    generated text: I think I'm going to be the one who's going to need it.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text contains additional information (Im going to be the one whos going to) that cannot be supported by the input text or the target text. This goes beyond the original intention expressed in the input and target texts, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: I didn't sign up for this. \n    target text: That's not the job I signed on for.\n    generated text: I didn't sign up for this, and I didn't want to be in the car.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text contains additional information (and I didnt want to be in the car) that cannot be supported by the input text or the target text. This extra information goes beyond the scope of the original statement and introduces a new context, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: I'll see you in a couple of days. \n    target text: You, I'll see you in a few days.\n    generated text: I'll see you in a couple of days, if you're going to be able to get a drink.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text introduces new information about getting a drink, which is not supported by the input text or the target text. This additional information is nonsensical and not relevant to the original context. Therefore, it is a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: I'm good at keeping secrets. \n    target text: I am great with secrets.\n    generated text: I'm a very good at keeping a secret.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text maintains the core meaning of the input and target texts without adding nonsensical or factually incorrect information. It simply adds emphasis to the proficiency in keeping secrets, which is supported by the input and target texts.\nThis is the probability assigned by the editor: 0.2\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Something's not right. \n    target text: There's something's wrong here.\n    generated text: There's something wrong with me, man.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text Theres something wrong with me, man does not contain any nonsensical or factually incorrect information, and it is closely related to the target text Theres somethings wrong here. Although it introduces a slight deviation by adding with me, man, this addition does not significantly change the meaning or introduce any unsupported information. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the editor: 0.2\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Tell me what the problem is. \n    target text: What seems to be the problem?\n    generated text: Tell me what the problem is here.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text Tell me what the problem is here is very similar to the target text What seems to be the problem? and directly addresses the issue raised in the input text. There are no nonsensical or factually incorrect information in the generated text, and it does not contain any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: May I speak candidly? \n    target text: Permission to speak freely?\n    generated text: May I speak to you frankly?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning and intent of the target text while maintaining the politeness and seeking permission to speak openly, which aligns with the input text and target text. There are no nonsensical or factually incorrect information present, and the additional information in the generated text is supported by the input and target texts. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: They'll say nothing. \n    target text: They're not gonna say anything.\n    generated text: They're not going to say a word of the word.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text Theyre not going to say a word of the word contains nonsensical and redundant information that is not supported by the input text or the target text. It adds of the word unnecessarily and does not accurately convey the meaning of the original input and target text. Therefore, it is a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: We just have to get you to the hospital. \n    target text: You need to get to a hospital.\n    generated text: We've just got to get you to the hospital.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text closely matches the target text and retains the essential meaning of the input text. There are no nonsensical or factually incorrect information in the generated text. Additionally, the generated text does not introduce any unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: No one has died. \n    target text: There ain't nobody dead.\n    generated text: There's no one who's been killed in the last year.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text contains additional information that cannot be supported by the input text or the target text. It introduces a time frame (in the last year) and specifies that no one has been killed during that time, which goes beyond the scope of the original statement. Additionally, the use of killed introduces a different connotation than the original died, which changes the meaning of the statement. Therefore, the generated text is a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: I'm just like everyone else. \n    target text: I'm no different than anybody else.\n    generated text: I don't know, I'm just like all the others.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning and sentiment of the input and target texts. It maintains the core idea of being similar to others, and the language used is appropriate and coherent. There are no nonsensical or factually incorrect statements, and no additional unsupported information is present. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: It's not safe. \n    target text: It is very dangerous.\n    generated text: It's a little bit too dangerous.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text Its a little bit too dangerous closely aligns with the target text It is very dangerous and maintains the overall meaning of the input text Its not safe. The paraphrased text does not introduce any nonsensical or factually incorrect information, nor does it contain any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Are you sure that's him? \n    target text: Can you confirm it's him?\n    generated text: Are you certain that's the man?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text stays true to the meaning of the original and target texts without introducing nonsensical or factually incorrect information. It maintains the same context and intent of confirming the identity, so it is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: What do you care anyway? \n    target text: Why do you even care, okay?\n    generated text: What's it to you, anyway?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning and tone of the target text, with a similar level of formality and intent. It does not introduce any nonsensical or factually incorrect information, and it does not contain additional unsupported information beyond the input and target texts. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: This is not your house anymore. \n    target text: You don't live here anymore.\n    generated text: This isn't your house anymore.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text closely aligns with the target text and maintains the same meaning as the input text. It does not introduce any nonsensical or factually incorrect information, nor does it contain any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: I'm sorry I can't take your call right now. \n    target text: I can't get to the phone.\n    generated text: I'm sorry I can't take your call right now, okay?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text contains additional information (okay) that cannot be supported by the input text or the target text. This addition changes the meaning and intention of the original statement, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Do you have the fever? \n    target text: Have you got a temperature?\n    generated text: You've got the heat, huh?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text Youve got the heat, huh? not only fails to convey the meaning of the target text Have you got a temperature?, but it also introduces nonsensical and unsupported information by replacing temperature with heat and adding huh. This significantly deviates from the original meaning and adds unsupported information, making it a clear case of hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: She's gonna have a baby. \n    target text: She's having the baby.\n    generated text: She's going to be able to have a baby.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text contains additional information that cannot be supported by the input text or the target text. It goes beyond the simple fact of having a baby to going to be able to have a baby, which is not supported by the original statement or the target text.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: It's urgent, she says. \n    target text: She said it's urgent.\n    generated text: She says it's urgent, she says.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text contains redundant information by repeating she says, which is not present in the input text or the target text. This additional information cannot be supported by the given inputs and targets, making it a hallucination.\nThis is the probability assigned by the editor: 0.9\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: I'll be right with you. \n    target text: See you in a moment.\n    generated text: I'll be right.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text Ill be right not only lacks the complete expression from the input text Ill be right with you but also fails to convey the intended meaning of See you in a moment from the target text. It not only omits crucial information but also adds uncertainty to the message, thereby deviating significantly from the original intent. Hence, it is a clear case of hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: He'll keep you safe. \n    target text: He's protecting you.\n    generated text: He'll keep you in safety.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text Hell keep you in safety does not contain any nonsensical or factually incorrect information. It captures the essence of the input text Hell keep you safe and the target text Hes protecting you by conveying the idea of providing safety and protection. The addition of in safety does not significantly alter the meaning and is supported by the input and target texts.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: We're being tracked. \n    target text: We have a tail.\n    generated text: We're being picked up.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text Were being picked up contains additional information that cannot be supported by the input text Were being tracked and the target text We have a tail. There is no indication of being picked up in the input or target text, making it an unsupported addition and hence a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: I'm just concerned. \n    target text: I just worry, you know?\n    generated text: I'm just a little concerned.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text stays true to the input and target text by simply adding the qualifier a little, which does not introduce any nonsensical or factually incorrect information. It does not provide any additional unsupported information beyond the input and target text. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: I'm gonna make a call. \n    target text: I gotta make a quick call, all right?\n    generated text: I'm gonna make a call, and I'm gonna make a call, okay?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text contains additional information (and Im gonna make a call, okay?) that is not supported by the input text or the target text. This goes beyond the original intention expressed in the input and target texts, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: I'm doing the best that I can. \n    target text: What I do is the best I can do.\n    generated text: I'm just doing the best I can, you know, to get out of here.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text contains additional information (you know, to get out of here) that cannot be supported by the input text or the target text. It introduces a new context or motivation that is not present in the original input or target text, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: She's a darling girl. \n    target text: She's a sweetheart.\n    generated text: She's a sweet, sweet little girl.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text stays true to the overall sentiment and meaning of the input and target texts. It maintains the essence of sweetness and endearment, which is consistent with the original meaning. The addition of little does not significantly change the meaning and can be considered as a minor embellishment. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Are you listening to this? \n    target text: Hey, you hear that?\n    generated text: Are you gonna listen to this?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text closely captures the meaning and intent of the target text while maintaining the essence of the input text. It does not introduce any nonsensical or factually incorrect information, nor does it add any unsupported details. The transformation from Are you listening to this? to Are you gonna listen to this? is a natural and plausible paraphrase, staying within the context and tone of the original utterance.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: And she's doing good. \n    target text: She's all right.\n    generated text: And, uh, she's doing a good job.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text contains additional information (a good job) that cannot be supported by the input text or the target text. This extra information goes beyond the simple statement of Shes all right and adds details that are not present in the original text or the target text. Therefore, it is a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Kid, you did a good job. \n    target text: Yeah, you really did a great job, kid.\n    generated text: Hey, kid, you did a good job, and you're a good one.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text contains additional information that cannot be supported by the input text or the target text. The target text emphasizes the greatness of the job done, but the generated text does not reflect the sentiment of greatness. Additionally, the phrase and youre a good one is not supported by the input or target text, making it an addition that does not align with the original meaning.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Be out in a sec. \n    target text: Be right there.\n    generated text: Be out in seconds.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text contains additional information (seconds) that cannot be supported by the input text or the target text, and it changes the meaning from right there to in seconds, making it factually incorrect and nonsensical.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Your fly is unzipped. \n    target text: Your zipper's down.\n    generated text: Your fly is undone.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text Your fly is undone carries the same meaning as the target text Your zippers down. Both phrases refer to the same situation of someones fly being open. There is no nonsensical or factually incorrect information in the generated text, and it does not contain any additional unsupported information. Therefore, based on the comparison with the input text and the target text, the generated text is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Just put some pressure on here. \n    target text: Press on this thing.\n    generated text: Just put some pressure on this one.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text closely aligns with the target text by instructing to apply pressure, and it does not introduce any nonsensical or factually incorrect information. The addition of this one does not significantly change the meaning or introduce unsupported information compared to the input and target texts. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: I am loving soccer. \n    target text: I love football.\n    generated text: I'm loving the football.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the sentiment and meaning of the target text while using synonymous words from the input text. It does not introduce any nonsensical or factually incorrect information and does not contain any additional unsupported information. Therefore, it is not hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: What does it say up here? \n    target text: What is written here?\n    generated text: What does it say upstairs?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text contains additional information that cannot be supported by the input text or the target text. The word upstairs is not mentioned in the input text or the target text, and it introduces new information that is not present in either of them.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: And how was your flight? \n    target text: Did you have a good flight?\n    generated text: And how'd you get on your flight?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text retains the core meaning of the input and target texts without adding any nonsensical or factually incorrect information. It simply rephrases the question about the flight without introducing any new information. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: It's been six weeks. \n    target text: Six weeks, Martin.\n    generated text: It's been 6 weeks now.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately represents the time frame mentioned in the input text and the target text. It does not contain any nonsensical or factually incorrect information, and it does not introduce any additional unsupported information. Therefore, it aligns with the input and target texts without any issues.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Carry on working. \n    target text: Get on with your work.\n    generated text: You're gonna have to work.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text Youre gonna have to work is a paraphrased version of the input text Carry on working and is consistent with the target text Get on with your work. It does not contain any nonsensical or factually incorrect information, nor does it introduce any additional unsupported information. Therefore, it does not meet the criteria for hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Well, didn't you like it? \n    target text: You didn't enjoy it?\n    generated text: Well, didn't you enjoy it?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text closely follows the structure and meaning of the target text, with minimal changes. The question in the input text and the statement in the target text are seamlessly combined in the generated text without introducing any nonsensical or factually incorrect information or adding any unsupported extra details. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: I thought you were coming with us? \n    target text: Won't you come along?\n    generated text: Didn't you come with us today?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text Didnt you come with us today? contains additional information today that cannot be supported by the input text I thought you were coming with us? and the target text Wont you come along?. This additional information changes the context and introduces new facts that are not present in the original texts, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Can you manage that? \n    target text: Do you feel up to that?\n    generated text: You think you can do that?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text closely captures the meaning and intent of the target text while staying true to the input text. It does not introduce any nonsensical or factually incorrect information, nor does it contain any additional unsupported information. Therefore, it does not meet the criteria for hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: I need to do this alone. \n    target text: It's just something I need to do by myself.\n    generated text: I'm sorry, I've got to do this by myself.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning of the input text and the target text without adding any nonsensical or factually incorrect information. It simply rephrases the original statement to convey the same meaning.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: We can't afford to risk it. \n    target text: We can't risk that.\n    generated text: We don't have the money to risk it, all right?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text closely aligns with the meaning and intent of the target text while retaining the essence of the input text. It doesnt introduce any nonsensical or factually incorrect information and doesnt contain any additional unsupported details. Therefore, it is consistent with the given inputs and targets.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Eh, just a few days. \n    target text: Just a couple of days.\n    generated text: Uh, just for a couple of days.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text closely matches the target text in terms of the intended meaning and only adds a minor filler word Uh which does not change the overall message. There are no nonsensical or factually incorrect information in the generated text, and it does not introduce any additional unsupported information. Therefore, it aligns well with the input text and the target text, making it not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: I'm not involved in this. \n    target text: I don't have anything to do with that.\n    generated text: I'm not in any of this at all.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning and intent of the target text while maintaining the essence of the input text. It does not introduce any nonsensical or factually incorrect information, nor does it contain any additional unsupported details. Therefore, it aligns with both the input and target texts without any signs of hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: Just breathe deep. \n    target text: Just take long, deep breaths.\n    generated text: Just breathe deep, and I'll be right there.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text contains additional information (and Ill be right there) that cannot be supported by the input text or the target text. This additional information changes the meaning and adds a new context that is not present in the original text or the target text, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically generated texts by a paraphrase generation (PG) system. You are given three inputs: \n    input text: I never told you that. \n    target text: I said nothing of the kind.\n    generated text: I never told you that before.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text stays true to the original meaning and does not introduce any nonsensical or factually incorrect information. It simply adds before at the end, which does not significantly alter the meaning or introduce any new unsupported information. Therefore, based on the given inputs and targets, the generated text is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Джон и Энн нравятся друг другу. \n    target text: John and Ann like each other.\n    generated text: John and John are the only one of them.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text John and John are the only one of them bears no resemblance to the input text Джон и Энн нравятся друг другу and the target text John and Ann like each other. It not only fails to accurately translate the original meaning, but it also introduces nonsensical information not supported by the input or target text, making it a clear case of hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Как у Тома с французским? - \"Неплохо\". \n    target text: How's Tom's French? \"Pretty good.\"\n    generated text: How about Tom and French? - \"Not bad.\"\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text contains additional information about Tom and French that cannot be supported by the input text or the target text. It goes beyond the simple inquiry about Toms proficiency in French and introduces a new context about Tom and French, making it factually incorrect.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Я думаю, Тому нужно переодеться. \n    target text: I think Tom needs to change his clothes.\n    generated text: I think that's why you need to dress up.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text contains additional information (thats why) that cannot be supported by the input text or the target text, thus deviating from the original meaning. It also introduces the concept of dressing up which is not present in the original text, adding new information. Therefore, the generated text is a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Был бы я канадец! \n    target text: I wish I were a Canadian.\n    generated text: I would be Canadian!\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the sentiment and meaning of the input text and the target text. It does not contain any nonsensical or factually incorrect information, and it does not introduce any additional unsupported information. The translation is faithful to the original intent and does not deviate in a hallucinatory manner.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Одноклассники обзывали Тома. \n    target text: Tom's classmates called him names.\n    generated text: The classmates called Tom.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text The classmates called Tom does not accurately convey the original meaning of the input text Одноклассники обзывали Тома and the target text Toms classmates called him names. It omits the fact that Tom was being called names, which is a crucial detail in the context. Hence, the generated text is a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Подожди, ты это серьёзно? \n    target text: Whoa, are you serious?\n    generated text: Excuse me, you're serious?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning and tone of the input text and the target text. It does not contain any nonsensical or factually incorrect information, and it does not introduce any additional unsupported information. Therefore, it aligns closely with the input and target texts, making it not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Комната Тома похожа на свинарник. \n    target text: Tom's room looks like a pigsty.\n    generated text: The room Toma looks like a piggy bank.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text The room Toma looks like a piggy bank contains nonsensical information as it replaces pigsty with piggy bank, which changes the meaning completely. Additionally, the generated text introduces information that is not supported by the input text or the target text, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Думаешь, нам удастся когда-нибудь на этом заработать? \n    target text: Do you think that we'll ever make money doing this?\n    generated text: What do you do you want to do?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text does not accurately reflect the content of the input and target texts. It does not capture the meaning of the original question and introduces a different question altogether. Additionally, it does not align with the context of making money, which is the central theme of the input and target texts.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ты вполне можешь пойти со мной. \n    target text: You may as well come with me.\n    generated text: You can go with me perfectly.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text You can go with me perfectly contains additional information that cannot be supported by the input text or the target text, as it introduces the word perfectly which is not present in the original text or the target text. Additionally, the use of perfectly in this context does not accurately convey the meaning of the original sentence. Therefore, the generated text is a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Тому ни до кого нет дела, кроме себя самого. \n    target text: Tom doesn't care about anyone but himself.\n    generated text: That’s why no one has done anything except themselves.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text does not accurately reflect the meaning of the input and target texts. It introduces a completely different idea that is not supported by the original sentence or the target translation. The phrase That’s why no one has done anything except themselves does not capture the original meaning of Tom doesnt care about anyone but himself. This divergence from the original meaning indicates a high likelihood of hallucination.\nThis is the probability assigned by the editor: 0.9\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Тому было некому рассказать свою историю. \n    target text: Tom had no one to tell his story to.\n    generated text: That’s why someone told their story.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text contains information that is not supported by the input text or the target text. It introduces the concept of someone telling their story, which is not present in the original text or the intended meaning. This additional information creates a new narrative that is not supported by the given inputs and targets, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Холодно не по сезону. \n    target text: It's unseasonably cold.\n    generated text: Cold not during the season.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text Cold not during the season does not accurately convey the meaning of the input text Холодно не по сезону and the target text Its unseasonably cold. It not only fails to capture the correct meaning but also introduces nonsensical information that is not supported by the input or target text. Therefore, it is a clear case of hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Пожалуйста, все внимание. Сейчас я приступаю к прослушиванию пациента. Убедитесь, что отследили правильность выполнения этой процедуры - вам предстоит обратиться к её использованию завтра. \n    target text: If everyone could pay close attention, please. I will now auscultate the patient. Make sure to note the proper procedure because you all will be practicing this tomorrow.\n    generated text: Please pay attention. Now I start listening to the patient. Make sure that you have followed the correct implementation of this procedure - you need to contact its use tomorrow.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text does not accurately reflect the content of the input and target texts. It introduces the idea of contacting someone for the use of a procedure, which is not present in the original texts. Additionally, it lacks the specific instruction to note the proper procedure for future practice, which is a key element in the target text. These discrepancies indicate a departure from the original meaning, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Вы ведь не знакомы с братом Тома? \n    target text: You don't know Tom's brother, do you?\n    generated text: Aren't you familiar with Tom's brother?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning of the input and target texts without adding any nonsensical or factually incorrect information. It simply rephrases the question in a slightly different way, which is a common occurrence in natural language translation. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Том нерешителен. \n    target text: Tom is indecisive.\n    generated text: That's unacceptable.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text Thats unacceptable does not accurately reflect the meaning of the input text Том нерешителен (Tom is indecisive) or the target text. It does not convey the same message and introduces new information not present in either the input or target text. Therefore, it is a clear case of hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Вся территория Палестины - это земля всех палестинцев. \n    target text: Palestine, all of it, is the land of all the Palestinians.\n    generated text: The entire territory of Palestine is the land of all Palestinians.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning and intent of the input and target texts. It does not contain any nonsensical or factually incorrect information, nor does it introduce any additional unsupported details. It stays faithful to the original message and effectively conveys the same idea as the target text. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Я могу пройти за кулисы? \n    target text: Can I come backstage?\n    generated text: Can I go for a walk?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text Can I go for a walk? does not accurately convey the meaning of the input text Я могу пройти за кулисы? and the target text Can I come backstage? The generated text introduces new and unrelated information about going for a walk, which is not supported by the input or target text. This additional information makes the generated text a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Опять я проспал! \n    target text: I've overslept again.\n    generated text: I woke up again!\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning of the input text and the target text, as it conveys the idea of oversleeping without introducing any nonsensical or factually incorrect information. It stays faithful to the context provided and does not add any unsupported details. Therefore, it is not hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Будем надеяться, в этом году не случится то же самое. \n    target text: Let's hope the same thing doesn't happen this year.\n    generated text: Hopefully this year won’t be the same thing.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text captures the main idea of hoping for something not to happen this year, similar to the target text. It does not contain any nonsensical or factually incorrect information, and it does not introduce any additional unsupported information. While it may not be an exact match to the target text, it effectively conveys the same meaning as the input and target texts without distortion or hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Срок действия водительских прав Тома истек. \n    target text: Tom's driver's license has expired.\n    generated text: The duration of Tom’s driving rights expired.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the essence of the input and target texts by conveying the expiration of Toms drivers license, although with different wording. There is no nonsensical or factually incorrect information, and no additional unsupported information is added. The meaning is preserved despite the change in phrasing, making it a faithful translation.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: «Но я ничего не делал!» — «Он врёт!» \n    target text: But I didn't do anything! \"He's lying!\"\n    generated text: “But I didn’t do anything!” he said.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the essence of the input and target text, conveying the denial of an action and the accusation of lying. It does not contain any nonsensical or factually incorrect information, and it does not introduce any additional unsupported details. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Похоже, что ограбление банка было спланировано вплоть до мелочей. \n    target text: It appears that the bank robbery was planned right down to the last detail.\n    generated text: It seems that the bank’s budget was designed to go back to the middle.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text completely changes the meaning of the original sentence and introduces information about the banks budget, which is not mentioned in the input or target text. This goes beyond mere translation errors and introduces nonsensical and factually incorrect information, making it a clear case of hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Интересно, что Том приготовит на ужин. \n    target text: I wonder what Tom will make for dinner.\n    generated text: It's interesting Tom's getting ready for dinner.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text Its interesting Toms getting ready for dinner. deviates significantly from the target text and the input text. It introduces the notion of Tom getting ready for dinner, which is not explicitly mentioned in the input or target text. Additionally, the original intention of wondering about what Tom will make for dinner is lost in the generated text, leading to a change in the meaning. Therefore, it contains additional information that cannot be supported by the input text or the target text, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Я прослежу, чтобы эти ботинки починили до завтра. \n    target text: I'll get these shoes fixed by tomorrow.\n    generated text: I'm gonna make sure these shoes don't die until tomorrow.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text contains additional information (dont die) that cannot be supported by the input text or the target text. It also deviates from the intended meaning of getting the shoes fixed, implying an unnecessary and incorrect sense of urgency.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Снаружи ещё светло. \n    target text: It is still light outside.\n    generated text: Get some more light.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text Get some more light does not accurately convey the meaning of the input text Снаружи ещё светло or the target text It is still light outside. Instead of conveying the existing light outside, it suggests an action to obtain more light, which is not supported by the input or target text. This divergence from the original meaning and the introduction of new information indicate that the generated text is a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Том только что вышел из тюрьмы. \n    target text: Tom just got out of jail.\n    generated text: That's just what came out of prison.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text Thats just what came out of prison does not accurately convey the meaning of the input text Том только что вышел из тюрьмы and the target text Tom just got out of jail. It introduces what without any reference, and the tense and structure are altered. Additionally, the phrase Thats just what came out of prison is not coherent and does not make sense in the context. Therefore, the generated text is a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Зачем Тому всё это? \n    target text: Why does Tom need all this?\n    generated text: Why is that all?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text Why is that all? does not accurately reflect the meaning of the input and target texts. It does not capture the essence of Tom needing all this and introduces a different meaning that is not supported by the input or target text. This divergence from the original meaning indicates hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Власть в руках Тома. \n    target text: The power rests with Tom.\n    generated text: Power in Tom's hands.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the essence of the input text and the target text by conveying the idea that power is in Toms possession. It does not introduce any nonsensical or factually incorrect information, nor does it add any unsupported details. Therefore, based on the given inputs and targets, the generated text is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Я чувствую себя амёбой. \n    target text: I feel like an amoeba.\n    generated text: I feel good about myself.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text I feel good about myself is not supported by the input text Я чувствую себя амёбой (I feel like an amoeba) or the target text I feel like an amoeba. It introduces additional information that is not present in the input or target text, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Том очень быстро бежит. \n    target text: Tom is running very fast.\n    generated text: I don't know it.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text I dont know it does not contain any information related to the input text Том очень быстро бежит (Tom is running very fast) or the target text Tom is running very fast. It not only fails to convey the meaning of the input and target texts but also introduces unrelated information, making it a clear case of hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: После всего, что она сделала для компании, её увольнение стало настоящей пощечиной. \n    target text: Her being fired was a real slap in the face after everything she did for the company.\n    generated text: After everything she did for the company, her release became a real bust.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text her release became a real bust contains additional information that cannot be supported by the input text or the target text. The word bust does not accurately convey the meaning of slap in the face and introduces new information not present in the original or target text. This demonstrates a clear hallucination in the translation.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Мы с Томом как раз вчера это обсуждали. \n    target text: Tom and I were discussing that just yesterday.\n    generated text: We talked to Tom about it once yesterday.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the essence of the input and target texts, conveying the idea that Tom and I had a discussion just yesterday. The translated text maintains the core meaning without introducing any nonsensical or factually incorrect information. Therefore, it is not hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Вы ведь сьели не всё печенье? \n    target text: You haven't eaten all the cookies, have you?\n    generated text: You didn't eat all the liver?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text contains factually incorrect information by replacing cookies with liver, which is nonsensical and not supported by the input or target text. Additionally, the mention of liver introduces additional information not present in the original text or target text, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ты в последнее время сама не своя. \n    target text: You haven't been yourself lately.\n    generated text: You're not your own lately.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning of the input and target texts, conveying the idea that the person has been acting differently lately. While it may not perfectly match the target text, it does not contain any nonsensical or factually incorrect information, nor does it introduce any unsupported additional details. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Я лучше домой пойду. \n    target text: I'd rather go home.\n    generated text: I'm better home tomorrow.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text Im better home tomorrow does not accurately convey the meaning of the input text Я лучше домой пойду and the target text Id rather go home. It introduces the word tomorrow which is not supported by the input or the target text, indicating additional information that is not present in the original text. Additionally, the phrase Im better home is nonsensical and does not make sense in the given context. Therefore, the generated text is a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Как это включается? \n    target text: How do you turn this thing on?\n    generated text: How does this include?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text How does this include? does not accurately convey the meaning of the input text Как это включается? or the target text How do you turn this thing on?. It contains nonsensical information and does not align with the input and target texts.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Том ушёл вовремя. \n    target text: Tom left on time.\n    generated text: Tom's gone in time.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text Toms gone in time differs significantly from the target text Tom left on time and introduces a different meaning by using gone instead of left. This change in verb alters the intended message of the original text, making it a hallucination. Additionally, the use of gone suggests a different connotation than left, adding unsupported information. Therefore, the generated text is a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Умение слушать ему не присуще. \n    target text: Listening is not his forte.\n    generated text: The ability to listen to him is not present.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning of the input text and the target text without adding any nonsensical or factually incorrect information. It stays true to the original meaning and does not introduce any unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Инструкции были все на китайском. \n    target text: The instructions were all in Chinese.\n    generated text: It's a lot of people.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text Its a lot of people does not convey any relevant information related to the input text Инструкции были все на китайском (The instructions were all in Chinese) or the target text The instructions were all in Chinese. It does not accurately reflect the content or meaning of the input or target text, and therefore, it is a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Чего бы я только ни отдал, чтобы вернуть эти годы! \n    target text: And what wouldn't I give for these years to come back.\n    generated text: I don’t want to give anything back to these years!\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text contradicts the meaning of the target text and introduces additional information not supported by the input or target text. It changes the sentiment from a desire to have the years back to a lack of desire to return anything.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Русское слово \"ярмарка\" имеет нидерландское происхождение. \n    target text: The Russian word for \"fair\", namely \"ярмарка\", is Dutch in origin.\n    generated text: The Russian word \"yardmark\" has Dutch origin.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text inaccurately translates ярмарка as yardmark, which is factually incorrect. Additionally, it introduces the term yardmark which is not supported by the input or target text, thus adding unsupported information. Therefore, the generated text is a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Том проверил список. \n    target text: Tom checked the list.\n    generated text: That's what I've done.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text Thats what Ive done does not convey the same meaning as the target text Tom checked the list. It introduces new information and does not accurately reflect the content of the input text or the target text. Therefore, it is a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ты обратился в христианство. \n    target text: You converted to Christianity.\n    generated text: It's a lot of people.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text Its a lot of people does not convey any relevant or coherent information related to the input text Ты обратился в христианство (You converted to Christianity) or the target text. It does not provide any meaningful or accurate representation of the content in the input and target texts, making it nonsensical and factually incorrect. Therefore, it is a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Я знаю, что ты это не специально. \n    target text: I know that it wasn't intentional.\n    generated text: I know you're not special.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text I know youre not special contains additional information that cannot be supported by the input text or the target text. It introduces a concept of not being special which is not present in the original text or the target text. Therefore, it is a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Из-за них Тому пришлось поменять своё мнение. \n    target text: They made Tom change his mind.\n    generated text: Because of this, he had to change his mind.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the essence of the input and target text, conveying the same meaning without introducing nonsensical or factually incorrect information. It stays true to the original context and doesnt add any unsupported details. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Когда я пользовался ксероксом, он сломался. \n    target text: I was using the photocopier when it broke.\n    generated text: When I used xerox, it broke down.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the main action and timing described in the input and target texts. Although it uses xerox instead of photocopier, it does not introduce any nonsensical or factually incorrect information. Additionally, it does not contain any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Да где угодно положи. \n    target text: Just put it anywhere.\n    generated text: Yeah, wherever you go.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text Yeah, wherever you go does not accurately convey the meaning of the input and target texts Да где угодно положи and Just put it anywhere. It introduces additional information about going somewhere, which is not supported by the input or target text. Therefore, it is a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ядрён батон! \n    target text: Blimey!\n    generated text: Nuclear Baton!\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text Nuclear Baton! contains additional information that cannot be supported by the input text or the target text. It adds the word nuclear which is not present in the input or target text, and it significantly changes the meaning of the original expression. Therefore, the generated text is a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Это было слишком просто? \n    target text: Was that too easy?\n    generated text: What are you doing?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text What are you doing? does not accurately reflect the content of the input text Это было слишком просто? or the target text Was that too easy? It introduces new information that is not present in the input or target text, and it does not align with the context or meaning of the original text. Therefore, it is a clear case of hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Мы извинились перед Томом. \n    target text: We apologized to Tom.\n    generated text: It's a lot of people.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text Its a lot of people does not preserve the meaning of the input text Мы извинились перед Томом (We apologized to Tom) and does not align with the target text. It introduces nonsensical information that is unrelated to the input or target text, making it a clear case of hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Какая из них ты? \n    target text: Which one is you?\n    generated text: Which one of them are you?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning of the input text and the target text, with only a minor difference in word choice. It does not contain any nonsensical or factually incorrect information, and it does not introduce any additional unsupported details. Therefore, it aligns closely with the original meaning and is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ты бы на моём месте поступил так же. \n    target text: You would've done the same thing if you were me.\n    generated text: You would have done the same in my place.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text is a rephrased version of the target text and does not contain any nonsensical or factually incorrect information. It stays true to the meaning of the input text and the target text without adding any unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Я тебя прикрыл. \n    target text: I've got you covered.\n    generated text: I covered you.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning of the input text and the target text without adding any nonsensical or factually incorrect information. It maintains the same essential message as the target text and does not introduce any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Я этот трек на репит поставил. \n    target text: I put this track on repeat.\n    generated text: I put this track on the shelf.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text I put this track on the shelf does not accurately convey the meaning of the input text Я этот трек на репит поставил and the target text I put this track on repeat. The addition of on the shelf introduces new information that is not supported by the input or target text, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Давайте не будем спешить. \n    target text: Let's take our time.\n    generated text: Let's not hurry.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the general sentiment and meaning of the input text and target text, despite using slightly different phrasing. It does not introduce any nonsensical or factually incorrect information, nor does it contain any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ты потом ещё придёшь? \n    target text: Will you come back later?\n    generated text: Then you'll come again?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the intent of the input text and the target text, which is about someone coming back later. There are no nonsensical or factually incorrect information, and no additional unsupported information is present in the generated text. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: После того Том никогда не видел Мэри. \n    target text: Tom never saw Mary after that.\n    generated text: Then Tom never saw Mary.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the main idea of the input and target texts, stating that Tom never saw Mary after a certain event. It does not introduce any nonsensical or factually incorrect information, nor does it contain any additional unsupported details. Therefore, it aligns with the input and target texts without any issues.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Собаку покормили? \n    target text: Has anyone fed the dog?\n    generated text: Did they feed the dog?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning of the input and target text without adding any nonsensical or factually incorrect information. It simply uses a different tense, but the overall meaning remains consistent.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Я ничем не могу помочь Тому. \n    target text: There's nothing I can do to help Tom.\n    generated text: I can't help Tom.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the essence of the input text and the target text, conveying the same meaning without adding any nonsensical or factually incorrect information. It stays true to the original message and does not introduce any unsupported details. Therefore, it is not hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Нам пойти? \n    target text: Should we go?\n    generated text: Let's go?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text Lets go? is a natural and plausible response to the input text Нам пойти? and the target text Should we go?. The meaning and intent of the input and target text are preserved in the generated text without introducing any nonsensical or factually incorrect information. There are no additional unsupported details in the generated text. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Я обычно прихожу на работу первым. \n    target text: I'm usually the first one to get to work.\n    generated text: I usually go to work first.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning of the input text and the target text without introducing any nonsensical or factually incorrect information. It stays true to the content and does not add any unsupported details. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Жаль, что я не такой храбрый, как Том. \n    target text: I wish I were as brave as Tom is.\n    generated text: I'm sorry I'm not as brave as Tom.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately conveys the main idea of the input text and the target text, expressing a wish for bravery like Toms. It does not contain nonsensical or factually incorrect information, and it does not introduce any additional unsupported details. The only difference is in the wording, but the meaning remains consistent.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Люди свободны. \n    target text: The people are free.\n    generated text: People are free.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text People are free accurately captures the main idea of the input text Люди свободны and the target text The people are free. While the article The is missing in the generated text, it does not alter the meaning of the sentence. Therefore, there are no nonsensical or factually incorrect information, and no additional unsupported information is present in the generated text. Hence, it is not hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: На нас многие рассчитывают. \n    target text: Many people rely on us.\n    generated text: Many expect us.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text Many expect us captures the general idea of reliance or dependence, although its not an exact match to the target text Many people rely on us. There are no nonsensical or factually incorrect information in the generated text, and it does not introduce any additional unsupported information. Therefore, based on the given inputs and targets, the generated text is not a hallucination.\nThis is the probability assigned by the editor: 0.8\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Том у меня самый младший. \n    target text: Tom is my youngest.\n    generated text: I have the youngest Tom.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning and relationship between Tom and my youngest from the input text and the target text. It does not introduce any nonsensical or factually incorrect information, nor does it contain any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Том выучил новое слово. \n    target text: Tom learned a new word.\n    generated text: I found a new book.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text I found a new book contains factually incorrect information as it introduces the concept of finding a book, which is not supported by the input text or the target text. Additionally, it introduces additional information about finding a book which is not present in the input or target text. Therefore, it is a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Твои сыновья довольно симпатичные. \n    target text: Your sons are quite handsome.\n    generated text: Your children are pretty nice to you.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text contains additional information that cannot be supported by the input text or the target text. While the input and target texts specifically mention sons and handsome, the generated text refers to children and nice, which introduces unsupported information and changes the meaning.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Я половину ночи не спала. \n    target text: I was up half the night.\n    generated text: I didn't sleep for half a night.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning of the input and target text without introducing any nonsensical or factually incorrect information. It conveys the same idea that the person did not sleep for part of the night, which aligns with the intended meaning of the original text. There are no additional unsupported details in the generated text. Therefore, it is not hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: В гостиной был огромный паук. \n    target text: In the living room there was a huge spider.\n    generated text: There was a huge spider in the hotel.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text contains additional information (hotel) that cannot be supported by the input text or the target text, which only mention a living room. This additional information changes the context and introduces unsupported details, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Как нам попасть в команду? \n    target text: How can we join the team?\n    generated text: How do we get to the team?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning and intent of the input and target text. It does not contain any nonsensical or factually incorrect information, and it does not introduce any additional unsupported information. The translation How do we get to the team? is a valid and natural way to express Как нам попасть в команду? in English.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Когда у меня плохое настроение, я люблю подумать о горностаях, чтобы приободриться. \n    target text: When I'm in a bad mood, I like to think of stoats to cheer myself up.\n    generated text: When I have a bad mood, I like to think about pride in order to get bored.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text think about pride in order to get bored does not accurately reflect the target text think of stoats to cheer myself up. The word pride is not related to stoats, and in order to get bored is nonsensical in this context. Additionally, the generated text introduces the concept of pride which is not supported by the input or target text, making it an additional unsupported information. Therefore, the generated text is a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Сейчас я не могу себе этого позволить. \n    target text: I can't afford that right now.\n    generated text: Now I can't afford it.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning of the input and target text without introducing any nonsensical or factually incorrect information. It stays faithful to the original message and does not add any unsupported details. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Перед тем как выйти из дома, я всегда завтракаю. \n    target text: I always have breakfast before leaving home.\n    generated text: Before I get out of the house, I always have breakfast.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning of the input text and the target text without adding any nonsensical or factually incorrect information. It maintains the same sequence of actions and does not introduce any additional unsupported information. Therefore, it is not hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Пожалуйста, просто делайте всё, как я. \n    target text: Please just do everything I do.\n    generated text: Please, just do everything like me.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning and intent of the input and target texts. It maintains the same request and does not introduce any nonsensical or factually incorrect information. The slight variation in wording (like me instead of I do) does not change the overall meaning of the request.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Они приветствовали нас с распростертыми обьятиями. \n    target text: They welcomed us with open arms.\n    generated text: They welcomed us with disillusioned hugs.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text disillusioned hugs does not accurately convey the meaning of с распростертыми обьятиями which means with open arms in English. Instead of a welcoming gesture, disillusioned hugs implies a sense of disappointment or loss of hope, which is factually incorrect and not supported by the input or target text. This additional information in the generated text constitutes a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Я постоянно врал жене. \n    target text: I lied constantly to my wife.\n    generated text: I've always been mad at my wife.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text Ive always been mad at my wife contains additional information that cannot be supported by the input text Я постоянно врал жене (I constantly lied to my wife) or the target text I lied constantly to my wife. This additional information changes the meaning and introduces new context, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Мы ещё далеко от цели. \n    target text: Our destination is still far away.\n    generated text: We're still far from our goal.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning and intent of the input text and the target text. It does not introduce any nonsensical or factually incorrect information, and it does not contain any additional unsupported information. Therefore, it aligns with the original meaning and does not deviate into hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Собака твоя. \n    target text: The dog is yours.\n    generated text: Your dog.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text Your dog is a simple reordering of the words in the input text Собака твоя and carries the same meaning as the target text The dog is yours. It does not contain any nonsensical or factually incorrect information, and it does not introduce any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Я получаю достаточно. \n    target text: I'm paid enough.\n    generated text: I get enough.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning and sentiment of the input and target texts without adding any nonsensical or factually incorrect information. It maintains the essence of the original message without introducing any unsupported details. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Нам придется баловать Мэри, пока она не поправится. \n    target text: We must baby Mary until she gets well again.\n    generated text: We'll have to beat Mary until she gets right.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text Well have to beat Mary until she gets right contains a completely different and inappropriate action compared to the target text We must baby Mary until she gets well again. The use of beat is factually incorrect and nonsensical in the context of caring for someone who is unwell. Additionally, the generated text introduces an action that is not supported by the input text or the target text, making it a clear case of hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Не позволяй детям играть около пруда. \n    target text: Don't let the children go near the pond.\n    generated text: Don’t let kids play around.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text captures the essence of the input and target texts by conveying the message of not allowing children near the pond. It may be slightly shorter and less specific than the target text, but it does not contain any nonsensical or factually incorrect information. The meaning is preserved, and no additional unsupported information is added. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Мне почти нечего делать. \n    target text: I have almost nothing to do.\n    generated text: There's almost nothing I can do.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning and intent of the input and target texts without introducing any nonsensical or factually incorrect information. It stays true to the original meaning and does not add any unsupported details. It simply rephrases the original statement while maintaining its essence.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Я могу коснуться ладонями пола, не сгибая коленей. \n    target text: I can place the palms of my hands on the floor without bending my knees.\n    generated text: I can touch the elbows of sex without bending my knees.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text contains nonsensical and factually incorrect information by mentioning touching the elbows of sex, which is not supported by the input text or the target text. Additionally, it introduces new and unrelated information, making it a clear case of hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Том пытается заработать на новую трубу. \n    target text: Tom is trying to earn enough money to buy himself a new trumpet.\n    generated text: Tom's trying to make money on a new pipe.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the main idea of the input text and the target text, as both refer to Tom trying to acquire something new (a trumpet or a pipe) by earning money. There are no nonsensical or factually incorrect details in the generated text, and it does not introduce any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Суп ещё не остыл. \n    target text: The soup is still hot.\n    generated text: The soup hasn't stayed yet.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text The soup hasnt stayed yet contains factually incorrect information as the soup is described as still hot in the target text, which contradicts the notion of it not having cooled down yet. Additionally, the phrase hasnt stayed yet does not make sense in this context. Furthermore, the generated text contains information that cannot be supported by the input text or the target text, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Решение тактических упражнений, понимание сложной концовки, наблюдение за живым матчем и попытки «угадать» ходы, которые будут сыграны. Всё это весело. \n    target text: Solving a tactical exercise, understanding a difficult ending, following a live match and trying to \"guess\" the moves that will be played. All of this is fun.\n    generated text: The solution of tactical exercises, understanding complex endings, watching the live match and trying to \"imagine\" the steps that will be played. All this fun.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the main ideas and concepts from the input text and the target text without introducing any nonsensical or factually incorrect information. It stays true to the content and meaning of the original text, making it a faithful translation without hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Я принёс это тебе. \n    target text: I brought this for you.\n    generated text: I'll bring it to you.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text Ill bring it to you contains additional information (Ill bring it) that cannot be supported by the input text Я принёс это тебе and the target text I brought this for you. This additional information changes the meaning of the original sentence and introduces new information not present in the source or target texts, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Руи Лопес де Сегура, священник и известный испанский шахматист XVI века, написал книгу на 150 страниц под названием Libro del Ajedrez, посвященную исчерпывающим исследованиям, которые он провел в дебюте (1.e4 e5 2.♘f3 ♘c6 3 .♗b5), названный в его честь. \n    target text: Ruy López de Segura, a priest and a famous Spanish chess player of the 16th century, wrote a book of 150 pages, called Libro del Ajedrez, about exhaustive studies he made on the opening (1.e4 e5 2.♘f3 ♘c6 3.♗b5) that is named after him.\n    generated text: Rui Lopez de Segura, priest and famous Spanish chess player of the 16th century, wrote a 150-page book called Libro del Ajedrez dedicated to the exhaustive research he conducted in his debut (1.e4 e5 2.f3 c6 3.b5), named in his honor.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately reflects the information provided in the input and target texts. It maintains the key details such as Ruy López de Segura being a priest and a famous Spanish chess player, the book titled Libro del Ajedrez, and the exhaustive studies on the opening (1.e4 e5 2.♘f3 ♘c6 3.♗b5) named after him. While there are some minor differences in translation, the essential information remains consistent and accurate.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Тому надо было туда поехать. \n    target text: Tom had to go there.\n    generated text: That's why we had to go there.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text Thats why we had to go there contains additional information (we) that cannot be supported by the input text or the target text. It goes beyond the scope of the original statement and introduces a new subject (we) not present in the input or target text, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: В этом уже нет особой необходимости. \n    target text: That isn't really necessary anymore.\n    generated text: There is no need for this anymore.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning and intent of the input text and the target text. It conveys the same message without adding any nonsensical or factually incorrect information, and it does not introduce any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Том соврал. \n    target text: Tom lied.\n    generated text: Tom agreed.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text Tom agreed is factually incorrect based on the input text Том соврал which translates to Tom lied in English. The generated text does not align with the target text and introduces additional unsupported information, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ты не обращаешь на меня внимания. \n    target text: You're ignoring me.\n    generated text: You don't pay attention to me.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning of the input text and the target text without adding any nonsensical or factually incorrect information. It stays true to the original meaning and doesnt introduce any unsupported details, hence it is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Вас в последнее время совсем не видно. \n    target text: You've been absent a lot lately.\n    generated text: You haven't seen anything lately.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text You havent seen anything lately does not accurately convey the meaning of the input text Вас в последнее время совсем не видно and the target text Youve been absent a lot lately. It not only fails to capture the intended meaning but also introduces a meaning that is not supported by the input or target text, making it factually incorrect. Therefore, the generated text is a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Она сняла с себя одежду. \n    target text: She took off her clothes.\n    generated text: She slept with her clothes.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text She slept with her clothes contains factually incorrect information compared to the target text She took off her clothes. The addition of slept instead of took off is a significant change in the action, leading to a different and factually incorrect interpretation of the original sentence. Therefore, the generated text is a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ей не нравится моя манера говорить. \n    target text: She doesn't like the way I speak.\n    generated text: She doesn't like to talk about my manner.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text contains additional information (talk about) that is not supported by the input text or the target text, and it changes the meaning of the original sentence. It also deviates from the intended meaning of the input and target texts, indicating a clear hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Монах в монастыре. \n    target text: The monk is in the monastery.\n    generated text: Monk in the monastery.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the main idea and information from the input and target text without any additional unsupported information. It is a simple and direct translation without any nonsensical or factually incorrect information.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Хотите записаться на прием? \n    target text: Would you like to make an appointment?\n    generated text: Do you want to sign up for admission?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the intent of the input text and the target text, which is to inquire about making an appointment. There are no nonsensical or factually incorrect information in the generated text, and it does not contain any additional unsupported information. Therefore, it aligns well with the input and target texts, making it not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Я готов, а вы? \n    target text: I'm ready, and you?\n    generated text: I'm ready, aren't you?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning of the input text and the target text without introducing any nonsensical or factually incorrect information. It simply adds a question tag at the end, which is a common form of expression and does not alter the intended meaning of the original text.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Это не для всех. \n    target text: This isn't everyone's cup of tea.\n    generated text: It's not for everyone.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the essence and meaning of the input and target text without adding any nonsensical or factually incorrect information. It conveys the same message in a concise manner without introducing any unsupported details. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Где мне его искать? \n    target text: Where should I look for it?\n    generated text: Where do I want him?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text Where do I want him? does not accurately convey the meaning of the input text Где мне его искать? or the target text Where should I look for it? The addition of want him introduces a new concept not present in the original texts, making it factually incorrect and containing additional unsupported information. Therefore, it is a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Поток лавы уничтожал всё на своём пути. \n    target text: The lava flow destroyed everything in its path.\n    generated text: The lava flow destroyed everything in its own way.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately conveys the destructive nature of the lava flow and its impact on everything in its path, which is consistent with both the input text and the target text. There are no nonsensical or factually incorrect information in the generated text, and it does not contain any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Том старается изо всех сил. \n    target text: Tom is trying as hard as he can.\n    generated text: Tom is trying his best.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning of the original text and the target text, conveying the same idea without adding any nonsensical or factually incorrect information. It stays true to the input and target texts without any hallucinations.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Скорее всего, никто даже не заметит. \n    target text: No one will likely even notice.\n    generated text: Most likely, no one will even notice.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning of the input text and the target text. It does not contain any nonsensical or factually incorrect information, and it does not introduce any additional unsupported information. Therefore, it aligns closely with the given inputs and targets.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Сегодня снег. \n    target text: Today it's snowing.\n    generated text: It's snowing today.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately conveys the same information as the target text and is a natural reordering of the words in the input text. There are no nonsensical or factually incorrect details present in the generated text.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Мы установим прожекторы. \n    target text: We'll install spotlights.\n    generated text: We'll set up projectors.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text Well set up projectors introduces information about setting up projectors, which is not supported by the input text or the target text. The target text specifically mentions spotlights, not projectors, indicating a clear deviation from the original meaning. This additional information constitutes a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Я чихнул около двадцати раз. \n    target text: I sneezed about twenty times.\n    generated text: I walked about twenty times.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text I walked about twenty times does not accurately reflect the input text Я чихнул около двадцати раз and the target text I sneezed about twenty times. The machine translation has completely changed the action from sneezing to walking, which is factually incorrect and nonsensical in the context of the input and target texts. This deviation from the original action makes the generated text a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Мэри считает, что она самая умная. \n    target text: Mary thinks she's smarter than everyone else.\n    generated text: Mary thinks she's the smartest.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the main idea and sentiment of the input text and the target text. It does not contain any nonsensical or factually incorrect information, and it does not introduce any additional unsupported information. Therefore, it is a faithful translation without hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Сколько времени тебе нужно, чтобы его починить? \n    target text: How much time do you need to repair it?\n    generated text: How long do you need to start it?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text How long do you need to start it? does not accurately convey the meaning of the original text Сколько времени тебе нужно, чтобы его починить? and the target text How much time do you need to repair it? The addition of start it in the generated text introduces information that is not present in the original or target text, making it factually incorrect and a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Здоровый человек не знает цены здоровью. \n    target text: A healthy man does not know the value of health.\n    generated text: A healthy person does not know the prices of health.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning of the input text and the target text. It substitutes man with person, which does not change the meaning. There are no nonsensical or factually incorrect information in the generated text, and it does not contain any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ты говоришь по-немецки. \n    target text: You speak German.\n    generated text: You're speaking German.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning of the input and target texts without introducing any nonsensical or factually incorrect information. It simply adds a continuous aspect to the verb, which does not change the meaning or introduce any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Я не хотел, чтобы со мной было то же самое. \n    target text: I didn't want the same thing to happen to me.\n    generated text: I didn’t want it to be the same with me.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the main idea and sentiment of the target text, although it uses slightly different phrasing. The meaning is preserved and no nonsensical or factually incorrect information is introduced. The generated text does not contain any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Вы хотите сказать, что это вас не пугает? \n    target text: Do you mean that doesn't scare you?\n    generated text: You mean it doesn't scare you?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning and intent of the target text while maintaining the core information from the input text. There are no nonsensical or factually incorrect elements, and no additional unsupported information is added. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Без твоей помощи это было бы невозможно. \n    target text: It would've been impossible without your help.\n    generated text: Without your help it would be impossible.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning and intent of the input text and the target text. It conveys the same essential message, albeit with a slightly different word order. There are no nonsensical or factually incorrect statements, nor does it contain any additional unsupported information. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Он давно её знает. \n    target text: He has known her for a long time.\n    generated text: He knew her a long time ago.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning of the input text and the target text, expressing the idea that the subject has been acquainted with her for an extended period. There are no nonsensical or factually incorrect details, and no additional unsupported information is introduced. The only difference is the tense used in the verb, but it does not significantly alter the meaning of the sentence. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Том только-что стоял там, открыв рот, и глазел на Мэри. \n    target text: Tom just stood there with his mouth open, staring at Mary.\n    generated text: Tom just stood there, opened his mouth, and looked at Mary.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the main actions described in the input text and the target text, such as Tom standing with his mouth open and staring at Mary. There are no nonsensical or factually incorrect information, and the generated text does not contain any additional unsupported information. The only difference is the order of the actions, but it does not change the overall meaning or context. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Том вернулся в Бостон после трёхдневного отсутствия. \n    target text: Tom came back to Boston after being away for three years.\n    generated text: Tom returned to Boston after a three-day absence.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the main idea of Tom returning to Boston after a period of absence, which aligns with the input text and the target text. There are no nonsensical or factually incorrect information in the generated text, and it does not contain any additional unsupported information. Hence, it is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Один квадратный метр солнечной батареи вырабатывает примерно один ватт энергии, поэтому в данный момент непросто использовать солнечную энергию в крупных масштабах. \n    target text: The output power of a one square meter solar panel is about one watt, so it is difficult to use solar power on a large scale at present.\n    generated text: One square meter of solar battery produces about one watt of energy, so it’s not easy to use solar energy on a large scale right now.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately conveys the information from the input text and the target text without adding any nonsensical or factually incorrect information. It maintains the same meaning and does not introduce any unsupported additional information. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Это очень весело, собирать разнообразные ракушки на пляже. \n    target text: It is a lot of fun picking various shells on the sands.\n    generated text: It is very fun to collect various crabs on the beach.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text contains factually incorrect information by replacing shells with crabs, which is unsupported by the input text or the target text. Additionally, it introduces new information not present in the input or target text, making it a clear case of hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Думаю, он делает вид. \n    target text: I think he's faking.\n    generated text: I think he's making a look.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text I think hes making a look contains additional information (making a look) that cannot be supported by the input text or the target text. It goes beyond the meaning of faking and adds an unsupported action, making it factually incorrect and an overinterpretation of the original text.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Постой-ка, ты это серьёзно? \n    target text: Woah, are you serious?\n    generated text: Wait, are you serious?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning and tone of the target text while staying faithful to the input text. It does not contain any nonsensical or factually incorrect information, nor does it introduce any additional information. Therefore, it aligns closely with the given inputs and targets, making it not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ты слышал, как птицы щебечут? \n    target text: Did you hear the birds tweeting?\n    generated text: Did you hear how the birds smell?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text Did you hear how the birds smell? contains factually incorrect information as birds do not emit a smell when they make sounds. Additionally, it introduces additional information about the birds smell which is not supported by the input text or the target text. Therefore, it is a clear case of hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Что ты там поёшь? \n    target text: What are you singing?\n    generated text: What are you drinking there?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text What are you drinking there? does not accurately reflect the meaning of the input text Что ты там поёшь? and the target text What are you singing?. The addition of drinking instead of singing introduces factually incorrect information, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Бомба была успешно обезврежена. \n    target text: The bomb was successfully defused.\n    generated text: The bomb was successfully decommissioned.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately conveys the same meaning as the target text. Decommissioned and defused are both valid ways to describe the successful neutralization of a bomb, and there are no nonsensical or factually incorrect information in the generated text. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Мне нравятся люди, которые не боятся стареть. \n    target text: I like people who are not afraid to grow old.\n    generated text: I like people who don’t like to be old.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text I like people who don’t like to be old differs significantly from the target text I like people who are not afraid to grow old in meaning. The generated text does not convey the same message as the target text and introduces a different concept (don’t like to be old) which is not supported by the input text or the target text. Additionally, the generated text introduces the idea of not liking to be old, which is not present in the original text and therefore adds information that is not supported by the input or target text.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Это Вы меня спасли? \n    target text: Are you the one who saved me?\n    generated text: Did you save me?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the main idea and sentiment of the target text, Are you the one who saved me?, without adding any nonsensical or factually incorrect information. The input text, Это Вы меня спасли?, is correctly translated to Did you save me? in the context of the target text. The generated text does not introduce any additional unsupported information. Therefore, it is not hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Это ты дал ему мой адрес? \n    target text: Were you the one who gave him my address?\n    generated text: Did you give him my address?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the essence of the input and target text, conveying the same meaning in a different form. It does not introduce any nonsensical or factually incorrect information, nor does it contain any additional unsupported details. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Свобода бесценна. \n    target text: Freedom is invaluable.\n    generated text: Freedom is worthless.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text Freedom is worthless completely changes the meaning of the original statement Свобода бесценна, which means Freedom is invaluable. The word worthless has a strongly negative connotation, while invaluable has a positive connotation. This is a significant deviation from the original meaning, making it a clear hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: На немецком тоже говорят? \n    target text: Is German spoken too?\n    generated text: Do they speak German too?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning and intent of the input and target text. It does not contain any nonsensical or factually incorrect information, and it does not introduce any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Возможно, мне лучше самому позвать Тома. \n    target text: Maybe I should call Tom myself.\n    generated text: Maybe I'd better call Tom.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning and intent of the input text and the target text. It does not contain any nonsensical or factually incorrect information, nor does it introduce any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ты не знал, что Том жил в Бостоне, когда был ребёнком? \n    target text: Didn't you know Tom lived in Boston when he was a kid?\n    generated text: You didn't know Tom lived in Boston when he was a kid?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning of the input text and the target text without adding any nonsensical or factually incorrect information. It maintains the same structure and conveys the same information as the target text, making it a faithful translation without any hallucinations.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: За мной никого, я последняя. \n    target text: There's no one behind me. I'm the last one.\n    generated text: No one's behind me, I'm the last one.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning and intent of the input and target texts without introducing any nonsensical or factually incorrect information. It maintains the same essential information and tone as the target text, and there are no additional unsupported details. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Кто-то кричал. \n    target text: Someone screamed.\n    generated text: Someone was yelling.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text Someone was yelling accurately conveys the action of someone making a loud cry or shout, which aligns with the input text Кто-то кричал meaning Someone screamed. While there is a slight difference in the intensity of the action, it still captures the essence of the original text without adding any nonsensical or factually incorrect information. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Некоторые предложения слишком длинные. \n    target text: Some sentences are too long.\n    generated text: Some suggestions are too long.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text Some suggestions are too long does not accurately reflect the meaning of the input text Некоторые предложения слишком длинные which translates to Some sentences are too long. The word suggestions is not supported by the input text or the target text, and it introduces additional information that changes the meaning. Therefore, the generated text is a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Я хочу только напомнить, что это была не моя идея. \n    target text: I just want to remind you that this wasn't my idea.\n    generated text: I just want to remember that it wasn’t my idea.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning of the input text and the target text without adding any nonsensical or factually incorrect information. It maintains the same intent and does not introduce any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Она не особенно помогла. \n    target text: She wasn't much help.\n    generated text: She didn't particularly help.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning of the input and target texts without introducing nonsensical or factually incorrect information. It maintains the core idea that she was not very helpful, albeit with a slightly different wording. There are no additional unsupported details in the generated text. Therefore, it is not hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Собаки не различают цвета. \n    target text: Dogs can't tell colors apart.\n    generated text: Dogs don’t distinguish colors.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning of the input and target text, stating that dogs cannot distinguish colors, which aligns with the information provided. There are no nonsensical or factually incorrect statements, and no additional unsupported information is introduced. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Он бегло говорит по-русски — по крайней мере, он так мне сказал. \n    target text: He speaks fluent Russian, or at least that's what he told me.\n    generated text: He speaks Russian fluently – at least he told me so.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning and tone of the input and target text. It does not contain any nonsensical or factually incorrect information, and it does not introduce any additional unsupported information. The translation is faithful to the original meaning and does not deviate in a way that would constitute a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: И Том, и Мэри знают, кто это сделал. \n    target text: Both Tom and Mary know who did that.\n    generated text: Tom and Mary both know who did it.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately conveys the same meaning as the target text and does not introduce any nonsensical or factually incorrect information. The reordering of Tom and Mary and know who did it does not change the meaning significantly. Therefore, it is not hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Том не знает, что Мэри хочет, чтобы он купил. \n    target text: Tom doesn't know what Mary wants him to buy.\n    generated text: Tom doesn't know Mary wants him to buy.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text omits the crucial information what from the target text, changing the meaning of the sentence. The omission of what alters the understanding and leads to a different interpretation of the original sentence. This deviation from the target text indicates that the generated text is a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Одеваем наши пальто и шапки. \n    target text: We put on our coats and hats.\n    generated text: We wear our coats and hats.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the action described in the input text and the target text without adding any nonsensical or factually incorrect information. It simply uses a different verb (wear instead of put on) but conveys the same meaning. There is no additional information that cannot be supported by the input or target text. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Мэри считает, что она самая умная. \n    target text: Mary thinks she's smarter than everyone else.\n    generated text: Mary thinks she's the smartest.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the main idea of the original sentence by conveying Marys belief in her intelligence, which aligns with the target text. There are no nonsensical or factually incorrect details, and the essence of the input and target texts is preserved in the generated text.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Мы видели, как ребенок сел в автобус. \n    target text: We saw the child get on the bus.\n    generated text: We saw a child sitting on a bus.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the action of the child getting on the bus, albeit in a slightly different form. It does not contain any nonsensical or factually incorrect information, nor does it introduce any additional unsupported details. Therefore, it aligns with the input text and the target text, making it not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: У него сломана шея. \n    target text: His neck is broken.\n    generated text: He had a broken neck.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately conveys the same information as the target text, with the same subject and action. It does not introduce any additional information or change the meaning of the original sentence. Therefore, it is not hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Мы все тебя любим. \n    target text: We all love you.\n    generated text: We love you all.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately conveys the sentiment and meaning of the input text and the target text. It does not contain any nonsensical or factually incorrect information, and it does not introduce any additional unsupported information. The reordering of words does not change the overall meaning of the sentence.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Нам не так уж важно, сколько вам лет. \n    target text: We don't really care how old you are.\n    generated text: It doesn’t matter how old you are.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning of the input and target text without introducing any nonsensical or factually incorrect information. It maintains the essence of the original message and does not add any unsupported information. Therefore, it is not hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Я хотел бы оставить отзыв. \n    target text: I'd like to leave feedback.\n    generated text: I would like to leave a comment.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the intended meaning of the input text and the target text. It does not contain any nonsensical or factually incorrect information, nor does it introduce any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: В моей стране люди обычно приветствуют друг друга рукопожатием. \n    target text: People generally greet each other by shaking hands in my country.\n    generated text: In my country, people usually welcome each other by hand.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text incorrectly implies that people welcoming each other by hand is the same as shaking hands, which is factually incorrect. Additionally, it omits the word greet which is present in the target text, changing the meaning of the sentence. These inaccuracies and omissions make the generated text a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ты часто купаешься? \n    target text: Do you go swimming often?\n    generated text: Do you often buy?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text Do you often buy? is factually incorrect and does not correspond to the input text Ты часто купаешься? or the target text Do you go swimming often?. The verb купаешься means swim in Russian, not buy, and the generated text introduces information that is not supported by the input or target texts, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Плавать с дельфинами опасно. \n    target text: It is dangerous to swim with dolphins.\n    generated text: Swimming with dolphins is dangerous.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately conveys the main idea of the input text and the target text without adding any nonsensical or factually incorrect information. It stays true to the original message and does not introduce any unsupported additional information. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Том единственный здесь, у кого нет водительских прав? \n    target text: Is Tom the only one here who doesn't have a driver's license?\n    generated text: That's the only one here who has no driver's license?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text changes the meaning of the original question by stating Thats the only one here who has no drivers license? instead of Is Tom the only one here who doesnt have a drivers license?. Additionally, the generated text introduces Thats which is not supported by the input or target text, making it factually incorrect and adding information not present in the original sentence. Therefore, the generated text is a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Нам надо его нанять. \n    target text: We should hire him.\n    generated text: We have to hire him.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text is a very close paraphrase of the target text and captures the same meaning as the input text. There are no nonsensical or factually incorrect information in the generated text, and it does not contain any additional unsupported information. Therefore, it is not hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Можете уходить, если хотите. \n    target text: You may leave if you want to.\n    generated text: You can leave if you want.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning of the input text and the target text. It conveys the same message without adding any nonsensical or factually incorrect information. It does not contain any additional unsupported information. Therefore, it is not hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Я их не боюсь. \n    target text: I don't fear them.\n    generated text: I'm not afraid of them.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning of the input text and the target text without adding any nonsensical or factually incorrect information. It maintains the same sentiment and does not introduce any unsupported details. Therefore, it aligns with the inputs and targets without any signs of hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Когда я встретил её на днях, она выглядела очень счастливой. \n    target text: When I saw her recently, she looked very happy.\n    generated text: When I met her during the day, she looked very happy.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text contains additional information (during the day) that is not supported by the input text or the target text. This extra information changes the context and meaning of the original sentence, making it factually incorrect compared to the target text.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Ты действительно думаешь, что я могу летать? \n    target text: You really think I can fly?\n    generated text: Do you really think I can fly?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning and intent of the input text and target text without introducing any nonsensical or factually incorrect information. It stays true to the content and context provided in the input and target texts.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Я лучше не буду отвечать на этот вопрос. \n    target text: I'd rather not answer that question.\n    generated text: I'd better not answer that question.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning and sentiment of the target text while maintaining the general structure of the input text. There are no nonsensical or factually incorrect information in the generated text, and it does not contain any additional information beyond what is present in the input and target texts. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Том стал отцом. \n    target text: Tom is a father now.\n    generated text: Tom became a father.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately conveys the same information as the target text based on the input. There are no nonsensical or factually incorrect details, and no additional unsupported information is present. The generated text stays true to the input and target texts without any embellishments or alterations, making it consistent and not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Я его узнала. \n    target text: I recognized him.\n    generated text: I knew him.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text I knew him is a valid and plausible rephrasing of I recognized him considering the context and meaning of the input and target texts. There are no nonsensical or factually incorrect information in the generated text, nor does it contain any additional unsupported information. Therefore, it is not hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Уборщица прервала разговор. \n    target text: The cleaning lady interrupted the conversation.\n    generated text: The locksmith interrupted the conversation.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text The locksmith interrupted the conversation is factually incorrect based on the input text and the target text. The input text mentions a cleaning lady, not a locksmith, and the target text also refers to the cleaning lady. Therefore, the mention of a locksmith is nonsensical and does not align with the information provided in the input and target texts, making it a clear case of hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Я его в последнее время не видел; передавай ему привет. \n    target text: I haven't seen him lately; give him my regards.\n    generated text: I haven't seen him lately; give him hello.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text contains a nonsensical phrase give him hello which does not convey the meaning of передавай ему привет in the input text or give him my regards in the target text. This is a clear deviation from the intended message and qualifies as a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: У нас оно уже есть. \n    target text: We already have one.\n    generated text: We already have it.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text closely matches the target text in terms of meaning and does not introduce any nonsensical or factually incorrect information. The change from one to it is a minor difference that does not alter the overall meaning of the sentence. Therefore, based on the given inputs and targets, the generated text is not hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Твоя собака умеет плавать? \n    target text: Can your dog swim?\n    generated text: Is your dog able to swim?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning of the input and target text without adding any nonsensical or factually incorrect information. It simply rephrases the question in a slightly different way, which is a common practice in translation. The meaning remains intact and there are no unsupported additional details.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Этот нож очень мне пригодился. \n    target text: This knife was very useful to me.\n    generated text: This knife was very good for me.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the general meaning and intention of the input text and the target text. It does not contain any nonsensical or factually incorrect information, and it does not add any unsupported details. The word useful in the input text is accurately translated to good in the generated text, conveying a similar positive sentiment. While there is a slight difference in the choice of words, the overall message remains consistent.\nThis is the probability assigned by the editor: 0.9\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Том вооружился винтовкой и ножом. \n    target text: Tom armed himself with a gun and a knife.\n    generated text: Tom was armed with a rifle and knife.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text Tom was armed with a rifle and knife differs from the target text Tom armed himself with a gun and a knife. The use of rifle instead of gun is factually incorrect and constitutes a hallucination. This is because the input text did not mention a rifle, making it unsupported information.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Том сказал, что трижды пытался это сделать. \n    target text: Tom said that he's tried doing that three times.\n    generated text: Tom said he tried to do it three times.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the main idea of the input and target texts without introducing any nonsensical or factually incorrect information. It maintains the core meaning of Tom attempting to do something three times, which aligns with the input and target texts. There are no unsupported additional details present in the generated text, and it stays faithful to the original intent of the source text. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: То, что сказал Том, подтвердилось. \n    target text: What Tom said proved true.\n    generated text: What Tom said was confirmed.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning of the input text and the target text without introducing any nonsensical or factually incorrect information. It maintains the same general idea and does not add any unsupported information. Therefore, it is not hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Где Том взял эти фотографии? \n    target text: Where did Tom get these pictures?\n    generated text: Where did Tom take those photos?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning and intent of the input and target text. It conveys the same message using different words, and there are no nonsensical or factually incorrect information in the generated text. The slight difference in word choice does not change the overall meaning of the sentence.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Исправь его, пожалуйста. \n    target text: Please fix it.\n    generated text: Just fix it, please.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning of the target text while adding a polite modifier (please). The additional word just does not significantly change the meaning and can be considered a polite emphasis. There are no nonsensical or factually incorrect information in the generated text, and it does not contain any unsupported additional information. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Это твой первый трип? \n    target text: Is this your first time tripping?\n    generated text: Is this your first trip?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning and intent of the input and target texts. It conveys the same idea of experiencing something for the first time, which aligns with the context provided. There are no nonsensical or factually incorrect information in the generated text, and it does not introduce any unsupported additional information. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Некоторые разговаривают во сне. \n    target text: Some people talk in their sleep.\n    generated text: Some people talk in their dreams.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning of the input text and the target text. While in their dreams is not an exact match for in their sleep, the overall meaning remains consistent. Additionally, there are no nonsensical or factually incorrect details in the generated text. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Не пользуйтесь телефоном во время вождения. \n    target text: Don't use your phone while driving.\n    generated text: Do not use your phone while driving.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately conveys the meaning of the input text and the target text without adding any nonsensical or factually incorrect information. It follows the same instruction as the target text and does not introduce any additional unsupported information. Therefore, it is consistent with the input and target texts and does not exhibit any signs of hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Подожди, ты это серьёзно? \n    target text: Whoa, are you serious?\n    generated text: Wait, are you serious?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the intent and meaning of the input text and target text. It does not contain any nonsensical or factually incorrect information, and it does not introduce any additional unsupported information. Therefore, it aligns closely with the given inputs and targets, making it not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Мне нечего тебе дать. \n    target text: I've got nothing to give you.\n    generated text: I don't have anything to give you.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning and intent of the input text and the target text. It does not contain any nonsensical or factually incorrect information, and it does not introduce any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Что ты ей купил? \n    target text: What did you buy for her?\n    generated text: What did you buy her?\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the essential information in the input and target texts. Although it omits the preposition for in What did you buy for her?, the overall meaning is preserved and there is no nonsensical or factually incorrect information. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Вы забыли упомянуть это. \n    target text: You forgot to mention that.\n    generated text: You forgot to mention it.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the main idea and sentiment of the target text while staying true to the input text. It does not contain any nonsensical or factually incorrect information, nor does it introduce any additional unsupported information. Therefore, it aligns closely with both the input and target texts, making it not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: На девочке была большая красная шляпа. \n    target text: The girl had a large red hat on.\n    generated text: There was a big red hat on the girl.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the main elements of the input text and the target text, with no nonsensical or factually incorrect information. It simply rearranges the words in the sentence, but does not add any additional unsupported information. Therefore, it is not considered a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Он в больнице. \n    target text: He is in hospital.\n    generated text: He's in the hospital.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning of the input text and the target text without adding any nonsensical or factually incorrect information. It simply uses a different form of the word hospital (in hospital vs. in the hospital), which does not change the overall meaning or introduce any new unsupported information. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Одноклассники Тома обзывали его. \n    target text: Tom's classmates called him names.\n    generated text: Tom's classmates called him.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text is missing the crucial information names from the target text, which is present in the input text and the target text. This means it doesnt accurately represent the original meaning and is factually incorrect. Therefore, it is a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Можешь больше этого не делать. \n    target text: You don't have to do that anymore.\n    generated text: You can't do that anymore.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text You cant do that anymore is not a hallucination because it still captures the essence of the original meaning, which is about not having to do something anymore. Although the modal verb cant introduces a slight change in meaning, it still aligns with the overall sentiment of the target text. There are no nonsensical or factually incorrect details present, and the core message remains intact.\nThis is the probability assigned by the editor: 0.3\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Посмотрим, что Том придумает. \n    target text: We'll see what Tom comes up with.\n    generated text: Let's see what Tom's coming up with.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning and intent of the target text while staying true to the input text. It does not introduce any nonsensical or factually incorrect information, nor does it contain any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Мне нужно тебе кое-что объяснить. \n    target text: I have something I need to explain to you.\n    generated text: I need to explain something to you.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the main idea and intention of the input text and the target text. It conveys the message of needing to explain something without adding any nonsensical or factually incorrect information. Additionally, the generated text does not contain any additional unsupported information. Therefore, it is not a hallucination.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Том хорошо выглядит. \n    target text: Tom looks well.\n    generated text: That looks good.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Hallucination\".\nHere is the editor's rationale about the decision: The generated text That looks good contains additional information that cannot be supported by the input text Том хорошо выглядит and the target text Tom looks well. It adds the word That which is not present in the input or target text, making it a hallucination.\nThis is the probability assigned by the editor: 1.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Том подошёл к Мэри и обнял её. \n    target text: Tom walked over to Mary and hugged her.\n    generated text: Tom came to Mary and hugged her.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the main action described in the input text and the target text without adding any nonsensical or factually incorrect information. The only difference is the use of came instead of walked over to, which does not change the meaning or introduce any new information. Therefore, the generated text is not a hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Не думаю, что Том будет помогать нам это делать. \n    target text: I don't think Tom is going to help us do that.\n    generated text: I don't think Tom's gonna help us do this.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning and intent of the input text and the target text. It maintains the core message without introducing any nonsensical or factually incorrect information. The only difference is the use of gonna instead of going to, which is a colloquial variation of the original text. Therefore, the generated text is not hallucination.\nThis is the probability assigned by the editor: 0.1\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Россия превратилась во вторую сверхдержаву. \n    target text: Russia had emerged as a second superpower.\n    generated text: Russia has turned into a second superpower.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning of the input text and the target text without introducing any nonsensical or factually incorrect information. It stays true to the content and intent of the original text.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: Дети получили подарки. \n    target text: The children got some presents.\n    generated text: The children received gifts.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately captures the meaning of the input text and the target text without adding any nonsensical or factually incorrect information. It stays faithful to the original message and does not introduce any unsupported details.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    },
    {
        "system": "You are a computational linguist. Your task at hand is checking the quality and correctness of the automatically translated text by a machine translation (MT) system. You are given three inputs: \n    input text: У меня нет денег, чтобы купить словарь. \n    target text: I have no money to buy the dictionary with.\n    generated text: I don't have any money to buy a dictionary.\nThere are two criteria for hallucination:\n    If the generated text contatins any nonsensical or factually incorrect information, it is a hallucination.\n    If the generated text contains additional information that cannot be supported by the input text or the target text, it is a hallucination.\nOtherwise, the generated text is not a hallucination.\nA editor annotated the generated text and decided that the generated text is \"Not Hallucination\".\nHere is the editor's rationale about the decision: The generated text accurately conveys the meaning of the input text and the target text without adding any nonsensical or factually incorrect information. It stays true to the intent and content of the original sentence while providing a natural and accurate translation.\nThis is the probability assigned by the editor: 0.0\n",
        "query": "I would like you to control the annotation considering the rationale and probability score provided by the annotator. \n1.0 means that the generated text is hallucination for sure and 0.0 means it is not hallucination at all.\nAs you already know, different annotators are likely to judge the same input differently and tend to disagree on the same input.\nNow it is time to make a final decision. Is the generated text a hallucination or not? \nFor your answer, use the following json format: {\"Answer\": \"Hallucination/Not Hallucination\", \"p(Hallucination)\": \"0.0-1.0\"}'\n",
        "label": "Not Hallucination"
    }
]